{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/00_Logo.jpg\"   style=\"width:116px;height:218px;\" >\n",
    "</figure>\n",
    "\n",
    "# **MACHINE LEARNING SPECIALIZATION**\n",
    "# Curso 2: Advanced Learning Algorithms\n",
    "# Semana 1: NEURAL NETWORKS\n",
    "\n",
    "*Esta notebook plasma los apuntes traducidos al español del Curso dicatado por [DeepLearning.AI](https://www.deeplearning.ai/courses/), por lo que puede encontrar errores. Las figuras y ecuaciones se han obtenido/adaptado directamente de las diapositivas utilizadas en el curso. Todo el mérito es de los instructores. Simplemente espero que los apuntes sirvan como material de estudio complementario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORKS INTUITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1HlIqCzspeEaJAl4i2HjlF7ZPhn-rZ6_Z/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido al curso 2 de esta especialización en aprendizaje automático. En este curso, aprenderás sobre las redes neuronales, también llamadas algoritmos de aprendizaje profundo, así como los árboles de decisión. Estos son algunos de los algoritmos de aprendizaje automático más potentes y más utilizados y conseguirás implementarlos y hacerlos funcionar por ti mismo. \n",
    "\n",
    "Una de las cosas que se ven también en este curso son los consejos prácticos sobre cómo construir sistemas de aprendizaje automático. Esta parte del material es bastante exclusiva de este curso. Cuando construyes un sistema práctico de aprendizaje automático, hay muchas decisiones que tienes que tomar, como por ejemplo, si debes dedicar más tiempo a recopilar datos o si debes comprar una GPU mucho más grande para construir una red neuronal mucho más grande. Incluso hoy en día, cuando visito una empresa tecnológica líder y hablo con el equipo que trabaja en una aplicación de aprendizaje automático, por desgracia, a veces veo lo que han estado haciendo durante los últimos seis meses y digo: \"Vaya, alguien podría haberles dicho hace seis meses que ese enfoque no iba a funcionar tan bien\". Con algunos de los consejos que se aprende en este curso, espero que usted será uno o los que no perder esos seis meses, pero en su lugar, ser capaz de hacer más sistemática y mejores decisiones sobre cómo construir aplicaciones de aprendizaje automático de trabajo práctico. Con eso, vamos a sumergirnos. \n",
    "\n",
    "Esto es lo que se ve en las cuatro semanas de este curso. \n",
    "\n",
    "- En la semana 1, repasaremos las redes neuronales y cómo realizar inferencia o predicción. Si fueras a Internet y descargaras los parámetros de una red neuronal que otra persona ha entrenado y cuyos parámetros ha colgado en Internet, entonces utilizar esa red neuronal para hacer predicciones se llamaría inferencia, y en esta semana has aprendido cómo funcionan las redes neuronales y cómo hacer inferencia. \n",
    "- La próxima semana, aprenderás cómo entrenar tu propia red neuronal. En concreto, si tienes un conjunto de entrenamiento de ejemplos etiquetados, X e Y, ¿cómo entrenas los parámetros de una red neuronal para ti? \n",
    "- En la tercera semana, entraremos en los consejos prácticos para construir sistemas de aprendizaje automático y compartiré contigo algunos consejos que creo que incluso los ingenieros altamente pagados que construyen sistemas de aprendizaje automático con mucho éxito hoy en día no siempre consiguen aplicar de forma consistente y creo que te ayudarán a construir sistemas por ti mismo de forma eficiente y rápida. \n",
    "- Luego, en la última semana de este curso, se aprende sobre los árboles de decisión. Mientras que los árboles de decisión no tienen tanto bombo en los medios de comunicación, hay menos bombo sobre los árboles de decisión en comparación con las redes neuronales. Además, son uno de los algoritmos de aprendizaje más utilizados y potentes que creo que es muy probable que acabes utilizando tú mismo si acabas creando una aplicación. \n",
    "\n",
    "Con eso, vamos a saltar a las redes neuronales y vamos a empezar por echar un rápido vistazo a cómo el cerebro humano, es decir, cómo funciona el cerebro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons and the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1fbIFo02kaxuOa-OcK5WwbReOcSTv7Qaj/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se inventaron las redes neuronales hace muchas décadas, la motivación original era escribir un software que pudiera imitar cómo el cerebro humano o cómo el cerebro biológico aprende y piensa. Aunque hoy en día las redes neuronales, a veces también llamadas redes neuronales artificiales, se han convertido en algo muy diferente a lo que cualquiera de nosotros podría pensar sobre cómo funciona y aprende realmente el cerebro. Algunas de las motivaciones biológicas aún permanecen en la forma en que pensamos sobre las redes neuronales artificiales o redes neuronales informáticas hoy en día. Empecemos por ver cómo funciona el cerebro y cómo se relaciona con las redes neuronales. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_05.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "El cerebro humano, o quizás más generalmente, el cerebro biológico demuestra un nivel superior o más capaz de inteligencia y cualquier otra cosa estaría en la cuenta hasta ahora. Así que las redes neuronales han comenzado con la motivación de intentar construir un software que imite al cerebro. El trabajo en redes neuronales había comenzado en la década de 1950, y luego cayó en desgracia durante un tiempo. Luego, en los años 80 y principios de los 90, volvieron a ganar popularidad y mostraron una enorme tracción en algunas aplicaciones como el reconocimiento de dígitos escritos a mano, que se utilizaban incluso en aquel entonces para leer los códigos postales para enrutar el correo y para leer las cifras en dólares en los cheques escritos a mano. Pero luego volvió a caer en desgracia a finales de los 90. Fue a partir de alrededor de 2005 cuando disfrutó de un resurgimiento y también se rebautizó un poco con el aprendizaje profundo. Una de las cosas que me sorprendió entonces fue que el aprendizaje profundo y las redes neuronales significaban cosas muy similares. Pero tal vez no se apreciaba en ese momento que el término aprendizaje profundo, simplemente suena mucho mejor porque es profundo y este aprendizaje. Así que esa resultó ser la marca que despegó en la última década o década y media. Desde entonces, las redes neuronales han revolucionado un área de aplicación tras otra. \n",
    "Creo que la primera área de aplicación en la que las redes neuronales modernas o el aprendizaje profundo tuvieron un gran impacto fue probablemente el reconocimiento del habla, donde empezamos a ver sistemas de reconocimiento del habla mucho mejores gracias al aprendizaje profundo moderno y autores fueron fundamentales para esto, y luego empezó a hacer incursiones en la visión por ordenador. A veces la gente todavía habla de los momentos de ImageNet en 2012, y eso fue tal vez un chapoteo más grande donde entonces se comenzaba a dibujar su imaginación y tuvo un gran impacto en la visión por ordenador. Luego, los años siguientes, nos hizo incursiones en los textos o en el procesamiento del lenguaje natural, y así sucesivamente. Ahora, las redes neuronales se utilizan en todo, desde el cambio climático hasta las imágenes médicas y la publicidad en línea. Así que, orgullosamente, las recomendaciones y realmente muchas áreas de aplicación del aprendizaje automático utilizan ahora redes neuronales. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_06.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Aunque las redes neuronales actuales no tienen casi nada que ver con el modo en que aprende el cerebro, la motivación inicial era tratar de construir un software que imitara al cerebro. ¿Cómo funciona el cerebro? He aquí un diagrama que ilustra el aspecto de las neuronas en un cerebro. Todo el pensamiento humano procede de neuronas como ésta en tu cerebro y en el mío, que envían impulsos eléctricos y a veces forman nuevas conexiones de otras neuronas. Dada una neurona como esta, tiene un número de entradas donde recibe impulsos eléctricos de otras neuronas, y luego esta neurona que he rodeado lleva a cabo algunos cálculos y luego enviará esta salida a otras neuronas por medio de estos impulsos eléctricos, y la salida de esta neurona superior a su vez se convierte en la entrada de esta neurona de abajo, que de nuevo agrega entradas de múltiples otras neuronas para luego tal vez enviar su propia salida, a otras neuronas, y esta es la materia de la que está hecho el pensamiento humano. Este es un diagrama simplificado de una neurona biológica. Una neurona comprende un cuerpo celular que se muestra aquí a la izquierda, y si has tomado un curso de biología, puedes reconocer que esto es el núcleo de la neurona. \n",
    "\n",
    "Como vimos en la diapositiva anterior, la neurona tiene diferentes entradas. En una neurona biológica, los cables de entrada se llaman dendritas, y luego ocasionalmente envía impulsos eléctricos a otras neuronas a través del cable de salida, que se llama axón. No te preocupes por estos términos biológicos. Si los viste en una clase de biología, puede que los recuerdes, pero realmente no necesitas memorizar ninguno de estos términos para construir redes neuronales artificiales. Pero esta neurona biológica puede enviar impulsos eléctricos que se convierten en la entrada de otra neurona. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_07.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que la red neuronal artificial utiliza un modelo matemático muy simplificado de lo que hace una neurona biológica. Voy a dibujar un pequeño círculo aquí para denotar una sola neurona. Lo que hace una neurona es tomar algunas entradas, una o más entradas, que son sólo números. Hace algún cálculo y da como resultado algún otro número, que luego podría ser una entrada para una segunda neurona, mostrada aquí a la derecha. Cuando construyes una red neuronal artificial o un algoritmo de aprendizaje profundo, en lugar de construir una neurona cada vez, a menudo quieres simular muchas de esas neuronas al mismo tiempo. En este diagrama, estoy dibujando tres neuronas. Lo que estas neuronas hacen colectivamente es introducir algunos números, llevar a cabo algún cálculo y dar salida a otros números. \n",
    "Llegados a este punto, me gustaría hacer una gran advertencia, y es que, aunque he hecho una analogía poco precisa entre las neuronas biológicas y las neuronas artificiales, creo que hoy en día casi no tenemos ni idea de cómo funciona el cerebro humano. De hecho, cada pocos años, los neurocientíficos hacen algún avance fundamental sobre el funcionamiento del cerebro. Creo que seguiremos haciéndolo en el futuro inmediato. Para mí, eso es una señal de que aún quedan muchos avances por descubrir sobre el funcionamiento real del cerebro y, por lo tanto, los intentos de imitar ciegamente lo que sabemos del cerebro humano en la actualidad, que es francamente muy poco, probablemente no nos llevarán tan lejos en la construcción de la inteligencia bruta. Desde luego, no con nuestro nivel actual de conocimientos en neurociencia. Dicho esto, incluso con estos modelos extremadamente simplificados de una neurona, de los que hablaremos, podremos construir algoritmos de aprendizaje profundo realmente potentes. Así que a medida que se profundiza en las redes neuronales y en el aprendizaje profundo, aunque los orígenes fueron motivados biológicamente, no hay que tomarse la motivación biológica demasiado en serio. De hecho, los que investigamos en el aprendizaje profundo hemos dejado de fijarnos tanto en la motivación biológica. En su lugar, sólo utilizan principios de ingeniería para averiguar cómo construir algoritmos que sean más eficaces. Pero creo que todavía puede ser divertido especular y pensar en cómo funcionan las neuronas biológicas de vez en cuando. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_08.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Las ideas de las redes neuronales existen desde hace muchas décadas. Algunas personas me han preguntado: \"Oye Andrew, ¿por qué ahora? ¿Por qué sólo en los últimos años las redes neuronales han despegado realmente?\". Esta es una imagen que dibujo para ellos cuando me hacen esa pregunta y que quizás tú también podrías dibujar para otros si te hacen esa pregunta. Permítanme trazar en el eje horizontal la cantidad de datos que tienen para un problema, y en el eje vertical, el rendimiento o la precisión de un algoritmo de aprendizaje aplicado a ese problema. En las últimas dos décadas, con el auge de Internet, el auge de los teléfonos móviles, la digitalización de nuestra sociedad, la cantidad de datos que tenemos para un montón de aplicaciones ha marchado constantemente hacia la derecha. Muchos de los registros que utilizan P en papel, como si usted pide algo en lugar de que sea en un pedazo de papel, es mucho más probable que sea un registro digital. Su registro de salud, si usted ve a un médico, es mucho más probable que sea digital ahora en comparación con los pedazos de papel. \n",
    "\n",
    "Así que, en muchas áreas de aplicación, la cantidad de datos digitales se ha disparado. Lo que vimos fue que, con los algoritmos tradicionales de aprendizaje automático, como la regresión logística y la regresión lineal, incluso cuando se alimentaban esos algoritmos con más datos, era muy difícil conseguir que el rendimiento siguiera aumentando. Era como si los algoritmos de aprendizaje tradicionales, como la regresión lineal y la regresión logística, no fueran capaces de escalar con la cantidad de datos que ahora podíamos alimentar y no eran capaces de aprovechar eficazmente todos estos datos que teníamos para diferentes aplicaciones. Lo que los investigadores de IA empezaron a observar fue que, si se entrena una pequeña red neuronal en este conjunto de datos, el rendimiento puede ser así. Si se entrena una red neuronal de tamaño medio, es decir, con más neuronas, su rendimiento puede ser así. Si se entrena una red neuronal muy grande, es decir, con muchas de estas neuronas artificiales, entonces para algunas aplicaciones el rendimiento seguirá aumentando. \n",
    "\n",
    "Esto significó dos cosas, significó que para una cierta clase de aplicaciones en las que tienes muchos datos, a veces se oye el término big data, si eres capaz de entrenar una red neuronal muy grande para aprovechar esa enorme cantidad de datos que tienes, entonces podrías alcanzar un rendimiento en cualquier cosa que va desde el reconocimiento del habla, al reconocimiento de imágenes, a las aplicaciones de paso del lenguaje natural y muchos más, que simplemente no eran posibles con las generaciones anteriores de algoritmos de aprendizaje. Esto provocó el despegue de los algoritmos de aprendizaje profundo, y también por eso los procesos informáticos más rápidos, incluyendo el aumento de las GPU o unidades de procesamiento gráfico. Se trata de un hardware diseñado originalmente para generar gráficos de ordenador de aspecto agradable, pero que resultó ser muy potente también para el aprendizaje profundo. Eso también fue una fuerza importante que permitió que los algoritmos de aprendizaje profundo se convirtieran en lo que son hoy. \n",
    "Así es como empezaron las redes neuronales, y también por qué han despegado tan rápidamente en los últimos años. Profundicemos ahora en los detalles de cómo funcionan realmente las redes neuronales. Pase al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Prediction\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1mnr0PEWd-eGc9l_CpdWHO4X72F7FRjwf/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^Para ilustrar cómo funcionan las redes neuronales, vamos a empezar con un ejemplo. Utilizaremos un ejemplo de predicción de la demanda en el que se observa el producto y se intenta predecir si este producto será un éxito de ventas o no. Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_10.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "En este ejemplo, usted vende camisetas y quiere saber si una camiseta en particular será un éxito de ventas, sí o no, y ha recopilado datos de diferentes camisetas que se vendieron a diferentes precios, así como cuáles se convirtieron en un éxito de ventas. Este tipo de aplicación la utilizan los minoristas hoy en día para planificar mejor los niveles de inventario, así como las campañas de marketing. Si se sabe qué es lo que más se va a vender, se puede planificar, por ejemplo, la compra anticipada de más existencias de ese producto. En este ejemplo, la característica de entrada $x$ es el precio de la camiseta, por lo que es la entrada del algoritmo de aprendizaje. Si aplicamos la regresión logística para ajustar una función sigmoidea a los datos, la salida de la predicción podría ser así, $\\frac{1}{1 + e^{-(wx+b)}}$. Anteriormente, habíamos escrito esto como $f(x)$ como salida del algoritmo de aprendizaje. Con el fin de prepararnos para construir una red neuronal, voy a cambiar la terminología un poco y utilizar la letra $a$ para denotar la salida de este algoritmo de regresión logística. El término a significa **activación**, y es en realidad un término de la neurociencia, y se refiere a lo mucho que una neurona está enviando una salida alta a otras neuronas aguas abajo de ella.\n",
    "\n",
    "Resulta que estas unidades de regresión logística o este pequeño algoritmo de regresión logística, puede ser pensado como un modelo muy simplificado de una sola neurona en el cerebro. Lo que hace la neurona es que toma el precio $x$, y luego computa esta fórmula en la parte superior, y emite el número $a$, que es calculado por esta fórmula, y emite la probabilidad de que esta camiseta sea la más vendida. Otra forma de pensar en una neurona es como un pequeño ordenador cuyo único trabajo es introducir un número o unos cuantos números, como un precio, y luego dar como resultado un número o quizás unos cuantos números más, que en este caso es la probabilidad de que la camiseta sea la más vendida. Como he aludido en el vídeo anterior, un algoritmo de regresión logística es mucho más sencillo que lo que hace cualquier neurona biológica de tu cerebro o del mío. Por eso la red neuronal artificial es un modelo tan enormemente simplificado del cerebro humano. Aunque en la práctica, como sabes, los algoritmos de aprendizaje profundo funcionan muy bien. \n",
    "\n",
    "Dada esta descripción de una sola neurona, construir una red neuronal ahora solo requiere tomar un montón de estas neuronas y conectarlas o juntarlas. Veamos ahora un ejemplo más complejo de predicción de la demanda. En este ejemplo, vamos a tener cuatro características para predecir si una camiseta es o no un éxito de ventas. Las características son el precio de la camiseta, los gastos de envío, las cantidades de marketing de esa camiseta en particular, así como la calidad del material, ¿es un algodón grueso de alta calidad frente a un material de menor calidad?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_11.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora bien, se puede sospechar que el hecho de que una camiseta se convierta en un éxito de ventas depende de varios factores. En primer lugar, uno es la asequibilidad de esta camiseta. El segundo es el grado de conocimiento de esta camiseta que tienen los compradores potenciales. El tercero es la calidad percibida al sesgo o el sesgo potencial de decir que esta es una camiseta de alta calidad. \n",
    "\n",
    "Lo que voy a hacer es crear una neurona artificial para intentar estimar la probabilidad de que esta camiseta sea percibida como altamente asequible. La asequibilidad es principalmente una función del precio y de los gastos de envío porque el importe total de la paga es parte del precio más los gastos de envío. Vamos a utilizar una pequeña neurona aquí, una unidad de regresión logística para introducir el precio y los gastos de envío y predecir si la gente piensa que esto es asequible. En segundo lugar, voy a crear otra neurona artificial aquí para estimar, ¿hay un alto conocimiento de esto? La conciencia en este caso es principalmente una función de la comercialización de la camiseta. Por último, voy a crear otra neurona para estimar si la gente percibe esto como de alta calidad, y que puede ser principalmente una función del precio de la camiseta y de la calidad del material. El precio es un factor aquí porque, por suerte o por desgracia, si hay una camiseta de precio muy alto, la gente a veces percibe que es de alta calidad porque es muy caro que tal vez la gente piensa que va a ser de alta calidad. Teniendo en cuenta estas estimaciones de la asequibilidad, la conciencia y la calidad percibida, entonces conectamos las salidas de estas tres neuronas a otra neurona aquí a la derecha, que luego hay otra unidad de regresión logística. Que finalmente introduce esos tres números y da como resultado la probabilidad de que esta camiseta sea la más vendida. \n",
    "\n",
    "En la terminología de las redes neuronales, vamos a agrupar estas tres neuronas en lo que se llama una capa (**layer**). Una capa es una agrupación de neuronas que nos toma la entrada de características iguales o similares, y que a su vez da salida a unos números juntos. Estas tres neuronas de la izquierda forman una capa, por eso las he dibujado una encima de la otra, y esta única neurona de la derecha también es una capa. La capa de la izquierda tiene tres neuronas, así que una capa puede tener múltiples neuronas o también puede tener una sola neurona como en el caso de esta capa de la derecha. Esta capa de la derecha también se llama capa de salida (**output layer**) porque la salida de esta última neurona es la probabilidad de salida predicha por la red neuronal. \n",
    "\n",
    "En la terminología de las redes neuronales también vamos a llamar **activaciones** a la conciencia de asequibilidad y a la percepción de la calidad. El término activaciones viene de las neuronas biológicas, y se refiere al grado en que la neurona biológica está enviando un valor de salida alto o enviando muchos impulsos eléctricos a otras neuronas a la corriente abajo de ella. Estos números sobre la asequibilidad, la conciencia y la calidad percibida son las activaciones de estas tres neuronas en esta capa, y también esta probabilidad de salida es la activación de esta neurona mostrada aquí a la derecha. \n",
    "\n",
    "Por lo tanto, esta red neuronal en particular lleva a cabo los cálculos de la siguiente manera. Introduce cuatro números y luego esta capa de la red neuronal utiliza esos cuatro números para calcular los nuevos números también llamados valores de activación. A continuación, la última capa, la capa de salida de la red neuronal, utiliza esos tres números para calcular un número. En una red neuronal esta lista de cuatro números también se llama capa de entrada (**input layer**), y es simplemente una lista de cuatro números. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_12.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, hay una simplificación que me gustaría hacer a esta red neuronal. La forma en que lo he descrito hasta ahora, tuvimos que ir a través de las neuronas uno a la vez y decidir qué entradas que tomaría de la capa anterior. Por ejemplo, dijimos que la asequibilidad es una función de sólo el precio y los gastos de envío y la conciencia es una función de sólo la comercialización y así sucesivamente, pero si usted está construyendo una gran red neuronal que sería un montón de trabajo para ir a través y decidir manualmente que las neuronas deben tomar las características como entradas. La forma en que una red neuronal se implementa en la práctica cada neurona en una determinada capa, digamos esta capa en el medio, tendrá acceso a cada característica, a cada valor de la capa anterior, de la capa de entrada que es por eso que ahora estoy dibujando flechas de cada característica de entrada a cada una de estas neuronas que se muestran aquí en el medio. Usted puede imaginar que si usted está tratando de predecir la asequibilidad y sabe lo que es el precio de envío de marketing y material, puede ser que usted aprenderá a ignorar la comercialización y el material y sólo averiguar a través de la configuración de los parámetros de manera adecuada para centrarse sólo en el subconjunto de características que son más relevantes para la asequibilidad. \n",
    "\n",
    "Para simplificar aún más la notación y la descripción de esta red neuronal voy a tomar estas cuatro características de entrada y escribirlas como un vector $x$, y vamos a ver la red neuronal como si tuviera cuatro características que comprenden este vector de características $x$. Este vector de características se alimenta a esta capa en el medio que luego calcula tres valores de activación. Es decir, estos números y estos tres valores de activación se convierten en otro vector que se alimenta a esta capa de salida final que finalmente produce la probabilidad de que esta camiseta sea una de las más vendidas. Eso es todo lo que es una red neuronal. Tiene unas cuantas capas en las que cada capa introduce un vector y emite otro vector de números. Por ejemplo, esta capa del centro introduce cuatro números $x$ y emite tres números correspondientes a la asequibilidad, el conocimiento y la calidad percibida. \n",
    "\n",
    "Para añadir un poco más de terminología, has visto que esta capa se llama capa de salida y esta capa se llama capa de entrada. Para dar un nombre a la capa del medio también, esta capa del medio se llama capa oculta (**hidden layer**). Sé que tal vez no sea el mejor nombre o el más intuitivo, pero esa terminología viene de que es cuando tienes un conjunto de entrenamiento. En un conjunto de entrenamiento, consigues observar tanto $x$ como $y$. Tu conjunto de datos te dice qué es $x$ y qué es $y$, y así consigues datos que te dicen cuáles son las entradas y salidas correctas. Pero su conjunto de datos no le dice cuáles son los valores correctos de asequibilidad, conocimiento y calidad percibida. Los valores correctos están ocultos. No los ves en el conjunto de entrenamiento, y por eso esta capa del medio se llama capa oculta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_13.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Me gustaría compartir contigo otra forma de pensar en las redes neuronales que me ha resultado útil para construir mi intuición al respecto. Permítanme cubrir la mitad izquierda de este diagrama, y ver lo que nos queda. Lo que ves aquí es que hay un algoritmo de regresión logística o unidad de regresión logística que está tomando como entrada, la asequibilidad, la conciencia, y la calidad percibida de una camiseta, y el uso de estas tres características para estimar la probabilidad de que la camiseta sea un top ventas. Esto es simplemente una regresión logística. Pero lo bueno de esto es que, en lugar de utilizar las características originales, el precio, los gastos de envío, el marketing, etc., se utiliza tal vez un mejor conjunto de características, la asequibilidad, la conciencia, y la calidad percibida, que se espera que sean más predictivas de si esta camiseta será un éxito de ventas. \n",
    "\n",
    "Una forma de pensar en esta red neuronal es, simplemente regresión logística. Pero, como una versión de la regresión logística, pueden aprender sus propias características que hacen más fácil hacer predicciones precisas. De hecho, usted puede recordar de la semana anterior, este ejemplo de la vivienda donde dijimos que, si usted quiere predecir el precio de la casa, usted podría tomar la fachada o la anchura de los lotes y multiplicar eso por la profundidad de un lote para construir una característica más compleja, $x_1$ veces $x_2$, que era el tamaño del césped. En este caso, teníamos que hacer una ingeniería de rasgos manual en la que teníamos que mirar los rasgos $x_1$ y $x_2$ y decidir a mano cómo combinarlos para obtener mejores rasgos. Lo que hace la red neuronal es que, en lugar de tener que diseñar manualmente las características, puede aprender, como verás más adelante, sus propias características para facilitar el problema del aprendizaje. Esto es lo que hace que las redes neuronales sean uno de los algoritmos de aprendizaje más potentes de la actualidad. \n",
    "\n",
    "Para resumir, una red neuronal, hace esto, la capa de entrada tiene un vector de características, cuatro números en este ejemplo, es la entrada a la capa oculta, que produce tres números. Voy a utilizar un vector para denotar este vector de activaciones que esta capa oculta produce. Luego la capa de salida toma su entrada a tres números y emite un número, que sería la activación final, o la predicción final de la red neuronal. \n",
    "\n",
    "Una nota, aunque he descrito anteriormente esta red neuronal como el cálculo de la asequibilidad, la conciencia, y la calidad percibida, una de las propiedades realmente agradable de una red neuronal es cuando se entrena a partir de los datos, no es necesario ir a decidir explícitamente lo que otras características, como la asequibilidad y así sucesivamente, que la red neuronal debe calcular en su lugar o averiguar por sí mismo cuáles son las características que desea utilizar en esta capa oculta. Eso es lo que lo convierte en un algoritmo de aprendizaje tan potente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_14.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Has visto aquí un ejemplo de red neuronal y esta red neuronal tiene una sola capa que es una capa oculta. Veamos otros ejemplos de redes neuronales, concretamente, ejemplos con más de una capa oculta. Aquí tenemos un ejemplo. Esta red neuronal tiene un vector de características de entrada X que se alimenta a una capa oculta. Voy a llamarla la primera capa oculta. Si esta capa oculta tiene tres neuronas, dará como resultado un vector de tres valores de activación. Estos tres números pueden ser introducidos en la segunda capa oculta. Si la segunda capa oculta tiene dos neuronas a las unidades logísticas, entonces este segundo oculto allí dará salida a otro vector de ahora dos valores de activación que tal vez va a la capa de salida que luego da salida a la predicción final de la red neuronal. \n",
    "\n",
    "Aquí hay otro ejemplo. Aquí tenemos una red neuronal cuya entrada va a la primera capa oculta, la salida de la primera capa oculta va a la segunda capa oculta, va a la tercera capa oculta, y finalmente a la capa de salida. Cuando construyas tu propia red neuronal, una de las decisiones que debes tomar es cuántas capas ocultas quieres y cuántas neuronas quieres que tenga cada capa oculta. Esta cuestión de cuántas capas ocultas y cuántas neuronas por capa oculta es una cuestión de la arquitectura de la red neuronal. Más adelante en este curso aprenderás algunos consejos para elegir una arquitectura adecuada para una red neuronal. Pero elegir el número correcto de capas ocultas y el número de unidades ocultas por capa también puede tener un impacto en el rendimiento de un algoritmo de aprendizaje. Más adelante en este curso, aprenderás también a elegir una buena arquitectura para tu red neuronal. \n",
    "\n",
    "Por cierto, en parte de la literatura, se ve este tipo de red neuronal con múltiples capas como esta llamada perceptrón multicapa. Si ves eso, se refiere a una red neuronal que se parece a lo que estás viendo aquí en la diapositiva. Es una red neuronal. \n",
    "\n",
    "Sé que hemos hablado mucho en este vídeo. Gracias por seguir conmigo. Pero ahora ya sabes cómo funciona una red neuronal. En el siguiente vídeo, vamos a ver cómo se pueden aplicar estas ideas a otras aplicaciones. En particular, vamos a echar un vistazo a la aplicación de visión por ordenador del reconocimiento facial. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Recognizing Images\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/12hHE4LOz0ikdSOukWNGglvWgiH2jL4qx/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, has visto cómo funciona una red neuronal en un ejemplo de predicción de la demanda. Veamos cómo se puede aplicar un tipo de idea similar a una aplicación de visión por ordenador. Entremos en materia. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_16.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Si estás construyendo una aplicación de reconocimiento de rostros, es posible que quieras entrenar una red neuronal que tome como entrada una imagen como ésta y dé como resultado la identidad de la persona en la imagen. Esta imagen tiene 1.000 por 1.000 píxeles. Su representación en el ordenador es en realidad como una cuadrícula de 1.000 por 1.000, o también llamada matriz de 1.000 por 1.000 de valores de intensidad de píxeles. En este ejemplo, mis valores de intensidad de píxel o valores de brillo de píxel, van de 0 a 255 y así 197 aquí sería el brillo del píxel en la parte superior izquierda de la imagen, 185 es el brillo del píxel, un píxel más, y así hasta 214 sería la esquina inferior derecha de esta imagen. Si tomáramos estos valores de intensidad de píxel y los desenrolláramos en un vector, terminaríamos con una lista o un vector de un millón de valores de intensidad de píxel. Un millón porque un cuadrado de 1.000 por 1.000 te da un millón de números. El problema del reconocimiento de rostros es si se puede entrenar una red neuronal que tome como entrada un vector de características con un millón de valores de luminosidad de píxeles y dé como resultado la identidad de la persona en la imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_17.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así es como se podría construir una red neuronal para llevar a cabo esta tarea. La imagen de entrada $X$ se introduce en esta capa de neuronas. Esta es la primera capa oculta, que luego extrae algunas características. La salida de esta primera capa oculta es alimentada a una segunda capa oculta y esa salida es alimentada a una tercera capa y finalmente a la capa superior, que entonces estima, digamos, la probabilidad de que esto sea una persona en particular. Una cosa interesante sería si usted mira una red neuronal que ha sido entrenado en un montón de imágenes de las caras y para tratar de visualizar lo que son estas capas ocultas, tratando de calcular. Resulta que cuando entrenas un sistema como este con muchas imágenes de caras y observas las diferentes neuronas en las capas ocultas para averiguar lo que pueden estar calculando esto es lo que puedes encontrar. En la primera capa oculta, podrías encontrar una neurona que busca la línea vertical baja o un borde vertical como ese. Una segunda neurona buscando una línea orientada o un borde orientado así. Una tercera neurona que busque una línea con esa orientación, y así sucesivamente. En las primeras capas de una red neuronal, puedes encontrar que las neuronas están buscando líneas muy cortas o bordes muy cortos en la imagen. Si observamos la siguiente capa oculta, veremos que estas neuronas pueden aprender a agrupar muchas líneas cortas y segmentos de bordes cortos para buscar partes de caras. Por ejemplo, cada una de estas pequeñas cajas cuadradas es una visualización de lo que esa neurona está tratando de detectar. Esta primera neurona parece que está tratando de detectar la presencia o ausencia de un ojo en una determinada posición de la imagen. La segunda neurona, parece que está tratando de detectar como una esquina de una nariz y tal vez esta neurona aquí está tratando de detectar la parte inferior de una nariz. A continuación, si se observa la siguiente capa oculta en este ejemplo, la red neuronal está agregando diferentes partes de las caras para tratar de detectar la presencia o ausencia de formas de cara más grandes y gruesas. Por último, la detección de la correspondencia de la cara con las diferentes formas de la misma crea un rico conjunto de características que ayuda a la capa de salida a determinar la identidad de la imagen de la persona. \n",
    "\n",
    "Lo más destacable de la red neuronal es que puede aprender por sí misma estos detectores de características en las diferentes capas ocultas. En este ejemplo, nadie le dijo que buscara pequeños bordes en la primera capa, y ojos y narices y partes de la cara en la segunda capa y luego formas de cara más completas en la tercera capa. La red neuronal es capaz de averiguar estas cosas por sí misma a partir de los datos. Sólo una nota, en esta visualización, las neuronas de la primera capa oculta se muestran mirando ventanas relativamente pequeñas para buscar estos bordes. En la segunda capa oculta está mirando una ventana más grande, y la tercera capa oculta está mirando una ventana aún más grande. Estas visualizaciones de pequeñas neuronas corresponden en realidad a regiones de distinto tamaño en la imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_18.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Sólo por diversión, veamos qué ocurre si se entrena esta red neuronal en un conjunto de datos diferente, digamos que, en muchas fotos de coches, con la foto de al lado. Se le pide al mismo algoritmo de aprendizaje que detecte los coches, entonces aprenderá los bordes en la primera capa. Bastante similar, pero luego aprenderá a detectar partes de coches en la segunda capa oculta y luego formas de coches más completas en la tercera capa oculta. Sólo con alimentarla con diferentes datos, la red neuronal aprende automáticamente a detectar características muy diferentes para intentar hacer las predicciones de detección de coches o de reconocimiento de personas o si hay una tarea determinada en la que se entrena. \n",
    "\n",
    "Así es como funciona una red neuronal para una aplicación de visión por ordenador. De hecho, más adelante esta semana, verás cómo puedes construir una red neuronal tú mismo y aplicarla a una aplicación de reconocimiento de dígitos escritos a mano. Hasta ahora hemos repasado la descripción de las intuiciones de las redes neuronales para que te hagas una idea de cómo funcionan. En el siguiente vídeo, vamos a profundizar en las matemáticas concretas y en una implementación concreta de los detalles de cómo se construye realmente una o varias capas de una red neuronal, y por tanto cómo puedes implementar una de estas cosas tú mismo. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Neural networks intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "¿Cuál de estos términos se utiliza para referirse a los componentes de una red neuronal artificial? \n",
    "- Neuronas\n",
    "- Capas\n",
    "- Axón\n",
    "- Función de activación\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "¿Verdadero/Falso? Las redes neuronales se inspiran en la forma en que aprenden las neuronas de un cerebro biológico, pero no la imitan con mucha precisión. \n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1:\n",
    "    \n",
    "- Neuronas\n",
    "- Capas\n",
    "- Función de activación\n",
    "\n",
    "Respuesta 2: Verdadero.\n",
    "  \n",
    "\n",
    "Las redes neuronales artificiales no imitan realmente la complejidad de las neuronas biológicas reales.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network layer\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/12Vflfav1G3ISbQfvdOYsVEv3ufGXhprR/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bloque de construcción fundamental de la mayoría de las redes neuronales modernas es una capa de neuronas. En este vídeo, aprenderás a construir una capa de neuronas y, una vez que lo tengas claro, podrás tomar esos bloques de construcción y unirlos para formar una gran red neuronal. Veamos cómo funciona una capa de neuronas. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_21.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está el ejemplo que teníamos del ejemplo de predicción de la demanda donde teníamos cuatro características de entrada que se establecieron en esta capa de tres neuronas en la capa oculta que luego envía su salida a esta capa de salida con una sola neurona. Acerquémonos a la capa oculta para ver sus cálculos. Esta capa oculta introduce cuatro números y estos cuatro números son entradas para cada una de las tres neuronas. Cada una de estas tres neuronas está implementando una pequeña unidad de regresión logística o una pequeña función de regresión logística. Tome esta primera neurona. Tiene dos parámetros, $w$ y $b$. De hecho, para denotar que, esta es la primera unidad oculta, voy a subíndice esto como $w_1$, $b_1$. Lo que hace es que voy a emitir algún valor de activación $a$, que es $g(w_1·x+b_1)$, donde este es el valor de $z$ familiar que usted ha aprendido en la regresión logística en el curso anterior, y $g(z)$ es la función logística familiar, $\\frac{1}{1+e^{(-z)}}$. Tal vez esto termina siendo un número 0,3 y ese es el valor de activación a de la primera neurona. Para denotar que esta es la primera neurona, también voy a añadir un subíndice $a_1$ por aquí, y así a1 puede ser un número como 0,3. Hay una probabilidad de 0,3 de que esto sea altamente asequible basado en las características de entrada. \n",
    "\n",
    "Ahora vamos a ver la segunda neurona. La segunda neurona tiene parámetros $w_2$ y $b_2$, y estos $w$, $b$ o $w_2$, $b_2$ son los parámetros de la segunda unidad logística. Calcula que $a_2$ es igual a la función logística $g$ aplicada al producto de puntos $w_2$ más $b_2$ y éste puede ser algún otro número, digamos 0,7. Porque en este ejemplo, hay una probabilidad de 0,7 de que creamos que los compradores potenciales conozcan esta camiseta. \n",
    "Del mismo modo, la tercera neurona tiene un tercer conjunto de parámetros $w_3$, $b_3$. Del mismo modo, calcula un valor de activación $a_3$ igual a $g$ del producto de puntos $w_3$ más $b_3$ y que puede ser, digamos, 0,2. \n",
    "\n",
    "En este ejemplo, estas tres neuronas dan como resultado 0,3, 0,7 y 0,2, y este vector de tres números se convierte en el vector de valores de activación a, que luego se pasa a la capa de salida final de esta red neuronal. Ahora, cuando construyas redes neuronales con múltiples capas, será útil dar a las capas números diferentes. Por convención, esta capa se llama capa 1 (layer 1) de la red neuronal y esta capa se llama capa 2 (layer 2) de la red neuronal. La capa de entrada también se llama a veces capa 0 (layer 0) y hoy en día, hay redes neuronales que pueden tener docenas o incluso cientos de capas. \n",
    "\n",
    "Pero para introducir una notación que nos ayude a distinguir entre las diferentes capas, voy a utilizar el superíndice en corchete 1 para indexar las diferentes capas. En particular, un superíndice [1], voy a utilizar, que es una notación para denotar la salida de la capa 1 de esta capa oculta de esta red neuronal, y de manera similar, $w_1$, $b_1$ aquí son los parámetros de la primera unidad en la capa 1 de la red neuronal, así que también voy a añadir un superíndice entre corchetes 1 aquí, y $w_2$, $b_2$ son los parámetros de la segunda unidad oculta o la segunda neurona oculta en la capa 1. Sus parámetros también se denotan aquí $w^{[1]}$ así. Del mismo modo, puedo añadir superíndices corchetes como así para denotar que estos son los valores de activación de las unidades ocultas de la capa 1 de esta red neuronal. Sé que tal vez esta notación se está volviendo un poco desordenada. Pero lo que hay que recordar es que cada vez que veas este superíndice [1], eso sólo se refiere a una cantidad que está asociada con la capa 1 de la red neuronal. Si ves el superíndice [2], eso se refiere a una cantidad asociada a la capa 2 de la red neuronal y de forma similar para otras capas también, incluyendo la capa 3, la capa 4 y así sucesivamente para las redes neuronales con más capas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_22.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Este es el cálculo de la capa 1 de esta red neuronal. Su salida es este vector de activación, $a^{[1]}$ y voy a copiarlo aquí porque esta salida a1 se convierte en la entrada de la capa 2. Ahora vamos a ampliar el cálculo de la capa 2 de esta red neuronal, que es también la capa de salida. La entrada a la capa 2 es la salida de la capa 1, así que $a^{[1]}$ es este vector 0.3, 0.7, 0.2 que acabamos de calcular en la parte anterior de esta diapositiva. Debido a que la capa de salida tiene una sola neurona, todo lo que hace es calcular a1 que es la salida de esta primera y única neurona, como $g$, la función sigmoidea aplicada a $w_1$ en un producto con $a^{[1]}$, así que esta es la entrada en esta capa, y luego más $b_1$. Aquí, esta es la cantidad $z$ con la que estás familiarizado y $g$ como antes es la función sigmoidea que se aplica a esto. Si esto da como resultado un número, digamos 0,84, entonces eso se convierte en la capa de salida de la red neuronal. En este ejemplo, debido a que la capa de salida tiene una sola neurona, esta salida es sólo un escalar, es un solo número en lugar de un vector de números. \n",
    "\n",
    "Siguiendo con nuestra convención notacional de antes, vamos a utilizar un superíndice entre [2], para denotar las cantidades asociadas con la capa 2 de esta red neuronal, por lo que $a^{[2]}$ es la salida de esta capa, y por lo que también voy a copiar esto aquí como la salida final de la red neuronal. Para hacer la notación consistente, también puedes añadir estos superíndices 2 entre corchetes para denotar que estos son los parámetros y valores de activación asociados a la capa 2 de la red neuronal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_23.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Una vez que la red neuronal ha calculado $a^{[2]}$, hay un último paso opcional que puedes elegir implementar o no, que es si quieres una predicción binaria, 1 o 0, ¿es esto un vendedor superior? ¿Si o no? Como usted puede tomar el número un superíndice corchetes 2 subíndice 1, y este es el número 0,84 que hemos calculado, y el umbral de este en 0,5. Si es mayor que 0.5, puedes predecir que y_hat es igual a 1 y si es menor que 0.5, entonces predice que y_hat es igual a 0. Vimos este umbral también cuando aprendiste sobre regresión logística en el primer curso de la especialización. Si lo deseas, esto te da la predicción final $\\hat{y}$ como uno o cero, si no quieres sólo la probabilidad de que sea un vendedor superior. \n",
    "\n",
    "Así es como funciona una red neuronal. Cada capa introduce un vector de números y aplica un montón de unidades de regresión logística a ella, y luego calcula otro vector de números que luego se pasa de capa a capa hasta llegar a la computación final de las capas de salida, que es la predicción de la red neuronal. Entonces se puede poner un umbral de 0,5 o no para llegar a la predicción final. Con esto, vamos a utilizar esta base que hemos construido ahora para ver algunos modelos de redes neuronales aún más complejos, aún más grandes. Espero que, al ver más ejemplos, este concepto de capas y cómo juntarlas para construir una red neuronal sea aún más claro. Así que pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex neural networks\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1tayIgwZkp2AHNpWZCUnaYPQBvpLcywVd/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, aprendiste sobre la capa de la red neuronal y cómo ésta toma como entrada un vector de números y, a su vez, da como salida otro vector de números. En este vídeo, vamos a utilizar esa capa para construir una red neuronal más compleja. A través de esto, espero que la notación que estamos utilizando para las redes neuronales será más clara y más concreta también. Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_25.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Este es el ejemplo que voy a utilizar a lo largo de este vídeo como ejemplo de una red neuronal más compleja. Esta red tiene cuatro capas, sin contar la capa de entrada, que también se llama capa 0, donde las capas 1, 2 y 3 son capas ocultas, y la capa 4 es la capa de salida, y la capa 0, como siempre, es la capa de entrada. Por convención, cuando decimos que una red neuronal tiene cuatro capas, eso incluye todas las capas ocultas en la capa de salida, pero no contamos la capa de entrada. Esta es una red neuronal con cuatro capas en la forma convencional de contar las capas de la red. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_26.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Acerquémonos a la capa 3, que es la tercera y última capa oculta para ver los cálculos de esa capa. La capa 3 introduce un vector, un corchete cuadrado superíndice 2 que fue calculado por la capa anterior, y emite $a_{[3]}$, que es otro vector. ¿Cuál es el cálculo que hace la capa 3 para pasar de $a^{[2]}$ a $a^{[3]}$? Si tiene tres neuronas o las llamamos tres unidades ocultas, entonces tiene los parámetros $w_1$, $b_1$, $w_2$, $b_2$, y $w_3$, $b_3$ y calcula $a_1$ igual a la sigmoidea de $w_1$. producto con esta entrada a la capa más $b_1$, y calcula $a_2$ igual a la sigmoidea de $w_2$, producto con otra vez $a_2$, la entrada a la capa más $b_2$ y así sucesivamente para obtener $a_3$. Entonces la salida de esta capa es un vector que comprende $a_1$, $a_2$ y $a_3$. De nuevo, por convención, si queremos denotar más explícitamente que todas estas son cantidades asociadas con la Capa 3, entonces añadimos en todos estos superíndices, corchetes 3 aquí, para denotar que estos parámetros $w$ y $b$ son los parámetros asociados con las neuronas en la Capa 3 y que estas activaciones son activaciones con la Capa 3. Observe que este término aquí es $w_1^{[3]}$, lo que significa que los parámetros asociados con la Capa 3 producto con un superíndice [2], que fue la salida de la Capa 2, que se convirtió en la entrada a la Capa 3. Es por eso que tiene $a_3$ aquí porque es un parámetro asociado de la Capa 3, producto con $a_2$ allí porque es la salida de la Capa 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_27.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, vamos a hacer una rápida doble comprobación en nuestra comprensión de esto. Voy a ocultar los superíndices y subíndices asociados a la segunda neurona y sin rebobinar este vídeo, sigue adelante y rebobina si quieres, pero prefiero que no. Pero sin rebobinar este vídeo, ¿eres capaz de pensar cuáles son los superíndices y subíndices que faltan en esta ecuación y rellenarlos tú mismo? Una vez que eches un vistazo al cuestionario del vídeo final y veas si puedes averiguar cuáles son los superíndices y subíndices apropiados para esta ecuación de aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "¿Puedes completar los superíndices y subíndices de la segunda neurona?\n",
    "\n",
    "- $a^{[3]}_{2}=g(\\vec{w}^{[3]}_{2} \\cdot \\vec{a}^{[2]} + b^{[3]}_{2})$ \n",
    "- $a^{[3]}_{2}=g(\\vec{w}^{[3]}_{2} \\cdot \\vec{a}^{[3]} + b^{[3]}_{2})$ \n",
    "- $a^{[3]}_{2}=g(\\vec{w}^{[3]}_{2} \\cdot a^{[2]} + b^{[3]}_{2})$\n",
    " \n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: $a^{[3]}_{2}=g(\\vec{w}^{[3]}_{2} \\cdot \\vec{a}^{[2]} + b^{[3]}_{2})$.\n",
    "\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para recapitular, $a^{[3]}$ es la activación asociada a la capa 3 para la segunda neurona, por lo que este $a_2$ es un parámetro asociado a la tercera capa. Para la segunda neurona, esto es $a^{[2]}$, igual que arriba y luego más $b^{[3]}$ también. Espero que esto tenga sentido. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_28.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Sólo la forma más general de esta ecuación para una capa arbitraria 0 y para una unidad arbitraria $j$, que es que una desactivación salidas de la capa $l$, la unidad $j$, como $a^{[32]}$, que va a ser la función sigmoide aplicada a este término, que es el vector de onda de la capa $l$, como la capa 3 para la unidad $j^{th}$ así que hay $a^{[2]}$ de nuevo, en el ejemplo anterior, y por lo que es punto-producto con un valor de desactivación. Fíjate, esto no es $l$, es $l-1$, como $a^{[2]}$ aquí arriba porque estás produciendo por puntos con la salida de la capa anterior y luego más b, el parámetro para esta capa para esa unidad $j$. Esto te da la activación de la unidad $j$ de la capa $l$, donde el superíndice entre corchetes $l$ denota la capa $l$ y un subíndice $j$ denota la unidad $j$. Cuando se construyen redes neuronales, la unidad $j$ se refiere a la neurona $j$, así que usamos esos términos un poco indistintamente donde cada unidad es una sola neurona en la capa. $G$ es aquí la función sigmoidea. En el contexto de una red neuronal, $g$ tiene otro nombre, que también se llama la **función de activación**, porque $g$ produce este valor de activación. Cuando digo función de activación, me refiero a esta función g aquí. Hasta ahora, la única función de activación que has visto, es una función sigmoidea, pero la próxima semana, vamos a ver cuando otras funciones, entonces la función sigmoidea se puede enchufar en lugar de g también. La función de activación es sólo la función que produce estos valores de activación. \n",
    "\n",
    "Sólo una última pieza de notación. Para hacer toda esta notación consistente, también voy a dar al vector de entrada $X$ y otro nombre que es $a^{[0]}$, así que de esta manera, la misma ecuación también funciona para la primera capa, donde cuando $l=a^{[1]}$, las activaciones de la primera capa, es decir $a^{[1]}$, sería la sigmoide por el producto punto de los pesos con $a^[0]$, que es sólo este vector de características de entrada $X$. Con esta notación, ahora sabes cómo calcular los valores de activación de cualquier capa en una red neuronal como una función de los parámetros, así como las activaciones de la capa anterior. \n",
    "\n",
    "Ahora sabes cómo calcular las activaciones de cualquier capa dadas las activaciones de la capa anterior. Pongamos esto en un algoritmo de inferencia para una red neuronal. En otras palabras, cómo conseguir que una red neuronal haga predicciones. Vamos a ver eso en el siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: making predictions (forward propagation)\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1Cn6yxXHGUtc39x1SAC7OSxhTl_0gl1ZX/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tomar lo que hemos aprendido y a juntarlo en un algoritmo para que tu red neuronal haga inferencias o predicciones. Este será un algoritmo llamado propagación hacia adelante. Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_30.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Voy a utilizar como ejemplo motivador, el reconocimiento de dígitos escritos a mano. Y para simplificar, sólo vamos a distinguir entre los dígitos manuscritos cero y uno. Se trata de un problema de clasificación binaria en el que vamos a introducir una imagen y clasificar, ¿es este el dígito cero o el dígito uno? Y podrás jugar con esto tú mismo más tarde esta semana en el laboratorio de prácticas también. Para el ejemplo de la diapositiva, voy a utilizar una imagen de ocho por ocho. Y así esta imagen de un uno es esta cuadrícula o matriz de ocho por ocho o 64 valores de intensidad de píxeles donde 255 denota un píxel blanco brillante y cero denotaría un píxel negro. Y diferentes números son diferentes tonos de gris entre los tonos de blanco y negro. Dadas estas 64 características de entrada, vamos a utilizar la red neuronal con dos capas ocultas. Donde la primera capa oculta tiene 25 neuronas o 25 unidades. La segunda capa oculta tiene 15 neuronas o 15 unidades. Y finalmente la capa de salida o unidad de salida, ¿cuál es la probabilidad de que sea 1 frente a 0?. Así que vamos a pasar por la secuencia de cálculos que en su red neuronal tendrá que hacer para ir de la entrada $X$, este ocho por ocho o 64 números a la probabilidad predicha $a^{[3]}$. \n",
    "\n",
    "El primer cálculo es ir de $X$ a $a^{[1]}$, y eso es lo que hace la primera capa de la primera capa oculta. Lleva a cabo un cálculo de un superíndice [1] es igual a esta fórmula de la derecha. Observa que $a^{[1]}$ tiene 25 números porque esta capa oculta tiene 25 unidades. Por eso los parámetros van de $w_1$ a $w_25$ así como de $b_1$ a $b_{25}$. Y he escrito $x$ aquí pero también podría haber escrito $a^{[0]}$ aquí porque por convención la activación de la capa cero, es decir $a^{[0]}$ es igual al valor de la característica de entrada $x$. Así que vamos a calcular $a^{[1]}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_31.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "El siguiente paso es calcular $a^{[2]}$. Mirando la segunda capa oculta, entonces lleva a cabo esta computación donde $a^{[2]}$ es una función de $a^{[1]}$ y se computa como la función de activación de punto seguro aplicada a $w$ producto de punto $a^{[1]}$ más el valor correspondiente de $b$. Observe que la capa dos tiene 15 neuronas o 15 unidades, por lo que los parámetros aquí van de $w_1$ a $w_{15}$ y $b_1$ a $b_{15}$. Ahora hemos calculado $a^{[2]}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_32.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "El paso final es entonces calcular $a^{[3]}$ y lo hacemos usando un cálculo muy similar. Sólo que ahora, esta tercera capa, la capa de salida tiene sólo una unidad, por lo que sólo hay una salida aquí. Así que $a^{[3]}$ es sólo un escalar. Y finalmente puedes tomar opcionalmente el subíndice uno de $a^{[3]}$ y ponerle un umbral de 4,5 para obtener una etiqueta de clasificación binaria. ¿Es este el dígito 1? ¿Si o no?.\n",
    "\n",
    "Así que la secuencia de cálculos primero toma x y luego calcula $a^{[1]}$, y luego calcula $a^{[2]}$, y luego calcula $a^{[3]}$, que es también la salida de las redes neuronales. También puedes escribirlo como $f(x)$. Así que recuerda cuando aprendimos sobre la regresión lineal y la regresión logística, usamos $f(x)$ para denotar la salida de la regresión lineal o la regresión logística. Así que también podemos usar $f(x)$ para denotar la función computada por la red neuronal en función de $x$. Como este cómputo va de izquierda a derecha, se empieza por $X$ y se computa $a^{[1]}$, luego $a^{[2]}$, luego $a^{[3]}$. Este disco también se llama propagación hacia adelante (forward propagation) porque estás propagando las activaciones de las neuronas. Así que estás haciendo estos cálculos en las cuatro direcciones de izquierda a derecha. Y esto es en contraste con un algoritmo diferente llamado propagación hacia atrás o back propagation, que se utiliza para el aprendizaje. Y eso es algo que aprenderás la próxima semana. \n",
    "\n",
    "Y, por cierto, este tipo de arquitectura de red neuronal donde tienes más unidades ocultas inicialmente y luego el número de unidades ocultas disminuye a medida que te acercas a la capa de salida. También hay una opción bastante típica a la hora de elegir arquitecturas de redes neuronales. Y verás más ejemplos de esto en el laboratorio de prácticas también. \n",
    "\n",
    "Así que esa es la inferencia de la red neuronal usando el algoritmo de propagación hacia adelante. Y con esto, serías capaz de descargar los parámetros de una red neuronal que alguien ha entrenado y publicado en Internet. Y serías capaz de llevar a cabo la inferencia en tus nuevos datos utilizando su red neuronal. Ahora que has visto las matemáticas y el algoritmo, vamos a echar un vistazo a cómo puedes implementar esto en tensorflow. En concreto, vamos a echar un vistazo a esto en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "Para una red neuronal, ésta es la fórmula para calcular la activación de la tercera neurona de la capa 2, dado el vector de activación de la capa 1: $a^{[2]}_{3}=g(\\vec{w}^{[2]}_{3} \\cdot \\vec{a}^{[1]} + b^{[2]}_{3})$ . ¿Cuál de las siguientes afirmaciones es correcta?\n",
    "\n",
    "- La activación de la capa 2 se determina utilizando las activaciones de la capa anterior.\n",
    "- La activación de la unidad 3 (neurona 3) de la capa 2 se calcula utilizando un vector de parámetros $\\vec{w}$ y $b$ que son específicos de la unidad 3 (neurona 3).\n",
    "- La unidad 3 (neurona 3) produce un único número (un escalar).\n",
    "- Si usted está calculando la activación para la capa 1, entonces las activaciones de la capa anterior se denotaría por $\\vec{a}^{[1]}$.\n",
    "\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Para la clasificación binaria para el reconocimiento de la escritura a mano, discutida en la conferencia, ¿cuál de las siguientes afirmaciones es correcta?\n",
    "- Hay una sola unidad (neurona) en la capa de salida.\n",
    "- La salida del modelo puede interpretarse como la probabilidad de que la imagen manuscrita sea del número uno \"1\".\n",
    "- Tras elegir un umbral, se puede convertir la salida de la red neuronal en una categoría de 0 o 1.\n",
    "- La red neuronal no puede ser diseñada para predecir si una imagen manuscrita es 8 o 9.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "Para una red neuronal, ¿cuál es la expresión para calcular la activación de la tercera neurona de la capa 2? Ten en cuenta que esta pregunta es diferente a la que has visto en el vídeo de la conferencia.\n",
    "\n",
    "- $a^{[2]}_{3}=g( \\vec{w}^{[3]}_{2} \\cdot \\vec{a}^{[1]} + b^{3}_{2} )$ \n",
    "- $a^{[2]}_{3}=g( \\vec{w}^{[2]}_{3} \\cdot \\vec{a}^{[2]} + b^{2}_{3} )$ \n",
    "- $a^{[2]}_{3}=g( \\vec{w}^{[2]}_{3} \\cdot \\vec{a}^{[1]} + b^{2}_{3} )$ \n",
    "- $a^{[2]}_{3}=g( \\vec{w}^{[3]}_{2} \\cdot \\vec{a}^{[2]} + b^{3}_{2} )$ \n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 4 </b></font>\n",
    "\n",
    "Para la tarea de reconocimiento de la escritura a mano comentada en la clase, ¿cuál es la salida?\n",
    "\n",
    "- Un vector de varios números que toman valores entre 0 y 1.\n",
    "- La probabilidad estimada de que la imagen de entrada sea de un número 1, un número que va de 0 a 1.\n",
    "- Un vector de varios números, cada uno de los cuales es exactamente 0 o 1.\n",
    "- Un número que es exactamente 0 o 1, que comprende la predicción de la red.\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1:\n",
    "    \n",
    "- La activación de la capa 2 se determina utilizando las activaciones de la capa anterior.\n",
    "- La activación de la unidad 3 (neurona 3) de la capa 2 se calcula utilizando un vector de parámetros $\\vec{w}$ y $b$ que son específicos de la unidad 3 (neurona 3).\n",
    "- La unidad 3 (neurona 3) produce un único número (un escalar).\n",
    "\n",
    "Respuesta 2:\n",
    "    \n",
    "- Hay una sola unidad (neurona) en la capa de salida.\n",
    "- La salida del modelo puede interpretarse como la probabilidad de que la imagen manuscrita sea del número uno \"1\".\n",
    "  \n",
    "Respuesta 3: $a^{[2]}_{3}=g( \\vec{w}^{[2]}_{3} \\cdot \\vec{a}^{[1]} + b^{2}_{3} )$ .\n",
    "    \n",
    "Respuesta 4: La probabilidad estimada de que la imagen de entrada sea de un número 1, un número que va de 0 a 1.\n",
    "    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORFLOW IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference in Code\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1RmRHu8SF2vR3VZIjM-TBm2lRzgjoAogZ/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow es uno de los principales marcos para implementar algoritmos de aprendizaje profundo. Cuando estoy construyendo proyectos, TensorFlow es en realidad una herramienta que uso con más frecuencia. La otra herramienta popular es PyTorch. Pero vamos a centrarnos en esta especialización en TensorFlow. En este video, vamos a echar un vistazo a cómo se puede implementar código de inferencia utilizando TensorFlow. Vamos a sumergirnos. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_34.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Una de las cosas notables de las redes neuronales es que el mismo algoritmo puede aplicarse a tantas aplicaciones diferentes. Para este vídeo y en algunos de los laboratorios para que veas lo que hace la red neuronal, voy a utilizar otro ejemplo para ilustrar la inferencia. A veces me gusta tostar granos de café yo mismo en casa. Mi favorito son los granos de café de Colombia. ¿Puede el algoritmo de aprendizaje ayudar a optimizar la calidad de los granos que se obtienen en un proceso de tostado como éste? Cuando se tuesta el café, hay dos parámetros que se pueden controlar: la temperatura a la que se calientan los granos de café crudos para convertirlos en granos de café bien tostados, y la duración o el tiempo que se van a tostar los granos. \n",
    "\n",
    "En este ejemplo ligeramente simplificado, hemos creado los conjuntos de datos de diferentes temperaturas y diferentes duraciones, así como las etiquetas que muestran si el café que has tostado tiene buen sabor. En este caso, la cruz positiva e igual a 1 corresponde a un buen café, y toda la cruz negativa corresponde a un mal café. Parece que una forma razonable de pensar en este conjunto de datos es que si lo cocinas a una temperatura demasiado baja, no se tuesta y acaba estando poco hecho. Si lo cocinas, no durante el tiempo suficiente, la duración es demasiado corta, tampoco es un conjunto de granos bien tostados. Por último, si lo cocinas durante demasiado tiempo o a una temperatura demasiado alta, entonces acabas teniendo alubias demasiado cocidas. Son granos un poco quemados. Tampoco hay un buen café. Sólo los puntos dentro de este pequeño triángulo de aquí corresponden a un buen café. Este ejemplo está simplificado un poco del tueste real del café. Aunque este ejemplo es una simplificación con fines ilustrativos, en realidad ha habido proyectos serios que utilizan el aprendizaje automático para optimizar el tostado de café también. La tarea es dar un vector de características x con la temperatura y la duración, digamos 200 grados centígrados durante 17 minutos, ¿cómo podemos hacer inferencia en una red neuronal para que nos diga si este ajuste de temperatura y duración dará como resultado un buen café o no? Es así. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_35.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a establecer que $x$ sea un array de dos números. La entrada tiene 200 grados centígrados y 17 minutos. Esto aquí, Capa 1 es igual a unidades densas 3 activación es igual a sigmoide crea una capa oculta de neuronas con tres unidades ocultas, y utilizando como la función de activación, la función sigmoide, y denso aquí es sólo el nombre de esta capa. Entonces, finalmente, para calcular los valores de activación $a^{[1]}$, escribirías a1 es igual a la Capa 1 aplicada a las características de entrada $x$. Entonces creas la Capa 1 como esta primera capa oculta, la red neuronal, como unidades densas de paréntesis abierto 3, eso significa tres unidades o tres unidades ocultas en esta capa usando como función de activación, la función sigmoide. Dense es otro nombre para las capas de una red neuronal que hemos aprendido hasta ahora. A medida que se aprende más sobre las redes neuronales, se aprende también sobre otros tipos de capas. Pero por ahora, sólo usaremos la capa densa, que es el tipo de capa que has aprendido en los últimos videos para todos nuestros ejemplos. A continuación, se calcula $a_1$ tomando la Capa 1, que es en realidad una función, y aplicando esta función Capa 1 a los valores de $x$. Así es como se obtiene $a_1$, que va a ser una lista de tres números porque la Capa 1 tenía tres unidades. Así que a1 aquí puede, sólo por el bien de la ilustración, ser 0,2, 0,7, 0,3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_37.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "A continuación, para la segunda capa oculta, la capa 2, sería densa. Ahora esta vez tiene una unidad y de nuevo a la función de activación sigmoide, y entonces usted puede calcular a2 mediante la aplicación de esta función de la capa 2 a los valores de activación de la capa 1 a $a_1$. Eso le dará el valor de $a_2$, que por el bien de la ilustración es tal vez 0,8. Por último, si desea el umbral en 0,5, entonces usted puede simplemente probar si $a_2$ es mayor e igual a 0,5 y establecer $\\hat{y}$ igual a uno o cero cruz positiva o negativa en consecuencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así es como se hace la inferencia en la red neuronal usando TensorFlow. Hay algunos detalles adicionales que no repasé aquí, como por ejemplo cómo cargar la biblioteca TensorFlow y cómo cargar también los parámetros $w$ y $b$ de la red neuronal. Pero eso lo veremos en el laboratorio. Por favor, asegúrese de echar un vistazo al laboratorio. Pero estos son los pasos clave para la propagación en la forma de calcular $a_1$ y $a_2$ y opcionalmente el umbral $a_2$. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_41.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos un ejemplo más y vamos a volver al problema de clasificación de dígitos escritos a mano. En este ejemplo, $x$ es una lista de los valores de intensidad de los píxeles. Así que $x$ es igual a un array numpy de esta lista de valores de intensidad de los píxeles. Entonces para inicializar y llevar a cabo un paso de la propagación hacia adelante, la Capa 1 es una capa densa con 25 unidades y la función de activación sigmoide. Entonces se computa $a_1$ como la función de la Capa 1 aplicada a $x$. Para construir y llevar a cabo la inferencia a través de la segunda capa, de forma similar, se configura la Capa 2 como sigue, y entonces se computa $a_2$ como la Capa 2 aplicada a $a_1$. Luego, finalmente, la Capa 3 es la tercera y última capa densa. Entonces, finalmente, usted puede opcionalmente umbral $a_3$ para llegar a una predicción binaria para $\\hat{y}$. \n",
    "\n",
    "Esa es la sintaxis para llevar a cabo la interferencia en TensorFlow. Una cosa a la que aludí brevemente es la estructura de los arrays de numpy. TensorFlow trata los datos de una manera determinada que es importante entender. En el siguiente video, vamos a echar un vistazo a cómo TensorFlow maneja los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in TensorFlow\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1lLujyEP9sstbOo9iltKG8l0FVcpKCQgq/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este vídeo, quiero explicar cómo se representan los datos en NumPy y en TensorFlow. Para que cuando implementes nuevas redes neuronales, puedas tener un marco consistente para pensar en cómo representar tus datos. Una de las cosas desafortunadas sobre la forma en que se hacen las cosas en el código hoy en día es que hace muchos, muchos años NumPy fue creado por primera vez y se convirtió en una biblioteca estándar para el álgebra lineal y Python. Y luego, mucho más tarde, el equipo Google Brain, el equipo que yo había comenzado y que una vez dirigí, creó TensorFlow. Y así, por desgracia, hay algunas inconsistencias entre cómo se representan los datos en NumPy y en TensorFlow. Así que es bueno ser consciente de estas convenciones para que puedas implementar el código correcto y, con suerte, conseguir que las cosas funcionen en tus redes neuronales. Empecemos por echar un vistazo a cómo TensorFlow representa los datos. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_43.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos que tienes un conjunto de datos como el del ejemplo del café. He mencionado que escribirías x de la siguiente manera. Entonces, ¿por qué tienes este doble corchete aquí? Echemos un vistazo a cómo NumPy almacena vectores y matrices. En caso de que pienses que las matrices y los vectores son conceptos matemáticos complicados, no te preocupes. Vamos a ver unos cuantos ejemplos concretos y podrás hacer todo lo que necesites con matrices y vectores para implementar tus redes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_44.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Empecemos con un ejemplo de matriz. Aquí tenemos una matriz con 2 filas y 3 columnas. Observa que hay una, dos filas y 1, 2, 3 columnas. Así que llamamos a esto una matriz de 2 x 3. Y así la convención es la dimensión de la matriz se escribe como el número de filas por el número de columnas. Así que en el código para almacenar esta matriz, esta matriz de 2 x 3, sólo tienes que escribir x = np.array de estos números como estos. Donde notas que el corchete te dice que 1, 2, 3 es la primera fila de esta matriz y 4, 5, 6 es la segunda fila de esta matriz. Y luego este corchete abierto agrupa la primera y la segunda fila. Así que esto establece x para ser esto a la matriz de números. Así que la matriz es sólo una matriz 2D de números.\n",
    "\n",
    "Veamos un ejemplo más, aquí he escrito otra matriz. ¿Cuántas filas y cuántas columnas tiene esta? Bueno, puedes contar esto como una, dos, tres, cuatro filas y tiene una, dos columnas. Así que esta es una matriz de número de filas por el número de columnas, por lo que es una matriz de 4 x 2. Y para almacenar esto en el código, escribirás x igual a np.array y luego esta sintaxis aquí para almacenar estas cuatro filas de la matriz en la variable x. Así que esto crea una matriz 2D de estos ocho números. Las matrices pueden tener diferentes dimensiones. Viste un ejemplo de una matriz de 2 x 3 y la matriz de 4 x 2. Una matriz también puede tener otras dimensiones como 1 x 2 o 2 x 1. Y veremos ejemplos de estas en la siguiente diapositiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_45.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que lo que hicimos anteriormente al establecer x para ser vectores de características de entrada, fue establecer x para ser igual a np.array con dos corchetes, 200, 17. Y lo que hace es que esto crea una matriz de 1 x 2, que es sólo una fila y dos columnas. Veamos un ejemplo diferente (segundo ejemplo), si usted fuera a definir x para ser np.array pero ahora escrito como esto, esto crea una matriz de 2 x 1 que tiene dos filas y una columna. Porque la primera fila es sólo el número 200 y la segunda fila, es sólo el número 17. Y así esto tiene los mismos números pero en una matriz de 2 x 1 en lugar de 1 x 2. Ya que este ejemplo en la parte superior también se llama un vector de fila, es un vector que es sólo una sola fila. Y este ejemplo (segundo ejemplo) también se llama un vector columna porque este vector que sólo tiene una sola columna. \n",
    "\n",
    "Y la diferencia entre el uso de corchetes dobles como este frente a un corchete simple como este (tercer ejemplo), es que mientras que los dos ejemplos en la parte superior de las matrices 2D donde una de las dimensiones pasa a ser 1. Este ejemplo da como resultado un vector 1D. Así que esto es sólo un array 1D que no tiene filas ni columnas, aunque por convención podemos enderezar $x$ como una columna como esta. Así que en un contraste esto con lo que habíamos hecho anteriormente en el primer curso, que era escribir $x$ como este con un solo corchete. Y eso resultó en lo que se llama en Python, un vector 1D en lugar de una matriz 2D. Y esto técnicamente no es 1 x 2 o 2 x 1, es sólo una matriz lineal sin filas o sin columnas, pero es sólo una lista de números. \n",
    "\n",
    "Así que donde está en el curso uno cuando estamos trabajando con la regresión lineal y la regresión logística, utilizamos estos vectores 1D para representar las características de entrada $x$. Con TensorFlow la convención es utilizar matrices para representar los datos. ¿Y por qué este cambio de convenciones? Bueno, resulta que TensorFlow fue diseñado para manejar conjuntos de datos muy grandes y al representar los datos en matrices en lugar de matrices 1D, permite que TensorFlow sea un poco más eficiente computacionalmente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_46.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que, volviendo a nuestro ejemplo original para el primer entrenamiento, el ejemplo en este conjunto de datos con las características 200°C en 17 minutos, se representó así. Y esto es en realidad una matriz de 1 x 2 que resulta tener una fila y dos columnas para almacenar los números 200, 17. Y en caso de que esto parezca un montón de detalles y convenciones realmente complicadas, no te preocupes, todo esto se aclarará. Y podrás ver las implementaciones concretas del código por ti mismo en los laboratorios opcionales y en los laboratorios de práctica. \n",
    "\n",
    "Volviendo al código para llevar a cabo la propagación o influencia en la red neuronal. Cuando se calcula que a1 es igual a la capa 1 aplicada a $x$, ¿qué es $a_1$? Bueno, $a_1$ en realidad va a ser porque los tres números, en realidad va a ser una matriz de 1 x 3. Y si usted imprime $a_1$ obtendrá algo así como esto es tf.tensor 0,2, 0,7, 0,3 como una forma de 1 x 3, 1, 3 se refiere a que esto es una matriz de 1 x 3. Y esta es la forma que tiene TensorFlow de decir que este es un número de punto flotante, lo que significa que es un número que puede tener un punto decimal representado usando 32 bits de memoria en tu ordenador, ahí es donde está el float 32. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_47.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "¿Y qué es el tensor? Un tensor es un tipo de datos que el equipo de TensorFlow ha creado para almacenar y realizar cálculos sobre matrices de manera eficiente. Así que siempre que veas un tensor piensa en la matriz de estas diapositivas. Técnicamente un tensor es un poco más general que la matriz, pero para los propósitos de este curso, piensa en el tensor como una forma de representar matrices. Así que recuerda que dije al principio de este video que hay la forma TensorFlow de representar la matriz y la forma NumPy de representar la matriz. Esto es un artefacto de la historia de cómo NumPy y TensorFlow fueron creados y desafortunadamente hay dos formas de representar una matriz que han sido horneadas en estos sistemas. Y de hecho si quieres tomar a1 que es un tensor y quieres convertirlo de nuevo en una matriz NumPy, puedes hacerlo con esta función a1.numpy. Y tomará los mismos datos y los devolverá en forma de array NumPy en lugar de en forma de array TensorFlow o matriz TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_48.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora vamos a echar un vistazo a lo que la salida de las activaciones de la segunda capa se vería. Aquí está el código que teníamos antes, la capa 2 es una capa densa con una unidad y activación sigmoidea y a2 se calcula tomando la capa 2 y aplicándola a $a_1$ así que ¿qué es $a_2$? $a_2$, tal vez un número como 0,8 y técnicamente esto es una matriz 1 x 1 es una matriz 2D con una fila y una columna y por lo que es igual a este número 0,8. Y si imprimes $a_2$, ves que es un tensor TensorFlow con un solo elemento un número 0.8 y es una matriz 1 x 1. Y de nuevo es un float32, número de puntos decimales que ocupa 32 bits en la memoria del ordenador. Una vez más se puede convertir de un tensor de tensorflow a una matriz de NumPy usando a2.numpy y eso convertirá esto de nuevo en una matriz de NumPy que se parece a esto. \n",
    "\n",
    "Así que espero que te dé una idea de cómo se representan los datos en TensorFlow y en NumPy. Estoy acostumbrado a cargar datos y manipular datos en NumPy, pero cuando pasas un array de NumPy a TensorFlow, a TensorFlow le gusta convertirlo a su propio formato interno. El tensor y entonces operar eficientemente usando tensores. Y cuando lees los datos de vuelta puedes mantenerlos como un tensor o convertirlos de nuevo a un array de NumPy. Creo que es un poco desafortunado que la historia de cómo evolucionaron estas bibliotecas nos haya dejado hacer este trabajo extra de conversión cuando en realidad las dos bibliotecas pueden trabajar bastante bien juntas. Pero cuando conviertes de un lado a otro, ya sea que estés usando un arreglo de NumPy o un tensor, es algo que debes tener en cuenta cuando estés escribiendo código. A continuación, vamos a tomar lo que hemos aprendido y ponerlo juntos para construir una red neuronal. Vamos a ver eso en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a neural network\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1dWoKZbc0Wc4C4ZYcX2LNOV0Fxj_uHBgN/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que usted ha visto un montón de código de flujo tensorial por ahora aprendido acerca de cómo construir una capa en el Tensorflow, cómo hacer forward prop a través de una sola capa en el Tensorflow. Y también has aprendido sobre el flujo intensivo de datos. Vamos a poner todo junto y hablar de cómo construir una red neuronal cargas intensivas. Este es también el último video sobre el Tensorflow para esta semana. Y en este video también se aprende sobre una forma diferente de construir una red neuronal, que será incluso un poco más simple que lo que has visto hasta ahora. Así que vamos a bucear.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_50.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Lo que viste anteriormente fue que, si quieres hacer propagación hacia adelante, inicializar los datos $x$ crear capa uno entonces calcular $a_1$, luego crear capa dos y calcular $a_2$. Así que esta era una forma explícita de llevar a cabo el problema de avance una capa de cálculo a la vez. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_51.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Resulta que el Tensorflow tiene una forma diferente de implementar el forward prop así como el aprendizaje. Permítanme mostrarles una forma diferente de construir en Tensorflow una red neuronal, que es que lo mismo que antes. Vas a crear la capa uno y crear la capa dos. Pero ahora en lugar de tomar manualmente los datos y pasarlos a la capa uno y luego tomar las activaciones de la capa uno y posiblemente la capa dos. En lugar de eso, podemos decirle al Tensorflow que nos gustaría que tomara la capa uno y la capa dos y las encadenara para formar una red neuronal. Eso es lo que hace la función secuencial de Tensorflow que dice, por favor crea una red neuronal para mí por la cadena secuencial juntos estas dos capas que acabo de crear. Resulta que con el marco secuencial el Tensorflow puede hacer mucho trabajo por ti. Digamos que tienes un conjunto de entrenamiento como este de la izquierda. Esto es para el ejemplo del café. Entonces puedes tomar los datos de entrenamiento como entradas $x$ y ponerlos en una matriz numpy. Esto aquí es una matriz de cuatro por dos y las etiquetas de destino. Y puede entonces escribirse como sigue. Y esto es sólo una matriz de cuatro dimensiones. Y este conjunto de objetivos puede ser almacenado como un array de una T como este 1001 que corresponde a cuatro ejemplos de entrenamiento. Y resulta que, dados los datos, $x$ e $y$ almacenados en esta matriz $x$ y este array, $y$, si quieres entrenar esta red neuronal, todo lo que necesitas hacer es llamar a las funciones que necesitas para llamar al punto de compilación del modelo con algunos parámetros. Hablaremos más de esto la próxima semana, así que no te preocupes por ahora. Y luego tienes que llamar a model.fit(x, y), que le dice al Tensorflow que tome esta red neuronal que se crea por la cadena secuencial de las capas uno y dos, y que la entrene en los datos, $x$ e $y$. Pero vamos a aprender cómo, pero vamos a aprender los detalles de cómo hacer esto la próxima semana. \n",
    "\n",
    "Y, finalmente, ¿cómo hacer la influencia en esta red neuronal? ¿Cómo se hace la propagación? Si tenemos un nuevo ejemplo, digamos $x$ nuevo, que es una matriz numpy con estas dos características, en lugar de tener que hacerlo una capa a la vez, sólo tenemos que llamar al modelo de predicción en $x$ nuevo y esto producirá el valor correspondiente de un dos para ti dado este valor de entrada de $x$. Así que el modelo de predicción lleva a cabo la propagación y lleva una influencia para ti, utilizando esta nueva red que has compilado utilizando la función secuencial. Ahora quiero tomar estas tres líneas de código en la parte superior y sólo simplificar un poco más, que es cuando la codificación de Tensorflow. Por convención no asignamos explícitamente las dos capas a dos variables, la capa uno y la capa dos como sigue. Pero por convención normalmente sólo escribiría un código como este, cuando decimos que el modelo es un modelo secuencial de algunas capas encadenadas. Secuencialmente donde la primera capa uno es una capa densa con tres unidades y activación de sigmoide y la segunda capa, es una capa densa con una unidad y de nuevo una función de activación sigmoide. Así que, si usted mira el código de Tensorflow de otros, a menudo se ve más como esto en lugar de tener una asignación explícita a estas variables de la capa uno y la capa dos. Y eso es todo. Este es más o menos el código que necesitas para entrenar así como para influir en Tensorflow para una red neuronal. Donde de nuevo hablaremos más sobre los bits de entrenamiento de estos dos combinados el compilador y la función de ajuste la próxima semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_53.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a rehacer esto para el ejemplo de clasificación de dígitos también. Así que previamente tuvimos $x$, en esta capa de entrada uno es una capa a uno es igual. Quieren aplicar a $x$ y así sucesivamente a través de la capa dos y la capa tres con el fin de tratar de clasificar un dígito, con esta nueva convención de codificación con el uso de la función secuencial de flujo de tensor, puede en cambio especificar lo que son la capa uno, la capa dos, la capa tres y decirle al flujo de tensor que encadene las capas para usted en una nueva red y lo mismo que antes. A continuación, puede almacenar los datos en la matriz y ejecutar la función de compilación y ajustar el modelo de la siguiente manera. De nuevo, más sobre esto la próxima semana. \n",
    "\n",
    "Por último, para hacer inferencia o para hacer predicciones se puede utilizar el model.predict en $x$ nuevo y similar a lo que se vio antes con la red de clasificación de café por la convención, en lugar de asignar la capa uno, capa dos, capa tres, explícitamente como este, que sería más común sólo tomar estas capas y ponerlas directamente en la función secuencial. Así que terminas con este código más compacto que sólo le dice al Tensorflow, crea un modelo para mí que encadena secuencialmente estas tres capas y luego el resto del código funciona igual que antes. \n",
    "\n",
    "Así es como has construido una red neuronal en Tensorflow. Ahora sé que cuando estás aprendiendo sobre estas técnicas, a veces alguien puede pedirte que implementes estas cinco líneas de código y entonces escribes cinco líneas de código y luego alguien dice \"felicidades\" con sólo cinco líneas de código. Construiste esta complicada red neuronal de última generación y a veces eso te hace preguntarte, ¿qué hice exactamente con sólo estas cinco líneas de código? Una de las cosas que quiero que te lleves de la especialización en aprendizaje automático es la capacidad de utilizar librerías de vanguardia, como TensorFlow, para hacer tu trabajo de forma eficiente. Pero realmente no quiero que solo llames a cinco líneas de código y no sepas realmente lo que el código está haciendo debajo del capó. Así que en el próximo video te dejaré volver y compartir contigo cómo puedes implementar desde cero por ti mismo. Para la propagación en python, para que pueda entender todo el asunto por sí mismo en la práctica. La mayoría de los ingenieros de aprendizaje de la máquina en realidad no implementan para un problema en python que a menudo sólo usamos bibliotecas como el Tensorflow y Pythorch, pero porque quiero que usted entienda cómo funcionan estos algoritmos por sí mismo para que si algo va mal, usted puede pensar por sí mismo, lo que podría necesitar para cambiar era probable que funcione era menos probable que funcione. También vamos a ir a través de lo que se necesitaría para que usted pueda implementar para la propagación de cero porque de esa manera, incluso cuando usted está llamando a una biblioteca y tener que ejecutar de manera eficiente y hacer grandes cosas en su aplicación, quiero que en la parte posterior de su mente para tener también que una comprensión más profunda de lo que su código está haciendo realmente, por lo que vamos a ir al siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: TensorFlow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "Para el siguiente código\n",
    "```python\n",
    "modelo = Secuencial([\n",
    "    Dense(unidades=25, activación=\"sigmoide\"),\n",
    "    Dense(unidades=15, activación=\"sigmoide\"),\n",
    "    Dense(unidades=10, activación=\"sigmoide\"),\n",
    "    Dense(unidades=1, activación=\"sigmoide\")])\n",
    "```\n",
    "Este código definirá una red neuronal con ¿cuántas capas?\n",
    "\n",
    "* 4\n",
    "* 25\n",
    "* 5\n",
    "* 3\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "¿Cómo se define la segunda capa de una red neuronal que tiene 4 neuronas y una activación sigmoidea?\n",
    "\n",
    "* Dense(unidades=4)\n",
    "* Dense(unidades=4, activación='sigmoide')\n",
    "* Dense(unidades=[4], activación=['sigmoide']) \n",
    "* Dense(capa=2, unidades=4, activación='sigmoide')\n",
    "\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/01.png\"   style=\"width:476px;height:136px;\" >\n",
    "</figure>\n",
    "\n",
    "Si las características de entrada son la temperatura (en grados centígrados) y la duración (en minutos), ¿cómo se escribe el código para el primer vector de características x mostrado arriba?\n",
    "\n",
    "* x = np.array([[200.0, 17.0]])\n",
    "* x = np.array(['200.0', '17.0']])\n",
    "* x = np.array([[200.0],[17.0]])\n",
    "* x = np.array([[200.0 + 17.0]])\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1: 4.\n",
    "\n",
    "Respuesta 2: Dense(unidades=4, activación='sigmoide').\n",
    "  \n",
    "Respuesta 3: x = np.array([[200.0, 17.0]]).\n",
    "       \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK IMPLEMENTATION IN PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward prop in a single layer\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1y3e6O2ApoaN4yS-msilNJan71vzL9nZ8/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si tuvieras que implementar la propagación hacia adelante tú mismo desde cero en python, cómo lo harías, además de ganar intuición sobre lo que realmente sucede en bibliotecas como TensorFlow y PyTorch. Si algún día decides que quieres construir algo aún mejor que TensorFlow y PyTorch, tal vez ahora tengas una mejor idea en casa, realmente no recomiendo hacer esto para la mayoría de la gente. Pero tal vez algún día, alguien vendrá con un marco aún mejor que TensorFlow y PyTorch y quien lo haga puede terminar teniendo que implementar estas cosas desde cero ellos mismos. Así que vamos a echar un vistazo.\n",
    "\n",
    "En esta diapositiva voy a ir a través de un poco de código y se ve todo este código de nuevo más tarde en el laboratorio opcional como lo fue en el laboratorio de práctica. Así que no te preocupes por tener que tomar notas de cada línea de código o memorizar cada línea de código. Verás este código escrito en el cuaderno Jupiter en el laboratorio y el objetivo de este vídeo es simplemente mostrarte el código para asegurarte de que puedes entender lo que está haciendo. Para que cuando vayas al laboratorio opcional y al laboratorio de prácticas y veas el código allí, sepas qué hacer, así que no te preocupes por tomar notas detalladas de cada línea. Si puedes leer el código en esta diapositiva y entender lo que está haciendo, eso es todo lo que necesitas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_55.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que vamos a echar un vistazo a cómo implementar forward prop en una sola capa, vamos a seguir utilizando el modelo de tostado de café que se muestra aquí. Y vamos a ver cómo se tomaría un vector de características de entrada x, e implementar forward prop para obtener esta salida $a^{[2]}$. En esta implementación de python, voy a utilizar arrays 1D para representar todos estos vectores y parámetros, por lo que sólo hay un corchete aquí. Este es un array 1D en python en lugar de una matriz 2D, que es lo que teníamos cuando teníamos dobles corchetes. \n",
    "\n",
    "Así que el primer valor que necesita para calcular es, $a_1^{[1]}$, que es el primer valor de activación de $a^{[1]}$ y que es $g$ de esta expresión aquí. Así que voy a utilizar la convención en esta diapositiva que en un término como `w2_1`, voy a representar como una variable $w_1^{[2]}$. Este subrayado uno denota el subíndice uno, denota el subíndice uno así que `w2` significa w superíndice 2 entre corchetes y luego subíndice 1.\n",
    "\n",
    "Así, para calcular `a1_1`, tenemos los parámetros `w1_1` y `b1_1`, que son, por ejemplo, 1, 2 y -1. Entonces calcularíamos `z1_1` como el producto punto entre ese parámetro `w1_1` y la entrada $x$, y lo sumaríamos a `b1_1` y finalmente `a1_1` es igual a $g$, la función sigmoidea aplicada a `z1_1`.\n",
    "\n",
    "A continuación, vamos a calcular $a_2^{[1]}$, que de nuevo por la convención que he descrito aquí va a ser `a1_2`, escrito así. Así que similar a lo que hicimos a la izquierda, `w1_2` es dos parámetros -3, 4, `b1_2` es el término, $b$ 1, 2 allí, por lo que calcular $z$ como este término en el medio y luego aplicar la función sigmoidea y luego terminas con `a1_2`, y finalmente haces lo mismo para calcular `a1_3`.\n",
    "\n",
    "Ahora, has calculado estos tres valores, `a1_1`, `a1_2`, y `a1_3`, y nos gusta tomar estos tres números y agruparlos en una matriz para darte `a1` aquí arriba, que es la salida de la primera capa. Y así lo haces agrupándolos juntos usando un array np como sigue, así que ahora has calculado `a_1`, vamos a implementar la segunda capa también. Así que calculas, la salida `a2`, así que `a2` se calcula utilizando esta expresión y así tendríamos los parámetros `w2_1` y `b2_1` correspondientes a estos parámetros. Y luego se calcularía $z$ como el producto punto entre `w2_1` y `a1`, y añadir `b2_1` y luego aplicar la función sigmoide para obtener `a2_1` y eso es todo.\n",
    "\n",
    "Así es como se implementa forward prop usando sólo python y np. Ahora, hay un montón de expresiones en esta página de código que acabas de ver, vamos a ver en el siguiente video cómo se puede simplificar esto para implementar forward prop para una red neuronal más general, en lugar de codificarla para cada neurona como acabamos de hacer. Así que vamos a ver que en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General implementation of forward propagation\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/11C2_NaIY3POtxP9k7JkY9uEmPnutN4B3/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último video, viste cómo implementar forward prop en Python, pero codificando duramente líneas de código para cada neurona. Veamos ahora la implementación más general de forward prop en Python. Al igual que en el vídeo anterior, mi objetivo en este vídeo es mostrarte el código para que cuando lo vuelvas a ver en su laboratorio de prácticas, en los laboratorios opcionales, sepas cómo interpretarlo. Mientras recorremos este ejemplo, no te preocupes por tomar notas de cada línea de código. Si puedes leer el código y entenderlo, eso es definitivamente suficiente. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_57.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Lo que puedes hacer es escribir una función para implementar una capa densa, que es una sola capa de una red neuronal. Voy a definir la función densa, que toma como entrada la activación de la capa anterior, así como los parámetros $w$ y $b$ para las neuronas de una capa determinada. Usando el ejemplo del video anterior, si la capa 1 tiene tres neuronas, y si $w_1$ y $w_2$ y $w_3$ son estos, entonces lo que vamos a hacer es apilar todos estos vectores de onda en una matriz. Esto va a ser una matriz de dos por tres, donde la primera columna es el parámetro $w_1^{[1]}$ la segunda columna es el parámetro $w_2^{[1]}$, y la tercera columna es el parámetro $w_3^{[1]}$. Entonces de manera similar, si tienes los parámetros ser, $b_1^{[1]}$ es igual a uno negativo, $b_2^{[1]}$ es igual a uno, y así sucesivamente, entonces vamos a apilar estos tres números en una matriz 1D b de la siguiente manera, -1, 1, 2. Lo que la función densa hará es tomar como entradas la activación de la capa anterior, y a aquí podría ser $a^{[0]}$, que es igual a $x$, o la activación de una capa posterior, así como los parámetros $w$ apilados en columnas, como se muestra a la derecha, así como los parámetros b también apilados en una matriz 1D, como se muestra a la izquierda allí. Lo que esta función haría es introducir a la activación de la capa anterior y daría salida a las activaciones de la capa actual. \n",
    "\n",
    "Vamos a pasar por el código para hacer esto. Aquí está el código. Primero, las unidades son iguales a `W.shape[1]`. W aquí es una matriz de 2x3, y por lo tanto el número de columnas es tres. Eso es igual al número de unidades en esta capa. Aquí, unidades sería igual a tres. Mirando la forma de $w$, es sólo una manera de sacar el número de unidades ocultas o el número de unidades en esta capa. A continuación, establecemos a para que sea una matriz de ceros con tantos elementos como unidades haya. En este ejemplo, necesitamos la salida de tres valores de activación, por lo que esto sólo inicializa a para ser 0, 0, 0, una matriz de tres ceros. A continuación, vamos a través de un bucle for para calcular el primer, segundo y tercer elemento de a. Para $j$ en las unidades de rango, por lo que $j$ va de 0 a las unidades -1. Va de 0, 1, 2 indexando desde cero y Python como siempre. Este comando $w$ es igual a $W$ dos puntos coma $j$, así es como se saca la $jª$ columna de una matriz en Python. La primera vez que se pasa por este bucle, se extrae la primera columna de w, por lo que se extrae `w1_1`. La segunda vez a través de este bucle, cuando estás calculando la activación de la segunda unidad, sacará la segunda columna correspondiente a `w1_2`, y así sucesivamente para la tercera vez a través de este bucle. Entonces calculas $z$ usando la fórmula habitual, es un producto punto entre ese parámetro $w$ y la activación que has recibido, más $b^{[j]}$. Y entonces calculas la activación a, $j$, es igual a la función sigmoidea $g$ aplicada a $z$. Tres veces a través de este bucle y lo calculas, los valores para los tres valores de este vector de activación es a. Entonces finalmente devuelves a. \n",
    "\n",
    "Lo que hace la función densa es que introduce las activaciones de la capa anterior, y dados los parámetros para la capa actual, devuelve las activaciones para la siguiente capa. Dada la función densa, así es como se pueden encadenar unas cuantas capas densas secuencialmente, para implementar la propensión hacia adelante en la red neuronal. Dadas las características de entrada $x$, puedes calcular las activaciones `a1` para que sean `a1` igual a denso de `x`, `W1`, `b1`, donde aquí `W1`, `b1` son los parámetros, a veces también llamados los pesos de la primera capa oculta. Entonces puedes calcular `a2` como denso de ahora a1, que acabas de calcular arriba. Y `W2`, `b2` que son los parámetros o pesos de esta segunda capa oculta. Entonces calcula `a3` y `a4`. Si se trata de una red neuronal con cuatro capas, a continuación, definir la salida $f(x)$ es sólo igual a `a4`, y por lo que devuelve $f(x)$. \n",
    "\n",
    "Tenga en cuenta que aquí estoy usando $W$, porque en virtud de las convenciones de notación de álgebra lineal es utilizar mayúsculas o un alfabeto de capital es cuando se refiere a una matriz y minúsculas se refieren a los vectores y escalares. Así que, porque es una matriz, esto es $W$.\n",
    "\n",
    "Eso es todo. Ahora ya sabes cómo implementar el forward prop tú mismo desde cero. Tienes la oportunidad de ver todo este código y ejecutarlo y practicarlo tú mismo en el laboratorio de prácticas que viene a esto también. Creo que incluso cuando estás usando librerías potentes como TensorFlow, es útil saber cómo funciona bajo el capó. Porque en caso de que algo vaya mal, en caso de que algo se ejecute muy lentamente, o tengas un resultado extraño, o parezca que hay un error, tu capacidad para entender lo que realmente está pasando te hará mucho más eficaz a la hora de depurar tu código. Cuando ejecuto algoritmos de aprendizaje automático, muchas veces, francamente, no funciona. Sophie, no la primera vez. Encuentro que mi habilidad para depurar mi código sea un código TensorFlow o cualquier otra cosa, es realmente importante para ser un ingeniero de aprendizaje automático efectivo. Incluso cuando usted está usando TensorFlow o algún otro marco, espero que usted encuentre esta comprensión más profunda útil para sus propias aplicaciones y para la depuración de sus propios algoritmos de aprendizaje automático también. Eso es todo. \n",
    "\n",
    "Este es el último vídeo obligatorio de esta semana con código. En el siguiente vídeo, me gustaría sumergirme en lo que creo que es un tema divertido y fascinante, que es, ¿cuál es la relación entre las redes neuronales y la IA o AGI, inteligencia general artificial? Se trata de un tema controvertido, pero como se ha debatido tanto, quiero compartir con vosotros algunas reflexiones al respecto. Cuando te preguntan si las redes neuronales están en el camino de la inteligencia a nivel humano, tienes un marco para pensar en ello. Tienes un marco para pensar en esa pregunta. Vamos a echar un vistazo a ese divertido tema, creo, en el siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Neural network implementation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "Según la clase, ¿cómo se calcula la activación de la tercera neurona de la primera capa utilizando NumPy?\n",
    "\n",
    "* layer_1 = Dense(units=3, activation='sigmoid')\n",
    "  a_1 = capa_1(x)\n",
    "* z1_3 =w1_3 * x + b\n",
    "  a1_3 = sigmoide(z1_3)\n",
    "* z1_3 = np.dot(w1_3, x) + b\n",
    "  a1_3 = sigmoide(z1_3)\n",
    "\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Según la clase, al codificar el numpy array W, ¿dónde colocarías los parámetros w de cada neurona?\n",
    "\n",
    "* En las filas de W.\n",
    "* En las columnas de W.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "\n",
    "Para el código anterior en la función \"dense\" que define una sola capa de neuronas, ¿cuántas veces pasa el código por el \"bucle for\"? Ten en cuenta que W tiene 2 filas y 3 columnas.\n",
    "\n",
    "* 2 veces\n",
    "* 6 veces \n",
    "* 3 veces\n",
    "* 5 veces \n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1: \n",
    "    \n",
    "    z1_3 = np.dot(w1_3, x) + b\n",
    "    a1_3 = sigmoide(z1_3).\n",
    "\n",
    "Respuesta 2: En las columnas de W..\n",
    "  \n",
    "Respuesta 3: 3 veces.\n",
    "    \n",
    "Para cada neurona de la capa, hay una columna en la matriz numpy W. Cada fila de W representa cuántas características de entrada se introducen en esa capa. El bucle for calcula el valor de activación para cada neurona.\n",
    "       \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPECULATIONS ON ARTIFICIAL GENERAL INTELLIGENCE (AGI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a path to AGI?\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1xUzk8sXUjSRGgVzsQDqumkSKkahH_y-Z/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde que era un adolescente y empecé a jugar con las redes neuronales, sentí que el sueño de construir algún día un sistema de IA tan inteligente como yo mismo o como un ser humano típico era uno de los sueños más inspiradores de la IA. Todavía hoy mantengo vivo ese sueño. Pero creo que el camino para llegar allí no está claro y podría ser muy difícil. No sé si nos llevará sólo unas décadas y si veremos avances en el transcurso de nuestras vidas, o si puede llevarnos siglos o incluso más tiempo llegar allí. Echemos un vistazo a cómo es este sueño de la AGI, la inteligencia general artificial, y especulemos un poco sobre cuáles podrían ser los caminos posibles, los caminos poco claros, los caminos difíciles para llegar allí algún día. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_59.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Creo que ha habido mucho bombo y platillo innecesario sobre la AGI o la inteligencia general artificial. Quizá una de las razones sea que la IA incluye dos cosas muy diferentes. \n",
    "\n",
    "- Una es ANI, que significa inteligencia artificial estrecha. Se trata de un sistema de IA que hace una cosa, una tarea limitada, a veces muy bien y que puede ser increíblemente valiosa, como el altavoz inteligente o el coche autodirigido o la búsqueda en la web, o la IA aplicada a aplicaciones específicas como la agricultura o las fábricas. En los últimos años, la ANI ha progresado enormemente y está creando, como sabes, un enorme valor en el mundo actual. Dado que la ANI es un subconjunto de la IA, el rápido progreso de la ANI hace que, lógicamente, la IA también haya progresado enormemente en la última década. \n",
    "\n",
    "- Hay una idea diferente en la IA, que es AGI, inteligencia general artificial. Existe la esperanza de construir sistemas de IA que puedan hacer cualquier cosa que un humano típico pueda hacer. A pesar de todos los avances en la ANI y, por tanto, de los tremendos progresos en la IA, no estoy seguro de cuánto progreso, si es que hay alguno, estamos haciendo realmente hacia la AGI. Creo que todos los avances en la ANI han hecho que la gente concluya correctamente que hay un tremendo progreso en la IA. Pero eso ha hecho que algunas personas concluyan, creo que incorrectamente, que un gran progreso en la IA significa necesariamente que hay un gran progreso hacia la AGI. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_60.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Si tienes otra cosa sobre la IA y la AGI, a veces puede que te resulte útil dibujar este cuadro para explicar algunas de las cosas que están pasando en la IA y algunas de las fuentes del bombo innecesario sobre la AGI. \n",
    "Con el auge del aprendizaje profundo moderno, empezamos a simular neuronas y con ordenadores cada vez más rápidos e incluso GPUs podemos simular aún más neuronas. Creo que hace muchos años existía la gran esperanza de que, vaya, si pudiéramos simular muchas neuronas, podríamos simular el cerebro humano o algo parecido a un cerebro humano y tendríamos sistemas realmente inteligentes. Lamentablemente, ha resultado no ser tan sencillo. Creo que hay dos razones para ello: \n",
    "\n",
    "- en primer lugar, si nos fijamos en las redes neuronales artificiales que estamos construyendo, son tan simples que una unidad de regresión logística no se parece en nada a lo que hace cualquier neurona biológica, es mucho más simple que lo que hace cualquier neurona de tu cerebro o del mío. \n",
    "\n",
    "- En segundo lugar, incluso a día de hoy, creo que no tenemos casi ninguna idea de cómo funciona el cerebro. Todavía hay cuestiones fundamentales sobre cómo exactamente una neurona mapea desde las entradas a las salidas que simplemente no conocemos hoy en día. Intentar simular eso en un ordenador, y mucho menos una función logística única, está muy lejos de ser un modelo preciso de lo que hace realmente el cerebro humano. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_61.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Dada nuestra limitada comprensión, tanto ahora como probablemente en un futuro próximo, de cómo funciona el cerebro humano, creo que tratar de simular el cerebro humano como camino hacia la AGI será un camino increíblemente difícil. Dicho esto, ¿hay alguna esperanza de que dentro de nuestras vidas veamos avances en la AGI? Permítanme compartir con ustedes algunas pruebas que me ayudan a mantener viva esa esperanza, al menos para mí. \n",
    "\n",
    "Se han realizado algunos experimentos fascinantes en animales que muestran o sugieren fuertemente que el mismo trozo de tejido cerebral biológico puede realizar una gama sorprendentemente amplia de tareas. Esto ha conducido a la hipótesis del algoritmo de aprendizaje único, según la cual, tal vez gran parte de la inteligencia podría deberse a uno o a un pequeño puñado de algoritmos de aprendizaje. Si pudiéramos averiguar cuál es ese algoritmo o ese pequeño puñado de algoritmos, podríamos implementarlo en un ordenador algún día. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_62.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Permítanme compartir con ustedes algunos detalles de esos experimentos. Este es un resultado debido a Roe et al. de hace muchas décadas. La parte de su cerebro que se muestra aquí es su corteza auditiva, y su cerebro está conectado para alimentar las señales de sus oídos en forma de impulsos eléctricos, dependiendo del sonido que su oído está detectando a esa corteza auditiva. Resulta que si se recablea el cerebro de un animal para cortar el cable entre el oído y la corteza auditiva, y en su lugar alimentar con imágenes a la corteza auditiva, entonces la corteza auditiva aprende a ver. Lo auditivo se refiere al sonido, y así esta parte del cerebro que en la mayoría de las personas aprende a ver, cuando se le alimentan datos diferentes, aprende a ver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_63.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "He aquí otro ejemplo. Esta parte del cerebro es la corteza somatosensorial, que se refiere al procesamiento del tacto. Si se reconfigura el cerebro de manera similar para cortar la conexión de los sensores del tacto a esa parte del cerebro y en su lugar se reconfigura el cerebro para alimentar imágenes, entonces la corteza somatosensorial aprende a ver. Ha habido una secuencia de experimentos como este, mostrando que muchas partes diferentes del cerebro, sólo en función de los datos que se dan puede aprender a ver, o aprender a sentir, o aprender a escuchar como si hubiera tal vez un algoritmo que sólo en función de lo que los datos o este dado, aprende a procesar que las entradas en consecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_64.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Hay sistemas construidos que toman una cámara puede ser montado en la frente de alguien y los mapas a un patrón de voltajes en una cuadrícula en la lengua de alguien. Al mapear una imagen en escala de grises a un patrón de voltajes en su lengua, esto puede ayudar a las personas que no son individuos de línea citados a aprender a ver con su lengua, o han sido fascinantes experimentos con la ecolocalización humana o el sonar humano, por lo que los animales como los delfines y los murciélagos utilizan el sonar para ver, y los investigadores han encontrado que si se entrena a los seres humanos para hacer sonidos de clic, y escuchar cómo eso rebota en los alrededores, los seres humanos a veces pueden aprender algún grado de ecolocalización humana. O esto es un cinturón háptico, y mi laboratorio de investigación en Stanford construyó una vez algo así también, pero si montas un anillo de zumbidos alrededor de tu cintura y lo programas usando una brújula magnética, de modo que digamos, los zumbidos hacia la dirección más al norte siempre están vibrando lentamente, entonces de alguna manera ganas un sentido de la dirección, que algunos animales tienen, pero los humanos no. Entonces se siente como si estuvieras caminando y simplemente sabes dónde está el Norte, no se siente como si esa parte de mi cintura estuviera zumbando, se siente como, oh, sé dónde está ese Norte. O las cirugías implantan un tercer ojo en la rana y el cerebro simplemente aprende contigo con esta entrada. Ha habido una variedad de experimentos como estos que demuestran que el cerebro humano es increíblemente adaptable, los neurocientíficos dicen que es increíblemente plástico, sólo quieren decir que es adaptable a una gama desconcertante de entradas de sensores, y entonces la pregunta es, si el mismo pedazo de tejido cerebral puede aprender a ver, o tocar, o sentir, o incluso otras cosas, ¿cuál es el promedio de los usuarios, y podemos replicar este algoritmo e implementarlo en una computadora? Me siento mal por la rana y otros animales, o que estos experimentos se hicieron, aunque creo que las conclusiones son también bastante fascinante. \n",
    "\n",
    "Incluso a día de hoy, creo que trabajar en la AGI es uno de los problemas de ciencia e ingeniería más fascinantes de todos los tiempos, y tal vez algún día decida investigar sobre ello. Sin embargo, creo que es importante evitar la exageración, no sé si el cerebro es realmente uno o un pequeño puñado de algoritmos, e incluso si lo fuera, no tengo ni idea, y no creo que nadie sepa cuál es el algoritmo, pero todavía esta esperanza viva, y tal vez lo sea, y tal vez podríamos, a través de un montón de trabajo duro, algún día descubrir una aproximación a ella. Sigo encontrando este tema como uno de los más fascinantes, realmente pienso en ello en mi tiempo libre y tal vez algún día, sea usted el que haga una contribución a este problema. A corto plazo, creo que incluso sin perseguir la AGI, el aprendizaje automático y las redes neuronales son una herramienta muy poderosa, e incluso sin intentar llegar a construir una inteligencia de nivel humano, creo que las redes neuronales son un conjunto de herramientas increíblemente poderoso y útil para las aplicaciones que se puedan construir. Eso es todo para los videos requeridos de esta semana, felicitaciones por llegar a este punto en las lecciones. Después de esto, también tendremos unos cuantos vídeos opcionales para profundizar un poco más en las implementaciones eficientes de las redes neuronales. En particular, en los videos opcionales que vienen, me gustaría compartir con ustedes algunos detalles de cómo vectorizar implementaciones de redes neuronales. Espero que también eches un vistazo a esos vídeos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VECTORIZATION (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How neural networks are implemented efficiently\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/19tFMJiFGt6-9yskymnJqheSt1GY2wCyw/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las razones por las que los investigadores del aprendizaje profundo han sido capaces de escalar las redes neuronales, y de pensar en redes neuronales realmente grandes durante la última década, es porque las redes neuronales pueden ser vectorizadas. Se pueden implementar de forma muy eficiente utilizando multiplicaciones matriciales. Resulta que el hardware de computación paralela, incluidas las GPU, pero también algunas funciones de la CPU son muy buenas para realizar multiplicaciones matriciales muy grandes. En este vídeo, veremos cómo funcionan estas implementaciones vectoriales de las redes neuronales. Sin estas ideas, no creo que el aprendizaje profundo se acerque al éxito y a la escala actual. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_66.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí a la izquierda está el código que habías visto anteriormente de cómo se implementaría la propagación hacia adelante, en una sola capa. `X` aquí es la entrada, `W`, los pesos de la primera, segunda y tercera neuronas, digamos, los parámetros `b`, y luego este es el mismo código que vimos antes. Esto dará como resultado tres números, digamos, así. Si realmente implementas este cálculo, obtienes 1, 0, 1. \n",
    "\n",
    "Resulta que puedes desarrollar una implementación vectorizada de esta función como sigue. Establece `X` para que sea igual a esto. Fíjate en los dobles corchetes. Esto es ahora un array 2D, como en TensorFlow. `W` es lo mismo que antes, y `B`, ahora estoy usando B, es también un array 2D de 1x3. Entonces resulta que todos estos pasos, este bucle for dentro, puede ser reemplazado con sólo un par de líneas de código, `Z` es igual a `np.matmul`. Matmul es como NumPy lleva a cabo la multiplicación de matrices. Donde ahora `X` y `W` son ambas matrices, y por lo tanto sólo se multiplican juntos. Resulta que este bucle for, todas estas líneas de código pueden ser reemplazadas con sólo un par de líneas de código, lo que da una implementación vectorizada de esta función. Calculas `Z`, que ahora es una matriz de nuevo, como numpy.matmul entre `A_in` y `W`, donde aquí `A_in` y `W` son ambas matrices, y matmul es como NumPy lleva a cabo una multiplicación de matrices. Multiplica dos matrices juntas, y luego le añade la matriz `B`. Entonces `A_out` es igual a la función de activación `g`, que es la función sigmoidea, aplicada elemento a elemento a esta matriz `Z`, y entonces finalmente devuelves `A_out`. \n",
    "\n",
    "Este es el aspecto del código. Obsérvese que en la implementación vectorizada, todas estas cantidades, `x`, que se introduce en el valor de `A_in` así como `W`, `B`, así como `Z` y `A_out`, todas ellas son ahora matrices 2D. Todos estos son matrices. Esto resulta ser una implementación muy eficiente de un paso de propagación hacia adelante a través de una capa densa en la red neuronal. \n",
    "\n",
    "Este es el código para una implementación vectorizada de la propagación hacia adelante en una red neuronal. Pero, ¿qué hace este código y cómo funciona realmente? ¿Qué hace realmente este matmul? En los dos siguientes vídeos, ambos también opcionales, repasaremos la multiplicación de matrices y su funcionamiento. Si estás familiarizado con el álgebra lineal, si estás familiarizado con los vectores, las matrices, las transposiciones y las multiplicaciones de matrices, puedes pasar rápidamente por encima de estos dos vídeos y saltar al último vídeo de esta semana. Luego, en el último video de esta semana, también opcional, nos sumergiremos en más detalles para explicar cómo matmul te da esta implementación vectorizada. Pasemos al siguiente video, donde veremos qué es la multiplicación de matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1cKp4WnzVcrqm2-L_MspCfrXRpvsCUWwB/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sabes que una matriz no es más que un bloque o matriz 2D de números. ¿Qué significa multiplicar dos matrices? Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_68.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Para llegar a multiplicar matrices, empecemos por ver cómo tomamos productos puntuales entre vectores. Usemos el ejemplo de tomar el producto punto entre este vector 1, 2 y este vector 3, 4. Si $z$ es el producto punto entre estos dos vectores, entonces calculas $z$ multiplicando el primer elemento por el primer elemento aquí, es 1 por 3, más el segundo elemento por el segundo elemento más 2 por 4, y así es sólo 3 más 8, que es igual a 11. \n",
    "\n",
    "En el caso más general, si $z$ es el producto punto entre un vector $a$ y un vector $w$, entonces calculas $z$ multiplicando el primer elemento juntos y luego los segundos elementos juntos y el tercero y así sucesivamente y luego sumando todos estos productos. Ese es el vector, el producto punto vectorial. \n",
    "\n",
    "Resulta que hay otra forma equivalente de escribir un producto punto, que ha dado un vector $a$, es decir, 1, 2 escrito como una columna. Puedes convertir esto en una fila. Es decir, puedes convertirlo de lo que se llama un vector columna a un vector fila tomando la transposición de a. La transposición del vector a significa que tomas este vector y pones sus elementos de lado así. \n",
    "\n",
    "Resulta que, si multiplicas una transposición, esto es un vector fila, o puedes pensar en esto como una matriz de 1x2 con $w$, que ahora puedes pensar como una matriz de 2x1. Entonces $z$ es igual a un transpuesto por $w$ y esto es lo mismo que tomar el producto punto entre $a$ y $w$. \n",
    "\n",
    "Para recapitular, $z$ es igual al producto punto entre $a$ y $w$ es lo mismo que $z$ es igual a un transpuesto, es decir un puesto de lado, multiplicado por $w$ y esto será útil para entender la multiplicación de matrices. Que son sólo dos formas de escribir exactamente el mismo cálculo para llegar a $z$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_69.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora vamos a ver la multiplicación de matrices vectoriales, que es cuando se toma un vector y se multiplica un vector por una matriz. Aquí de nuevo es el vector $a$ [1, 2] y una transposición es un puesto en el lado, así que en lugar de este pensar en esto como una matriz de 2x1 se convierte en una matriz de 1x2. Permítanme ahora crear una matriz $W$ de 2x2 con estos cuatro elementos, [3, 4, 5, 6]. Si quieres calcular $Z$ como una transposición veces $W$. Vamos a ver cómo hacerlo. Resulta que $Z$ va a ser una matriz de 2x1, y para calcular el primer valor de $Z$ vamos a tomar una transposición, [1, 2] aquí, y se multiplican por la primera columna de $W$, que es [3, 4]. Para calcular el primer elemento de $Z$, terminas con 1 por 3 más 2 por 4, lo que vimos antes es igual a 11, y así el primer elemento de $Z$ es 11. Averigüemos cuál es el segundo elemento de $Z$. Resulta que sólo tienes que repetir este proceso, pero ahora multiplicando una transposición por la segunda columna de $w$. Para hacer ese cálculo, tienes 1 por 5 más 2 por 6, que es igual a 5 más 12, que es 17. Eso es igual a 17. $Z$ es igual a esta matriz de uno por dos, 11 y 17. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_70.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, sólo una última cosa, y luego que nos llevará al final de este video, que es cómo tomar la multiplicación de la matriz vectorial y generalizarlo a la multiplicación de la matriz. Tengo una matriz $A$ con estos cuatro elementos, la primera columna es 1, 2 y la segunda columna es -1, -2 y quiero saber cómo calcular una transposición veces $w$. A diferencia de la diapositiva anterior, $A$ ahora es una matriz en lugar de sólo el vector o la matriz es sólo un conjunto de diferentes vectores apilados en columnas. Primero vamos a averiguar qué es la transposición de $A$. Para calcular la transposición de $A$, vamos a tomar las columnas de $A$ y de manera similar a lo que sucede cuando se transpone un vector, vamos a tomar las columnas y ponerlas de lado, una columna a la vez. La primera columna 1, 2 se convierte en la primera fila 1, 2, vamos a ponerla de lado, y esta segunda columna, -1, -2 se pone de lado -1, -2 así. La forma de transponer una matriz es tomar las columnas y simplemente poner las columnas en el lado, una columna a la vez, que terminan con este ser $A$ transposición. \n",
    "\n",
    "A continuación, tenemos esta matriz $W$, que vamos a escribir como 3,4, 5,6. Hay una columna 3, 4 y la columna 5, 6. Una de las formas en que te animo a pensar en las matrices. Por lo menos es útil para las implementaciones de redes neuronales es que si ves una matriz, piensa en las columnas de la matriz y si ves la transposición de una matriz, piensa en las filas de esa matriz agrupadas como se ilustra aquí, con $A$ y la transposición de $A$, así como $W$.\n",
    "\n",
    "Ahora, déjame mostrarte cómo multiplicar la transposición de $A$ y $W$. Para realizar este cálculo déjame llamar a las columnas de $A$, $a1$ y $a2$ y eso significa que la transposición de $a1$, es la primera fila de la transposición de $A$, y la transposición de $a2$ es la segunda fila de la transposición de $A$. Entonces igual que antes, llamemos a las columnas de W para que sean $w1$ y $w2$. Resulta que para calcular la transposición $W$ de $A$, lo primero que tenemos que hacer es ignorar la segunda fila de $A$ y prestar atención a la primera fila de $A$ y tomar esta fila 1, 2 que es la transposición $a1$ y multiplicarla por $W$. Ya sabes cómo hacerlo desde la diapositiva anterior. El primer elemento es 1, 2, producto interno o producto punto tenemos 3, 4. Eso termina con 3 por 1 más 2 por 4, que es 11. Entonces el segundo elemento es 1, 2 Una transposición, producto interno tenemos 5, 6. Hay 5 por 1 más 6 por 2, que es 5 más 12, que es 17. Eso le da la primera fila de $Z$ es igual a $A$ transponer $W$. Todo lo que hemos hecho es tomar a1 transponer y multiplicar que por W. Eso es exactamente lo que hicimos en la diapositiva anterior. \n",
    "\n",
    "A continuación, olvidemos $a1$ por ahora, y veamos $a2$ y tomemos $a2$ transpuesto y multipliquemos eso por $W$. Ahora tenemos $a2$ transpuesto por $W$. Para calcular eso primero tomamos 1 negativo y 2 negativo y el producto punto que con 3, 4. Eso es 1 negativo por 3 más 2 negativo por 4 y eso resulta ser 11 negativo. Luego tenemos que calcular $a2$ transposición veces la segunda columna, y tiene negativo 1 veces 5 más negativo 2 veces 6, y eso resulta ser negativo 17. Usted termina con $A$ transponer veces $W$ es igual a esta matriz de dos por dos aquí. \n",
    "\n",
    "Vamos a hablar de la forma general de la multiplicación de matrices. Este fue un ejemplo de cómo se multiplica un vector con una matriz, o una matriz con una matriz es un montón de productos de punto entre los vectores, pero ordenados de una manera determinada para construir los elementos de la $Z$ superior, un elemento a la vez. Sé que esto ha sido mucho, pero en el siguiente vídeo, vamos a ver la forma general de cómo se define una multiplicación de matrices y espero que todo esto quede claro también. Pasemos al siguiente vídeo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication rules\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1mQp1UF2eVtumgt1Kzez-JIOm47Wl7zCi/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que vamos a echar un vistazo a la forma general de cómo se multiplican dos matrices juntas. Y luego en el último video después de este, tomaremos esto y lo aplicaremos a la implementación vectorizada de una red neuronal. Vamos a sumergirnos. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_72.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está la matriz $A$, que es una matriz de 2 por 3 porque tiene dos filas y tres columnas. Como antes te animo a pensar en las columnas de esta matriz como tres vectores, los vectores $a_1$, $a_2$ y $a_3$. Y lo que vamos a hacer es tomar la transposición de $A$ y multiplicarla por la matriz $W$. La primera, ¿qué es la transposición de $A$? Bueno, la transposición de $A$ se obtiene tomando la primera columna de $a$ y poniéndola de lado así y luego tomando la segunda columna de $a$ y poniéndola de lado así. Y luego la tercera columna de $a$ y poniéndola de lado así (haciendo filas se refiere). Y así estas funciones son ahora $a_1^T$, $a_2^T$ y $a_3^T$. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_73.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "A continuación, aquí está la matriz $W$. Te animo a pensar en W como factores $w_1$, $w_2$, $w_3$ y $w_4$ apilados. Así que vamos a ver cómo se calcula la transposición de $A$ por $W$. Ahora, observe que también he utilizado ligeramente diferentes tonos de naranja para denotar las diferentes columnas de $A$, donde el mismo tono corresponde a los números que pensamos como agrupados en un vector. Y ese mismo tono se utiliza para indicar los diferentes roles de $A$ transpuesto porque los diferentes roles de $a_1^T$, $a_2^T$ y $a_3^T$. Y de manera similar, he usado diferentes tonos para denotar las diferentes columnas de $W$. Porque los números son del mismo tono de azul, son los que se agrupan para formar los vectores , $w_2$, $w_3$ y $w_4$. Ahora, vamos a ver cómo se puede calcular $A$ transpose veces $W$. Voy a dibujar arcos verticales a los diferentes tonos de azul y barras horizontales con los diferentes tonos de naranja para indicar qué elementos de $Z$ que es $A$ transpose $W$ son influenciados o afectados por los diferentes papeles de $A$ transpose y que son influenciados o afectados por las diferentes columnas de $W$. Así que, por ejemplo, vamos a ver la primera columna de $W$. Así que eso es $w_1$ como se indica por el tono más claro de azul aquí. Así que $w_1$ influirá o corresponderá a esta primera columna de $Z$ mostrada aquí por este tono más claro de azul. Y los valores de esta segunda columna de $W$ que es $w_2$ como se indica por este segundo tono más claro de azul afectará a los valores computados en la segunda columna de $Z$ y así sucesivamente para la tercera y cuarta columnas.\n",
    "\n",
    "En consecuencia, veamos la transposición $A$. La transposición $a_1$ es la primera fila de la transposición $A$, como lo indica el tono más claro de naranja y la transposición $a_1$ afectará o influirá o corresponderá a los valores de la primera fila de $Z$. Y la transposición $a_2$ influirá en la segunda fila de $Z$ y la transposición $a_3$ influirá o corresponderá a esta tercera fila de $Z$. Así que vamos a ver cómo calcular la matriz $Z$, que va a ser una matriz de 3 por 4. Así que con 12 números en total. \n",
    "\n",
    "Comencemos y averigüemos cómo calcular el número en la primera fila, en la primera columna de $Z$. Así que este elemento superior izquierdo aquí porque esta es la primera fila y la primera columna que corresponde al tono más claro de naranja y el tono más claro de azul. La forma de calcular esto es tomar la primera fila de una transposición y la primera columna de W y tomar su producto interno o el producto. Y así este número va a ser (1,2) producto escalar con (3,4) que es (1 * 3) + (2 * 4) = 11. \n",
    "\n",
    "Veamos el segundo ejemplo. Cómo calcularías este elemento de $Z$. Así que esto está en la tercera fila, fila 1, fila 2, fila 3. Así que esto está en la fila 3 y la segunda columna, columna 1, columna 2. Así que para calcular el número en la fila 3, columna 2 de $Z$, que ahora tomaría la fila 3 de A transposición y la columna 2 de $W$ y punto producto de los mismos. Observa que esto corresponde al tono más oscuro de naranja y al segundo tono más claro de azul. Y para calcular esto, esto es (0,1 * 5) +(0,2 * 6), que es (0,5 + 1,2), que es igual a 1,7. Así que para calcular el número de la fila 3, columna 2 de Z, coges la tercera fila, la fila 3 de una transposición y la columna 2 de $W$. \n",
    "\n",
    "Veamos un ejemplo más y veamos si puedes resolverlo. Esta es la fila 2, columna 3 de la matriz $Z$. ¿Por qué no echas un vistazo y ver si usted puede averiguar qué fila y qué columna para agarrar el producto punto juntos y por lo tanto lo que es el número que va a ir en este elemento de esta matriz?. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "¿Puedes calcular el valor de la columna 3, fila 2?\n",
    "\n",
    "* $(-1 x 7) + (-2 x 8) = -23$\n",
    "* $(0.1 x 5) + (0.2 x 6) = 1.7$\n",
    "* $(1 x 3) + (2 x 4) = 11$\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta:  $(-1 x 7) + (-2 x 8) = -23$.\n",
    "       \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_74.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Espero que lo tengas. Usted debe agarrar la fila 2 de $A$ transposición y la columna 3 de $W$. Y cuando el producto de punto que juntos tiene $a_2$ transposición $w_3$ es (-1 * 7) + (-2 * 8 ), que es (-7 + -16), que es igual a -23. Y así es como se calcula este elemento de la matriz $Z$. Y resulta que si usted hace esto para cada elemento de la matriz $Z$, entonces usted puede calcular todos los números en esta matriz que resulta ser así. No dudes en poner en pausa el vídeo si quieres y elegir los elementos y volver a comprobar que la fórmula que hemos repasado te da el valor correcto de $Z$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_75.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Sólo quiero señalar un último requisito interesante para multiplicar matrices entre sí, que es que la transposición $X$ aquí es una matriz de 3 por 2 porque tiene 3 filas y 2 columnas, y $W$ aquí es una matriz de 2 por 4 porque tiene 2 filas y 4 columnas. Un requisito para poder multiplicar dos matrices juntas es que este número (la fila de $W$) debe coincidir con aquel (la columna de $A^T$). Y eso es porque sólo puedes tomar productos escalares entre vectores que tengan la misma longitud. Así que puedes tomar el producto punto entre un vector con dos números. Y eso es porque puedes tomar el producto interior entre el vector de longitud 2 sólo con otro vector de longitud 2. No puedes tomar el producto interior entre el vector de longitud 2 con un vector de longitud 3, por ejemplo. Y es por eso que la multiplicación de matrices es válida sólo si el número de columnas de la primera matriz, es decir $A$ transpuesta aquí es igual al número de rollos de la segunda matriz, es decir el número de filas de $W$ aquí. De modo que cuando tomas productos escalares durante este proceso, estás tomando productos escalares de vectores del mismo tamaño. \n",
    "\n",
    "Y luego la otra observación es que la salida $Z$ es igual a una transposición, $W$. Las dimensiones de $Z$ es 3 por 4. Y así la salida de esta multiplicación tendrá el mismo número de filas como $X$ transposición y el mismo número de columnas como $W$. Y así también es otra propiedad de la multiplicación de matrices. \n",
    "\n",
    "Así que eso es la multiplicación de matrices. Todos estos videos son opcionales. Así que gracias por seguir conmigo a través de estos. Y si estás interesado más adelante en esta semana, también hay algunos cuestionarios puramente opcionales para que puedas practicar algunos más de estos cálculos por ti mismo también. Un poco de eso, vamos a tomar lo que hemos aprendido acerca de la multiplicación de matrices y aplicado de nuevo a la implementación vectorizada de una Red Neural. Tengo que decir que la primera vez que entendí la implementación vectorizada, pensé que era realmente genial. Yo mismo he estado implementando Redes Neuronales durante un tiempo sin la implementación vectorizada. Y cuando finalmente entendí la implementación vectorizada y la implementé de esa manera por primera vez, se ejecutó mucho más rápido que cualquier cosa que haya hecho antes. Y pensé, wow, ojalá hubiera descubierto esto antes. La implementación vectorizada, es un poco complicada, pero hace que tus redes corran mucho más rápido. Así que vamos a echar un vistazo a eso en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication code\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1ezzlFDzL1HN6m9Un6HRp2lcJIukIpny0/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin más preámbulos, vamos a saltar a la implementación vectorial de una red neuronal. Vamos a ver el código que habéis visto en un vídeo anterior, y con suerte, `matmul`, que es ese cálculo de multiplicación de matrices, tendrá más sentido. Vamos a entrar.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_77.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Usted vio anteriormente cómo se puede tomar la matriz $A$ y calcular $A^TW$ resultando en esta matriz aquí, $Z$. En el código si esta es la matriz $A$, esto es una matriz NumPy con los elementos correspondientes a lo que escribí en la parte superior, a continuación, A transponer, que voy a escribir como $A^T$, va a ser esta matriz aquí, con otra vez las columnas de $A$ ahora dispuestas en filas en su lugar. Por cierto, en lugar de configurar $A^T$ de esta manera, otra forma de calcular $A^T$ en NumPy, vamos a escribir $A^T$ es igual a `A.T`. Esa es la función de transposición que toma las columnas de una matriz y las pone de lado. En código, así es como se inicializa la matriz $W$ como otro array 2D de NumPy. Entonces para calcular $Z$ es igual a la $A^TW$, escribirás `Z=np.matmul(AT, W)`, y eso calculará esta matriz $Z$ por aquí, dándote este resultado aquí abajo. Por cierto, si lees el código de otros, a veces ves que `Z=AT@W`. Esta es una forma alternativa de llamar a la función matmul. Aunque encuentro que usar `np.matmul` es más claro. La llamada que ves en esta clase, simplemente usamos la función matmul así en lugar de esta `@`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C2_W1_Página_78.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos cómo es una implementación vectorizada de forward prop. Voy a establecer que $A^T$ sea igual a los valores de la característica de entrada 217. Estos son los valores habituales de la característica de entrada, 200 grados de tueste de café durante 17 minutos. Esta es una matriz de uno por dos. Voy a tomar los parámetros $w_1$, $w_2$, y $w_3$, y apilarlos en columnas así para formar esta matriz $W$. Los valores $b_1$, $b_2$, $b_3$, voy a ponerlos en una matriz de uno por tres, que es esta matriz $B$ como sigue. Entonces resulta que si usted fuera a calcular $Z$ es igual a $A^TW+B$, que dará lugar a estos tres números y que se calcula tomando los valores de la característica de entrada y multiplicando que por la primera columna y luego añadiendo $B$ para obtener 165. Tomando estos valores de características, produciendo por puntos con la segunda columna, que es un peso $w_2$ y añadiendo $b_2$ para obtener 531 negativo. Estos valores de las características se producen por puntos con los pesos $w_3$ más $b_3$ para obtener 900. Siéntase libre de pausar el vídeo si desea volver a comprobar estos cálculos. Pero esto le da es los valores de $z_1^{[1]}$, $z_1^{[2]}$, y $z_1^{[3]}$. Entonces, finalmente, si la función $g$ aplica la función sigmoidea a estos tres números de forma elemental, es decir, aplica la función sigmoidea a 165, a -531 y a 900, entonces terminas con A igual a $g$ de esta matriz $Z$ termina siendo 1,0,1. Es 1,0,1 porque el sigmoide de 165 está tan cerca de uno que hasta el redondeo numérico se basa en uno y estas son las bases 0 y 1. \n",
    "\n",
    "Veamos cómo se implementa esto en código. $A^T$ es igual a esto, es esta matriz de uno por dos de 200, 17. La matriz $W$ es esta matriz de dos por tres, y $B$, es esta matriz de uno por tres. La forma en que se puede implementar forward prop en una capa es densa entrada $A^TW+b=z$ es igual a `matmul(AT,W)+b`. Eso sólo implementa esta línea de código. Entonces $a_out$ que es la salida de esta capa es igual a $g$, la función de activación aplicada elemento a elemento a esta matriz $Z$. Devuelves $a_out$, y eso te da este valor. \n",
    "En caso de que estés comparando esta diapositiva con la diapositiva de hace unos vídeos, sólo había una pequeña diferencia, que era por convención, la forma en que esto se implementa en TensorFlow, en lugar de llamar a esta variable $A$,$T$, la llamamos simplemente $A$, en lugar de llamar a esta variable $A$,$T$, la llamamos $A_in$, por lo que esta también es la implementación correcta del código. Hay una convención en TensorFlow de que los ejemplos individuales están realmente dispuestos en filas en la matriz $X$ en lugar de en la matriz $X$ transpuesta, que es la razón por la que la implementación del código realmente se ve así en TensorFlow. Pero esto explica por qué con sólo unas pocas líneas de código se puede implementar el forward prop en la red neuronal y, además, obtener un enorme bono de velocidad porque la multiplicación matricial matmul se puede hacer muy eficientemente usando hardware rápido y obtener un enorme bono porque los ordenadores modernos son muy buenos en la implementación de multiplicaciones matriciales como matmul de manera eficiente. \n",
    "\n",
    "Este es el último vídeo de esta semana. Gracias por seguir conmigo hasta el final de estos vídeos opcionales. Para el resto de esta semana, espero que también eches un vistazo a los cuestionarios y a los laboratorios de práctica y también a los laboratorios opcionales para ejercitar este material aún más profundamente. Ahora ya sabes cómo hacer inferencia y propulsión hacia delante en una red neuronal, lo que me parece realmente genial, así que enhorabuena. Después de que hayas pasado por los cuestionarios y los laboratorios, por favor, vuelve también y en la próxima semana, veremos cómo entrenar realmente una red neuronal. Espero verlos la próxima semana."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
