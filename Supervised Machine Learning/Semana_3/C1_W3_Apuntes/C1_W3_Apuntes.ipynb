{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/00_Logo.jpg\"   style=\"width:116px;height:218px;\" >\n",
    "</figure>\n",
    "\n",
    "# **MACHINE LEARNING SPECIALIZATION**\n",
    "# Curso 1: Supervised Machine Learning: Regression and Classification\n",
    "# Semana 3: CLASSIFICATION\n",
    "\n",
    "*Esta notebook plasma los apuntes traducidos al español del Curso dicatado por [DeepLearning.AI](https://www.deeplearning.ai/courses/), por lo que puede encontrar errores. Las figuras y ecuaciones se han obtenido/adaptado directamente de las diapositivas utilizadas en el curso. Todo el mérito es de los instructores. Simplemente espero que los apuntes sirvan como material de estudio complementario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICATION WITH LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1ZX9Ep5hvHKRFrwDa1cFg7CC2ha8plWX0/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido a la tercera semana de este curso. Al final de esta semana, habrás completado el primer curso de esta especialización. Así que vamos a entrar en materia. La semana pasada aprendiste sobre la regresión lineal, que predice un número. Esta semana, aprenderás sobre la **clasificación**, en la que tu variable de salida y puede tomar sólo uno de un pequeño puñado de valores posibles en lugar de cualquier número en un rango infinito de números. Resulta que la regresión lineal no es un buen algoritmo para los problemas de clasificación. Veamos por qué y esto nos llevará a un algoritmo diferente llamado regresión logística. Que es uno de los algoritmos de aprendizaje más populares y más utilizados hoy en día. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_03.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí hay algunos ejemplos de problemas de clasificación recordemos el ejemplo de intentar averiguar si un correo electrónico es spam. La respuesta que se quiere obtener es un no o un sí. Otro ejemplo sería averiguar si una transacción financiera en línea es fraudulenta. La lucha contra el fraude financiero en línea es algo en lo que trabajé una vez y fue extrañamente estimulante. Porque sabía que había fuerzas que intentaban robar dinero y el trabajo de mi equipo era detenerlas. Así que el problema es dar una transacción financiera. ¿Puede su algoritmo de aprendizaje averiguar si esta transacción es fraudulenta, como por ejemplo, si esta tarjeta de crédito ha sido robada? Otro ejemplo que hemos tocado antes era tratar de clasificar un tumor como maligno o no. \n",
    "\n",
    "En cada uno de estos problemas, la variable que se quiere predecir sólo puede tener uno de los dos valores posibles. No o sí. Este tipo de problema de clasificación en el que sólo hay dos resultados posibles se llama **clasificación binaria**. La palabra binario se refiere a que sólo hay dos clases o dos categorías posibles. En estos problemas utilizaré los términos **clase** y **categoría** de forma relativamente intercambiable. Significan básicamente lo mismo. Por convención, podemos referirnos a estas dos clases o categorías de algunas formas comunes. A menudo designamos las cláusulas como no o sí o, a veces, de forma equivalente, como falso o verdadero o, muy comúnmente, utilizando los números cero o uno. Siguiendo la convención común en ciencias de la computación con el cero denotando caídas y el uno denotando verdadero. Normalmente voy a usar los números cero y uno para representar la respuesta y. Porque eso se ajustará más fácilmente a los tipos de algoritmos de aprendizaje que queremos implementar. Pero cuando hablamos de ello a menudo también diremos no o sí o falso o verdadero. \n",
    "\n",
    "Una de las tecnologías comúnmente utilizadas es llamar a la clase falsa o cero. La **clase negativa** y la verdadera o la clase uno, la **clase positiva**. Por ejemplo, para la clasificación del spam, un correo electrónico que no es spam se puede denominar ejemplo negativo. Porque la salida a la pregunta de es un spam. La salida es no o cero. Por el contrario, un correo electrónico que tiene spam puede denominarse ejemplo de entrenamiento positivo. Porque la respuesta a es spam es sí o verdadero o uno para ser claros, negativo y positivo. No significan necesariamente malo frente a bueno o malvado frente a bueno. Es sólo que los ejemplos negativos y positivos se utilizan para transmitir los conceptos de ausencia o cero o falso frente a la presencia o verdadero o uno de algo que podría estar buscando. Como la ausencia o presencia de la enfermedad de spam o la propiedad de spam de un correo electrónico o la ausencia de presencia de actividad de ampliación o ausencia de presencia de malignidad del tumor. \n",
    "\n",
    "Entre los correos electrónicos no spam y spam. Cuál se llama falso o cero y cuál se llama verdadero o uno es un poco arbitrario. A menudo cualquiera de las dos opciones podría funcionar. Así que un ingeniero diferente podría cambiarla y tener la clase positiva B. La presencia de un buen correo electrónico o las posibles causas ser la presencia de una transacción financiera real o un paciente sano. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_04.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Entonces, ¿cómo se construye un algoritmo de clasificación? He aquí el ejemplo de un conjunto de entrenamiento para clasificar si el tumor es maligno. Una clase uno clase positivas, sí cláusula o la clase nueve cero o clase negativa. He trazado tanto el tamaño del tumor en el eje horizontal como la etiqueta Y en el eje vertical. Por cierto, en la primera semana, cuando hablamos por primera vez sobre la clasificación. Así es como lo visualizamos previamente en la línea numérica, excepto que ahora estamos llamando a las clases cero y uno, y trazarlos en el eje vertical. \n",
    "\n",
    "Ahora, una cosa que podrías intentar en este conjunto de entrenamiento es aplicar el algoritmo que ya conoces. Regresión lineal y tratar de ajustar una línea recta a los datos. Si haces eso, tal vez la línea recta se vea así, ¿verdad? Y ese es tu efecto F. La regresión lineal predice no sólo los valores cero y uno. Sino todos los números entre cero y uno o incluso menos de cero o más de uno. Pero aquí queremos predecir categorías. \n",
    "\n",
    "Una cosa que podría intentar es elegir un **umbral** de, por ejemplo, 0,5. De modo que si el modelo produce un valor inferior a 0,5, entonces se predice por qué es igual a cero o no es maligno. Y si el modelo arroja un número igual o superior a 0,5, entonces predice que Y es igual a uno o maligno. Observe que este valor de umbral de 0,5 se cruza con la línea recta de mejor ajuste en este punto. Así que si dibujas esta línea vertical aquí, todo a la izquierda termina con una predicción de y igual a cero. Y todo a la derecha termina con la predicción de y igual a uno. Ahora, para este conjunto de datos en particular parece que la regresión lineal podría hacer algo razonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_05.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Pero ahora veamos qué sucede si su conjunto de datos tiene un ejemplo de entrenamiento más. Este de aquí a la derecha. También vamos a ampliar el eje horizontal. Observe que este ejemplo de entrenamiento no debería cambiar realmente la forma de clasificar los puntos de datos. Esta línea divisoria vertical que acabamos de dibujar todavía tiene sentido como el corte donde los tumores más pequeños que esto deben ser clasificados como cero. Y los tumores mayores que esto deben ser clasificados como uno. Pero una vez que has añadido este ejemplo de entrenamiento extra a la derecha. La línea de mejor ajuste para la regresión lineal se desplazará así. Y si continúa usando el umbral de 0,5, ahora notará que todo lo que está a la izquierda de este punto se predice como cero no maligno. Y todo lo que está a la derecha de este punto se predice como uno o maligno. \n",
    "\n",
    "Esto no es lo que queremos porque añadir ese ejemplo a la derecha no debería cambiar ninguna de nuestras conclusiones sobre cómo clasificar los tumores malignos frente a los benignos. Pero si tratamos de hacer esto con la regresión lineal, añadiendo este ejemplo que parece que no debería cambiar nada. Termina con nosotros el aprendizaje de una función mucho peor para este problema de clasificación. Claramente, cuando el tumor es grande, queremos que el algoritmo lo clasifique como maligno. Así que lo que acabamos de ver fue la regresión lineal que provoca la línea de mejor ajuste. Cuando añadimos un ejemplo más a la derecha para desplazarse. Y hace que la línea divisoria, también llamada límite de decisión, se desplace hacia la derecha. \n",
    "\n",
    "Aprenderás más sobre el límite de decisión en el siguiente video, también aprenderás sobre un algoritmo llamado **regresión logística**. Donde el valor de salida del resultado siempre estará entre cero y uno. Y el promedio evitará estos problemas que estamos viendo en esta diapositiva. Por cierto una cosa que confunde el nombre de regresión logística es que aunque tiene la palabra de regresión en realidad se utiliza para la clasificación. No te confundas por el nombre que se le dio por razones históricas. En realidad se utiliza para resolver problemas de clasificación binaria con una etiqueta de salida y que puede ser cero o uno. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "¿Cuál de los siguientes es un ejemplo de tarea de clasificación?\n",
    "- Decidir si un animal es un gato o no es un gato.\n",
    "- Estimar el peso de un gato en función de su altura.\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Decidir si un animal es un gato o no es un gato.\n",
    "    \n",
    "Este es un ejemplo de clasificación binaria en el que hay dos clases posibles (Verdadero/Falso o Sí/No o 1/0).\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el próximo laboratorio opcional también podrás echar un vistazo a lo que ocurre cuando intentas utilizar la regresión lineal para la clasificación. A veces tienes suerte y puede funcionar, pero a menudo no funciona bien. Por eso yo mismo no utilizo la regresión lineal para la clasificación. En el laboratorio opcional, puedes ver un gráfico interactivo que intenta clasificar entre dos categorías. Y es de esperar que notes cómo esto a menudo no funciona muy bien. Lo cual está bien porque eso motiva la necesidad de un modelo diferente para hacer charlas de clasificación. Así que por favor, echa un vistazo a este laboratorio opcional y después de que vamos a la siguiente vídeo para mirar a la regresión logística para la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/168THPLbtmmkmSEqlLfX7JVK81-2_E1zq/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hablemos de la regresión logística, que es probablemente el algoritmo de clasificación más utilizado en el mundo. Es algo que utilizo constantemente en mi trabajo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_07.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Sigamos con el ejemplo de clasificar si un tumor es maligno. Mientras que antes vamos a utilizar la etiqueta 1 o sí a la clase positiva para representar los tumores malignos, y cero o no y los ejemplos negativos para representar los tumores benignos. Aquí tenemos un gráfico del conjunto de datos en el que el eje horizontal es el tamaño del tumor y el eje vertical sólo toma valores de 0 y 1, porque es un problema de clasificación. Ya has visto en el último vídeo que la regresión lineal no es un buen algoritmo para este problema. En cambio, lo que acabamos haciendo con la regresión logística es ajustar una curva que tiene este aspecto, una curva en forma de S, a este conjunto de datos. Para este ejemplo, si un paciente viene con un tumor de este tamaño, que estoy mostrando en el eje $x$, entonces el algoritmo dará como resultado 0,7 sugiriendo que está más cerca o tal vez más probable de ser maligno y benigno. Diré más adelante lo que significa realmente 0,7 en este contexto. Pero la etiqueta de salida $y$ nunca es 0,7 sólo es 0 o 1. \n",
    "\n",
    "Para construir el algoritmo de regresión logística, hay una función matemática importante que me gusta describir que se llama la función sigmoide, a veces también se refiere a la función logística. La función Sigmoide se ve así. Observa que el eje $x$ del gráfico de la izquierda y de la derecha son diferentes. En la gráfica de la izquierda (el de arriba) en el eje $x$ está el tamaño del tumor, por lo que son todos números positivos. Mientras que en el gráfico de la derecha (el de aca), tienes 0 aquí abajo, y el eje horizontal toma valores negativos y positivos y han etiquetado el eje horizontal Z. Estoy mostrando aquí sólo un rango de -3  a  3. Así que el valor de salida de la función Sigmoide está entre 0 y 1. Si uso $g(z)$ para denotar esta función, entonces la fórmula de $g(z) = \\frac{1}{1+e^{-z}}$. Donde aquí $e$ es una constante matemática que toma un valor de alrededor de 2,7, y así $e^{-z}$ es esa constante matemática a la potencia del negativo $z$. \n",
    "\n",
    "Observe si $z$ donde realmente es, digamos un 100, $e^{-z}$ es $e^{-100}$ que es un número pequeño. Así que esto termina siendo 1 sobre 1 más un pequeño número, y así el denominador será básicamente muy cercano a 1. Por eso, cuando $z$ es grande, $g(z)$ que es una función sigmoidea de $z$ va a estar muy cerca de 1. A la inversa, también puedes comprobar por ti mismo que cuando $z$ es un número negativo muy grande, entonces $g(z)$ se convierte en 1 sobre un número gigante, por lo que $g(z)$ está muy cerca de 0. Por eso la función sigmoide tiene esta forma en la que empieza muy cerca de cero y poco a poco se va acumulando o creciendo hasta el valor de uno. \n",
    "\n",
    "Además, en la función sigmoidea cuando $z$ es igual a 0, entonces e al negativo de $z$ es e al negativo de 0 que es igual a 1, y por lo tanto $g(z)=\\frac{1}{1+1}$ es igual a 1 sobre 1 más 1 que es 0,5, por eso pasa el eje vertical en 0,5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_08.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, vamos a utilizar esto para construir el algoritmo de regresión logística. Vamos a hacer esto en dos pasos:\n",
    "\n",
    "- En el primer paso, espero que recuerdes que una función de línea recta, como una función de regresión lineal puede ser definida como ${w·x + b}$. Vamos a almacenar este valor en una variable que voy a llamar $z$, y esta resultará ser la misma $z$ que viste en la diapositiva anterior, pero llegaremos a eso en un minuto. \n",
    "\n",
    "- El siguiente paso es tomar este valor de $z$ y pasarlo a la función sigmoidea, también llamada función logística, $g$. Ahora, $g(z)$ da como resultado un valor calculado por esta fórmula, $\\frac{1}{1+e^{-z}}$. Va a estar entre 0 y 1. Cuando tomas estas dos ecuaciones y las pones juntas, te dan el modelo de regresión logística $f(x)$, que es igual a $g(w·x + b)$. O equivalentemente $g(z)$, que es igual a esta fórmula de aquí. Este es el modelo de regresión logística, y lo que hace es que introduce la característica o el conjunto de características $x$ y da como resultado un número entre 0 y 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_09.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "A continuación, vamos a echar un vistazo a cómo interpretar el resultado de la regresión logística. Volveremos al ejemplo de la clasificación de tumores. La forma en que le animo a pensar en la salida de la regresión logística es pensar en ella como la salida de la probabilidad de que la clase o la etiqueta $y$ sea igual a 1 dada una determinada entrada $x$. Por ejemplo, en esta aplicación, en la que $x$ es el tamaño del tumor e $y$ es 0 o 1, si llega una paciente y tiene un tumor de un determinado tamaño $x$, y si, basándose en esta entrada $x$, el modelo suma 0,7, entonces lo que significa es que el modelo predice o piensa que hay un 70 por ciento de posibilidades de que la verdadera etiqueta y sea igual a 1 para esta paciente. En otras palabras, el modelo nos dice que cree que el paciente tiene un 70% de posibilidades de que el tumor sea maligno. \n",
    "\n",
    "Ahora, déjame hacerte una pregunta. A ver si lo consigues. Sabemos que y tiene que ser o bien 0 o bien 1, así que si y tiene un 70% de posibilidades de ser 1, ¿cuál es la probabilidad de que sea 0? Así que y tiene que ser o bien 0 o bien 1, y por lo tanto la probabilidad de que sea 0 o 1 estos dos números tienen que sumar uno o una probabilidad del 100 por ciento. Por eso, si la probabilidad de que $y$ sea 1 es del 0,7 o del 70%, la probabilidad de que sea 0 tiene que ser del 0,3 o del 30%. \n",
    "\n",
    "Si algún día lees artículos de investigación o tiras de blog de toda la regresión logística, a veces ves esta notación de que $f(x)$ es igual a $p(1)$ es igual a 1 dadas las características de entrada $x$ y con los parámetros $w$ y $b$. Lo que el \";\" aquí se utiliza para denotar es sólo que $w$ y $b$ son parámetros que afectan a este cálculo de ¿cuál es la probabilidad de que y sea igual a 1 dada la característica de entrada $x$? Para el propósito de esta clase, no te preocupes demasiado por lo que significa esta línea vertical y el punto y coma. No es necesario que recuerdes o sigas nada de esta notación matemática para esta clase. Lo menciono sólo porque es posible que lo veas en otros lugares. \n",
    "\n",
    "En el laboratorio opcional que sigue a este video, también puedes ver cómo se implementa la función Sigmoide en el código. Podrás ver un gráfico que utiliza la función Sigmoide para hacer mejor las tareas de clasificación que viste en el laboratorio opcional anterior. Recuerda que el código se te proporcionará, así que sólo tienes que ejecutarlo. Espero que le eches un vistazo y te familiarices con el código. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Recordemos que la función sigmoidea es $g(z)=\\frac{1}{1+e^{-z}}$ . Si z es un número negativo grande entonces\n",
    "- $g(z)$ está cerca de uno negativo (-1) \n",
    "- $g(z)$ está cerca de cero\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "$g(z)$ está cerca de cero.\n",
    "    \n",
    "Digamos que $z=-100.e^{-z}$ es entonces $e^{-100}$, un número positivo realmente grande. Entonces, $g(z) = 1 +$ un número positivo grande o aproximadamente 0.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhorabuena por haber llegado hasta aquí. Ahora ya sabes qué es el modelo de regresión logística, así como la fórmula matemática que define la regresión logística. Durante mucho tiempo, una gran cantidad de publicidad en Internet fue en realidad impulsada por básicamente una ligera variación de la regresión logística. Esto era muy lucrativo para algunas grandes empresas, y esto es básicamente el algoritmo que decidía qué anuncio se le mostraba a usted y a muchos otros en algunos grandes sitios web. Ahora, hay, incluso más, para aprender sobre este algoritmo. En el siguiente video, echaremos un vistazo a los detalles de la regresión logística. Veremos algunas visualizaciones y también examinaremos algo llamado el límite de decisión. Esto le dará algunas maneras diferentes de asignar los números que este modelo produce, como 0,3, o 0,7, o 0,65 a una predicción de si y es realmente 0 o 1. Pasemos al siguiente vídeo para aprender más sobre la regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1jlHPzWA7k5K6MhxlGt2XPjQwenu-C1Fc/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, aprendiste sobre el modelo de regresión logística. Ahora, echemos un vistazo al límite de decisión para tener una mejor idea de cómo la regresión logística calcula estas predicciones. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_11.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Para recapitular, así es como se calculan los resultados de los modelos de regresión logística en dos pasos. En el primer paso, se calcula $z=w·x+b$. Luego se aplica la función sigmoidea $g$ a este valor $z$. Aquí también está la fórmula de la función sigmoidea. Otra forma de escribir esto es que podemos decir que $f(x)$ es igual a $g$, la función sigmoidea, también llamada función logística, aplicada a $w·x+b$, donde esto es, por supuesto, el valor de $z$. Si tomas la definición de la función sigmoidea y metes la definición de $z$, entonces encuentras que $f(x)$ es igual a esta fórmula de aquí, $\\frac{1}{1+e^{-z}}$, donde $z=wx+b$. Usted puede recordar que dijimos en el video anterior que interpretamos esto como la probabilidad de que $y$ es igual a 1 dado $x$ y con los parámetros $w$ y $b$. Esto va a ser un número como tal vez un 0,7 o 0,3. \n",
    "Ahora, ¿qué pasa si usted quiere aprender el algoritmo para predecir. ¿El valor de y va a ser cero o uno? Bien, una cosa que podrías hacer es establecer un umbral por encima del cual predices que y es uno, o estableces que $\\hat{y}$ es igual a uno y por debajo del cual podrías decir $\\hat{y}$, mi predicción va a ser igual a cero. \n",
    "\n",
    "Una opción común sería elegir un umbral de 0,5, de modo que si $f(x)$ es mayor o igual a 0,5, entonces predice que $y$ es uno. Escribimos esa predicción como $\\hat{y}$ igual a 1, o si $f(x)$ es menor que 0,5, entonces la predicción $y$ es 0, o en otras palabras, la predicción $\\hat{y}$ es igual a 0. \n",
    "\n",
    "Ahora, profundicemos en cuándo el modelo predeciría uno. En otras palabras, cuando $f(x)$ es mayor o igual a 0,5. Recordemos que $f(x)=g(z)$. Así que f es mayor o igual a 0,5 siempre que $g(z)$ sea mayor o igual a 0,5. Pero, ¿cuándo $g(z)$ es mayor o igual que 0,5? Bueno, aquí tenemos una función sigmoidea. Así que $g(z)$ es mayor o igual a 0,5 siempre que z sea mayor o igual a 0. Es decir, siempre que $z$ esté en la mitad derecha de este eje. \n",
    "\n",
    "Finalmente, ¿cuándo es $z$ mayor o igual a cero? Bueno, $z$ es igual a $w·x+b$, por lo que $z$ es mayor o igual a cero siempre que $w·x+b$ sea mayor o igual a cero. \n",
    " \n",
    "Para recapitular, lo que has visto aquí es que el modelo predice 1 siempre que $w·x+b$ es mayor o igual que 0. A la inversa, cuando $w·x+b$ es menor que cero, el algoritmo predice que $y$ es 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_12.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Dado esto, vamos a visualizar ahora cómo el modelo hace predicciones. Voy a tomar un ejemplo de un problema de clasificación en el que tienes dos características, $x_1$ y $x_2$ en lugar de una sola característica. Aquí hay un conjunto de entrenamiento donde las pequeñas cruces rojas denotan los ejemplos positivos y los pequeños círculos azules denotan los ejemplos negativos. Las cruces rojas corresponden a $y=1$, y los círculos azules corresponden a $y=0$. El modelo de regresión logística hará predicciones usando esta función $f(x)$ igual a $g(z)$, donde $z$ es ahora esta expresión de aquí, $w_1x_1+w_2x_2+b$, porque tenemos dos características $x_1$ y $x_2$. \n",
    "\n",
    "Digamos para este ejemplo que el valor de los parámetros son $w_1=1$, $w_2=1$, y $b=-3$ negativo. Veamos ahora cómo la regresión logística hace predicciones. En concreto, vamos a averiguar cuándo $wx+b$ es mayor que igual a 0 y cuándo $wx+b$ es menor que 0. Para averiguarlo, hay una línea muy interesante que hay que mirar, que es cuando $wx+b$ es exactamente igual a 0. Resulta que esta línea también se llama el límite de decisión porque es la línea en la que eres casi neutral sobre si $y$ es 0 o $y$ es 1.\n",
    "\n",
    "Ahora, para los valores de los parámetros $w_1$, $w_2$, y $b$ que habíamos escrito anteriormente, este límite de decisión es sólo $x_1+x_2-3$. ¿Cuándo $x_1+x_2-3=0$? Bueno, eso corresponderá a la línea $x_1+x2=3$, y esa es esta línea que se muestra aquí. Esta línea resulta ser el límite de decisión, donde si las características x están a la derecha de esta línea, la regresión logística predeciría 1 y a la izquierda de esta línea, la regresión logística con predice 0. \n",
    "\n",
    "En otras palabras, lo que acabamos de visualizar es el límite de decisión para la regresión logística cuando los parámetros $w_1$, $w_2$ y $b$ son 1, 1 y -3. Por supuesto, si tuviéramos una elección diferente de los parámetros, la frontera de decisión sería una línea diferente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_13.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "Ahora veamos un ejemplo más complejo en el que la frontera de decisión ya no es una línea recta. Como antes, las cruces denotan que la clase $y=1$, y los pequeños círculos denotan que la clase $y=0$. A principios de la semana pasada, vio cómo utilizar polinomios en la regresión lineal, y puede hacer lo mismo en la regresión logística. Esto hace que $z$ sea $w_1x_1^{2}+w_2x_2^{2}+b$. Esto hace que $z$ sea $w_1x_1^{2}+w_2x_2^{2}+b$. Con esta elección de características, las características polinómicas en una regresión logística. $F(x)$, que es igual a $g(z)$, es ahora $g$ de esta expresión de aquí. Digamos que terminamos eligiendo $w_1$ y $w_2$ para ser 1 y $b$ para ser negativo 1. $Z$ es igual a 1 veces $x_1^{2}+x_2^{2}-1$. La frontera de decisión, como antes, corresponderá a cuando $z=0$. Esta expresión será igual a 0 cuando $x_1^{2}+x_2^{2}-1$. Si se traza en el diagrama de la izquierda, la curva correspondiente a $x_1^{2}+x_2^{2}=1$, ésta resulta ser el círculo. Cuando $x_1^{2}+x_2^{2}$ es mayor o igual a 1, es esta área fuera del círculo y es cuando se predice que $y=1$. A la inversa, cuando $x_1^{2}+x_2^{2}-1$, esa es esta área dentro del círculo y es cuando se predice que $y=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_14.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "¿Podemos crear límites de decisión aún más complejos que estos? Sí, se puede. Puedes hacerlo teniendo términos polinómicos de orden superior. Digamos que $z=w_1x_1+w_2x_2+w_3x_1^{2}+w_4x_1x_2+w_5x_2^{2}$. Entonces es posible obtener límites de decisión aún más complejos. El modelo puede definir límites de decisión, como en este ejemplo, una elipse como esta, o con una elección diferente de los parámetros. Incluso puedes obtener límites de decisión más complejos, que pueden parecerse a funciones que tal vez se vean así. Así que este es un ejemplo de un límite de decisión aún más complejo que los que hemos visto anteriormente. Esta implementación de la regresión logística predecirá que $y=1$ dentro de esta forma y fuera de la forma predecirá que $y=0$. Con estas características polinómicas, puedes obtener límites de decisión muy complejos. En otras palabras, la regresión logística puede aprender a ajustarse a datos bastante complejos. Aunque si no incluye ninguno de estos polinomios de orden superior, es decir, si las únicas características que utiliza son $x_1$, $x_2$, $x_3$, etc., entonces el límite de decisión para la regresión logística siempre será lineal, siempre será una línea recta. \n",
    "\n",
    "En el próximo laboratorio opcional, también podrá ver la implementación del código del límite de decisión. En el ejemplo del laboratorio, habrá dos características para que puedas ver el límite de decisión como una línea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Digamos que está creando un algoritmo de detección de tumores. Su algoritmo se utilizará para marcar posibles tumores para una futura inspección por parte de un especialista. ¿Qué valor debería utilizar para un umbral?\n",
    "- ¿Alto, por ejemplo un umbral de 0,9? \n",
    "- ¿Bajo, digamos un umbral de 0,2?\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "¿Bajo, digamos un umbral de 0,2?.\n",
    "    \n",
    "No querrá pasar por alto un posible tumor, por lo que querrá un umbral bajo. Un especialista revisará la salida del algoritmo, lo que reduce la posibilidad de un \"falso positivo\". El punto clave de esta pregunta es observar que el valor del umbral no tiene por qué ser 0,5.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta visualización, espero que ahora tenga una idea de la gama de posibles modelos que puede obtener con la regresión logística. Ahora que ha visto lo que $f(x)$ puede calcular potencialmente, echemos un vistazo a cómo puede entrenar realmente un modelo de regresión logística. Empezaremos por ver la función de coste de la regresión logística y, después, veremos cómo aplicarle el descenso de gradiente. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice quiz: Classification with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "¿Cuál es un ejemplo de tarea de clasificación?\n",
    "\n",
    "- Basándose en la presión arterial de un paciente, determinar qué cantidad de medicación para la presión arterial (una dosis medida en miligramos) debería recetarse al paciente.\n",
    "- Basándose en la edad y la presión arterial de un paciente, determine qué cantidad de medicación para la presión arterial (medida en miligramos) debe recetarse al paciente.\n",
    "- Basándose en el tamaño de cada tumor, determine si cada tumor es maligno (canceroso) o no.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Recuerda que la función sigmoidea $g(z)=\\frac{1}{1+e^{-z}}$. Si $z$ es un número positivo grande, entonces\n",
    "\n",
    "- g(z) está cerca de uno negativo (-1) \n",
    "- g(z) está cerca de uno (1)\n",
    "- g(z) estará cerca de cero (0) \n",
    "- g(z) estará cerca de 0,5 \n",
    "\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "Un modelo de clasificación de fotos de gatos predice 1 si es un gato y 0 si no es un gato. Para una fotografía concreta, el modelo de regresión logística da como resultado $g(z)$ (un número entre 0 y 1). ¿Cuál de estos sería un criterio razonable para decidir si se predice si es un gato?\n",
    "\n",
    "- Predecir que es un gato si $g(z)<0,7$  \n",
    "- Predecir que es un gato si $g(z)<0,5$  \n",
    "- Predecir que es un gato si $g(z)>=0.5$ \n",
    "- Predecir que es un gato si $g(z)=0,5$  \n",
    " \n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 4 </b></font>\n",
    "\n",
    "¿Verdadero/Falso? Independientemente de las características que utilice (incluso si utiliza características polinómicas), el límite de decisión aprendido por la regresión logística será un límite de decisión lineal. \n",
    " \n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1: Basándose en el tamaño de cada tumor, determine si cada tumor es maligno (canceroso) o no.\n",
    "\n",
    "Respuesta 2: $g(z)$ está cerca de uno 1.\n",
    "    \n",
    "Respuesta 3: Predecir que es un gato si $g(z)>=0.5$.\n",
    "    \n",
    "Respuesta 4: Falso.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COST FUNCTION FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1elekZafBxoUqrFW5YBbpvfEJh8eRJVH0/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde que la función de coste le proporciona una forma de medir lo bien que un conjunto específico de parámetros se ajusta a los datos de entrenamiento. Por lo tanto, le da una manera de tratar de elegir mejores parámetros. En este vídeo, veremos cómo la función de coste del error cuadrado no es una función de coste ideal para la regresión logística. Veremos una función de coste diferente que puede ayudarnos a elegir mejores parámetros para la regresión logística. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_16.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Este es el conjunto de entrenamiento para nuestro modelo de regresión logística. En este caso, cada fila podría corresponder a los pacientes que han visitado al médico y que han recibido algún diagnóstico. Como antes, utilizaremos m para denotar el número de ejemplos de entrenamiento. Cada ejemplo de entrenamiento tiene una o más características, como el tamaño del tumor, la edad del paciente, etc. para un total de n características. Llamemos a las características $x_1$ a $x_n$. Como se trata de una tarea de clasificación binaria, la etiqueta objetivo y sólo toma dos valores, 0 o 1. Por último, el modelo de regresión logística se define mediante esta ecuación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_17.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "La pregunta que se quiere responder es, dado este conjunto de entrenamiento, ¿cómo se pueden elegir los parámetros $w$ y $b$? Recordemos que para la regresión lineal, esta es la función de coste del error cuadrado. Lo único que he cambiado es que he puesto la mitad dentro de la suma en lugar de fuera de la suma. Usted puede recordar que en el caso de la regresión lineal, donde $f(x)$ es la función lineal, $w·x+b$. La función de costo se ve así, es una función convexa o una forma de tazón o martillo. El descenso gradual se verá así, donde se da un paso, un paso, y así sucesivamente para converger en el mínimo global. Ahora usted podría tratar de utilizar la misma función de coste para la regresión logística. \n",
    "\n",
    "Pero resulta que si escribiera $f(x)=\\frac{1}{1+e^{-(w·x+b)}}$ y trazara la función de coste usando este valor de $f(x)$, entonces el coste se verá así. Esto se convierte en lo que se llama una función de coste no convexa no es convexa. Lo que esto significa es que si usted fuera a tratar de utilizar el descenso de gradiente, hay un montón de mínimos locales que usted puede conseguir atraparse. Resulta que para la regresión logística, esta función de coste de error cuadrado no es una buena opción. En su lugar, habrá una función de coste diferente que puede hacer que la función de coste sea convexa de nuevo. Se puede garantizar que el descenso del gradiente converja al mínimo global. Lo único que he cambiado es que he puesto la mitad dentro de la suma en lugar de fuera de la suma. Esto hará que las matemáticas que se ven más adelante en esta diapositiva un poco más simple. \n",
    "\n",
    "Para construir una nueva función de costo, una que usaremos para la regresión logística. Voy a cambiar un poco la definición de la función de costo $J(w,b)$. En particular, si usted mira dentro de esta suma, vamos a llamar a este término dentro de la pérdida en un solo ejemplo de entrenamiento. Voy a denotar la pérdida a través de esta mayúscula $L$ y como una función de la predicción del algoritmo de aprendizaje, $f(x)$ así como de la verdadera etiqueta $y$. La pérdida dada la predicción $f(x)$ y la verdadera etiqueta $y$ es igual en este caso a 1,5 de la diferencia al cuadrado. Veremos en breve que eligiendo una forma diferente para esta función de pérdida, podremos mantener la función de coste global, que es 1 sobre $n$ veces la suma de estas funciones de pérdida para que sea una función convexa. \n",
    "\n",
    "Ahora, la función de pérdida entradas $f(x)$ y la etiqueta verdadera y nos dice lo bien que estamos haciendo en ese ejemplo. Voy a escribir aquí en la definición de la función de pérdida que vamos a utilizar para la regresión logística. Si la etiqueta $y=1$, entonces la pérdida es el logaritmo negativo de $f(x)$ y si la etiqueta $y=0$, entonces la pérdida es el $-log(1-f(x))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_18.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos por qué esta función de pérdida tiene sentido. Consideremos primero el caso de $y=1$ y grafiquemos el aspecto de esta función para obtener alguna intuición sobre lo que hace esta función de pérdida. Recuerde, la función de pérdida mide lo bien que está haciendo en un ejemplo de entrenamiento y es mediante la suma de las pérdidas en todos los ejemplos de entrenamiento que luego se obtiene, la función de coste, que mide lo bien que está haciendo en todo el conjunto de entrenamiento. \n",
    "\n",
    "Si graficas el $log(f)$, se parece a esta curva, donde $f$ está en el eje horizontal. Un gráfico de un negativo del $log(f)$ se parece a esto, donde acabamos de voltear la curva a lo largo del eje horizontal. Observe que se cruza el eje horizontal en $f=1$ y continúa hacia abajo desde allí. Ahora, $f$ es el resultado de la regresión logística. Por lo tanto, $f$ está siempre entre cero y uno porque la salida de la regresión logística está siempre entre cero y uno. La única parte de la función que es relevante es, por tanto, esta parte de aquí, que corresponde a $f$ entre 0 y 1. \n",
    "\n",
    "Acerquémonos y veamos con más detalle esta parte del gráfico. Si el algoritmo predice una probabilidad cercana a 1 y la etiqueta verdadera es 1, entonces la pérdida es muy pequeña. Es prácticamente 0 porque está muy cerca de la respuesta correcta. Ahora continuamos con el ejemplo de que la etiqueta verdadera y es 1, digamos que todo es un tumor maligno. Si el algoritmo predice 0,5, entonces la pérdida está en este punto de aquí, que es un poco más alto pero no tan alto. Mientras que en contraste, si el algoritmo tuviera salidas en 0,1 si piensa que sólo hay un 10 por ciento de posibilidades de que el tumor sea maligno pero y realmente es 1. Si realmente es maligno, entonces la pérdida es este valor mucho más alto aquí. Cuando y es igual a 1, la función de pérdida incentiva o nutre, o ayuda a empujar al algoritmo a hacer predicciones más precisas porque la pérdida es menor, cuando predice valores cercanos a 1. Ahora, en esta diapositiva, veremos cuál es la pérdida cuando y es igual a 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_19.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En esta diapositiva, vamos a ver la segunda parte de la función de pérdida correspondiente a cuando y es igual a 0. En este caso, la pérdida es el $-log(1-f(x))$. Cuando esta función se traza, en realidad se ve así. El rango de $f$ está limitado a 0 y 1 porque la regresión logística sólo produce valores entre 0 y 1. Si ampliamos la imagen, esto es lo que parece. En este gráfico, correspondiente a $y=0$, el eje vertical muestra el valor de la pérdida para diferentes valores de $f(x)$. Cuando $f=0$ o muy cercano a 0, la pérdida también va a ser muy pequeña, lo que significa que si la etiqueta verdadera es 0 y la predicción del modelo está muy cerca de 0, bueno, casi has acertado, así que la pérdida es apropiadamente muy cercana a 0. Cuanto mayor sea el valor de $f(x)$, mayor será la pérdida porque la predicción está más lejos de la etiqueta verdadera 0. De hecho, a medida que la predicción se acerca a 1, la pérdida se aproxima al infinito. Volviendo al ejemplo de la predicción de un tumor, sólo decimos que si el modelo predice que el tumor del paciente es casi seguro que sea maligno, digamos, un 99,9 por ciento de probabilidad de malignidad, resulta que en realidad no es maligno, por lo que y es igual a 0, entonces penalizamos el modelo con una pérdida muy alta. En este caso de y igual a 0, así que esto es en el caso de $y=1$ en la diapositiva anterior, cuanto más lejos esté la predicción $f(x)$ del verdadero valor de $y$, mayor será la pérdida. De hecho, si $f(x)$ se acerca a 0, la pérdida aquí es realmente grande y de hecho se acerca al infinito. Cuando la etiqueta verdadera es 1, el algoritmo está fuertemente incentivado para no predecir algo demasiado cercano a 0. \n",
    "\n",
    "En este vídeo, has visto por qué la función de coste del error cuadrado no funciona bien para la regresión logística. También definimos la pérdida para un solo ejemplo de entrenamiento y llegamos a una nueva definición de la función de pérdida para la regresión logística. Resulta que con esta elección de la función de pérdida, la función de coste global será convexa y, por lo tanto, se puede utilizar de forma fiable el descenso del gradiente para llegar al mínimo global. Demostrar que esta función es convexa, está más allá del alcance de este coste. Puede recordar que la función de coste es una función de todo el conjunto de entrenamiento y es, por tanto, la media o 1 sobre $m$ veces la suma de la función de pérdida en los ejemplos individuales de entrenamiento. El coste en un determinado conjunto de parámetros, $w$ y $b$, es igual a 1 sobre $m$ veces la suma de todos los ejemplos de entrenamiento de la pérdida en los ejemplos de entrenamiento. Si puedes encontrar el valor de los parámetros, $w$ y $b$, que minimiza esto, entonces tendrás un buen conjunto de valores para los parámetros $w$ y $b$ para la regresión logística. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "¿Por qué no se utiliza el coste del error cuadrado en la regresión logística?\n",
    "\n",
    "- La naturaleza no lineal del modelo da lugar a una función de costes \"ondulada\" y no convexa con muchos mínimos locales potenciales.\n",
    "- En la regresión logística se utiliza el error cuadrático medio.\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "La naturaleza no lineal del modelo da lugar a una función de costes \"ondulada\" y no convexa con muchos mínimos locales potenciales.\n",
    "    \n",
    "Si se utiliza el error cuadrático medio para la regresión logística, la función de coste es \"no convexa\", por lo que es más difícil para el descenso de gradiente encontrar un valor óptimo para los parámetros $w$ y $b$.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el próximo laboratorio opcional, podrás echar un vistazo a cómo la función de coste del error cuadrado no funciona muy bien para la clasificación, porque ves que el gráfico de la superficie resulta en una superficie de costes muy ondulada con muchos mínimos locales. A continuación, echaremos un vistazo a la nueva función de pérdida logística. Como se puede ver aquí, esto produce un bonito y suave gráfico de superficie convexa que no tiene todos esos mínimos locales. Por favor, eche un vistazo a los costos y las parcelas después de este video. \n",
    "\n",
    "Hemos visto mucho en este vídeo. En el próximo vídeo, volveremos a tomar la función de pérdida para un solo ejemplo de entrenamiento y la utilizaremos para definir la función de coste global para todo el conjunto de entrenamiento. También descubriremos una forma más sencilla de escribir la función de coste, lo que nos permitirá más tarde ejecutar el descenso de gradiente para encontrar buenos parámetros para la regresión logística. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Cost Function for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1ceFUJAPCyMYh7mqPO8m3liOtxJaHhLur/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo vimos la función de pérdida y la función de coste para la regresión logística. En este vídeo verás una forma un poco más sencilla de escribir las funciones de pérdida y de coste, para que la implementación pueda ser un poco más sencilla cuando lleguemos al descenso de gradiente para ajustar los parámetros de un modelo de regresión logística. Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_22.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Como recordatorio, aquí está la función de pérdida que habíamos definido en el vídeo anterior para la regresión logística. Como todavía estamos trabajando en un problema de clasificación binaria, y es cero o uno. Debido a que y es cero o uno y no puede tomar ningún valor distinto de cero o uno, vamos a ser capaces de llegar a una forma más sencilla de escribir esta función de pérdida. \n",
    "\n",
    "Se puede escribir la función de pérdida de la siguiente manera (recuadro negro). Dada una predicción $f(x)$ y la etiqueta objetivo $y$, la pérdida es igual a $-ylog(f)-(1-y)log(1-f)$. Resulta que esta ecuación, que acabamos de escribir en una línea, es completamente equivalente a esta fórmula más compleja de aquí arriba. Veamos por qué es así. Recuerda que y sólo puede tomar los valores de uno o cero. \n",
    "\n",
    "En el primer caso, digamos que $y$ es igual a 1. Este primer $y$ de aquí es uno y este $(1-y)$ es 1 menos 1, que por lo tanto es igual a 0. Así que la pérdida se convierte en $-1logf(x)-0$ por un montón de cosas. Eso se convierte en cero y desaparece. Cuando $y=1$, la pérdida es de hecho el primer término en la parte superior, logaritmo negativo de $f(x)$. \n",
    "\n",
    "Veamos el segundo caso, cuando $y=0$. En este caso, este y aquí es igual a 0, por lo que este primer término desaparece, y el segundo término es 1 menos 0 veces ese término logarítmico. La pérdida se convierte en este $-1log(1-f(x))$. Eso es igual a este segundo término aquí arriba. En el caso de $y=0$, también obtenemos de nuevo la función de pérdida original como se define anteriormente. \n",
    "\n",
    "Lo que se ve es que si y es uno o cero, esta única expresión aquí es equivalente a la expresión más compleja aquí, por lo que esto nos da una forma más sencilla de escribir la pérdida con una sola ecuación sin separar estos dos casos, como lo hicimos en la parte superior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_23.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Usando esta función de pérdida simplificada, volvamos a escribir la función de coste para la regresión logística. Aquí está de nuevo la función de pérdida simplificada. Recordemos que el costo $J$ es sólo la pérdida promedio, el promedio a través de todo el conjunto de entrenamiento de $m$ ejemplos. Así que es $\\frac{1}{m}$ veces la suma de la pérdida de $i$ es igual a 1 a $m$. Si se introduce la definición de la pérdida simplificada de arriba, entonces se ve así, $\\frac{1}{m}$ veces la suma de este término de arriba. Si traes los signos negativos y los mueves fuera, entonces terminas con esta expresión aquí, y esta es la función de costo. La función de costo que casi todo el mundo utiliza para entrenar la regresión logística. \n",
    "\n",
    "Usted podría preguntarse, ¿por qué elegimos esta función en particular cuando podría haber toneladas de otras funciones de costos que podríamos haber elegido? Aunque no tendremos tiempo de entrar en grandes detalles sobre esto en esta clase, sólo me gustaría mencionar que esta función de coste particular se deriva de la estadística utilizando un principio estadístico llamado estimación de máxima verosimilitud, que es una idea de la estadística sobre cómo encontrar eficientemente los parámetros para diferentes modelos. Esta función de coste tiene la bonita propiedad de ser convexa. Pero no te preocupes por aprender los detalles de la máxima verosimilitud. Es sólo un razonamiento más profundo y una justificación detrás de esta función de coste particular. \n",
    "\n",
    "El próximo laboratorio opcional le mostrará cómo se implementa la función de coste logístico en el código. Te recomiendo que le eches un vistazo, porque lo implementarás más tarde en el laboratorio de prácticas al final de la semana. Este próximo laboratorio opcional también le muestra cómo dos opciones diferentes de los parámetros dará lugar a diferentes cálculos de costos. Puede ver en el gráfico que el límite de decisión azul, que se ajusta mejor, tiene un coste menor en relación con el límite de decisión magenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Para la función de pérdida simplificada $L(f_{w,b}(x^{i}),y^{(i)})=-y^{(i)}log(f_{w,b}(x^{i}))-(1-y^{(i)})log(1-f_{w,b}(x^{(i)}))$ si el objetivo $y^{(i)}=1$, ¿a qué se simplifica esta expresión?\n",
    "- $-log(f_{w,b}(x^{i}))$\n",
    "- $-log(1-f_{w,b}(x^{(i)}))$\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "$-log(1-f_{w,b}(x^{(i)}))$.\n",
    "    \n",
    "El segundo término de la expresión se reduce a cero cuando el objetivo es igual a 1.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que, con la función de coste simplificada, ya estamos preparados para aplicar el descenso de gradiente a la regresión logística. Vamos a ver que en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Cost function for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "En esta serie de conferencias, \"coste\" y \"pérdida\" tienen significados distintos. ¿Cuál de ellos se aplica a un solo ejemplo de formación?\n",
    "\n",
    "- Pérdida\n",
    "- Coste \n",
    "- Tanto la pérdida como el coste\n",
    "- Ni pérdida ni coste \n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Para la función de pérdidas simplificada, si la etiqueta $y^{(i)}=0$, ¿a qué se simplifica esta expresión?\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/Ejercicio2.png\"   style=\"width:254;height:66;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "- $log(1-f_{w,b}(x^{(i)}))+log(1-f_{w,b}(x^{(i)}))$\n",
    "\n",
    "- $-log(1-f_{w,b}(x^{(i)}))$\n",
    "\n",
    "- $-log(f_{w,b}(x^{(i)}))$\n",
    "\n",
    "- $-log(1-f_{w,b}(x^{(i)}))-log(1-f_{w,b}(x^{(i)}))$\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1: Tanto la pérdida como el coste.\n",
    "\n",
    "Respuesta 2: $-log(1-f_{w,b}(x^{(i)}))$.\n",
    "   \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT DESCENT FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/18u23lkb-PR7XN7oi3qjWIbKT7eW5AwMo/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ajustar los parámetros de un modelo de regresión logística, vamos a tratar de encontrar los valores de los parámetros $w$ y $b$ que minimicen la función de coste $J(w,b)$, y para ello aplicaremos de nuevo el descenso gradiente. Veamos cómo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_26.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En este vídeo nos centraremos en cómo encontrar una buena elección de los parámetros $w$ y $b$. Una vez hecho esto, si le damos al modelo una nueva entrada, $x$, digamos un nuevo paciente en el hospital con un determinado tamaño de tumor y una determinada edad, entonces éstos son el diagnóstico. El modelo puede entonces hacer una predicción, o puede intentar estimar la probabilidad de que la etiqueta y sea una. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_27.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "La media que puede utilizar para minimizar la función de coste es el descenso de gradiente. Aquí está de nuevo la función de coste. Si quieres minimizar el coste $J$ como una función de $w$ y $b$, bueno, aquí está el algoritmo habitual de descenso de gradiente, donde se actualiza repetidamente cada parámetro como el valor 0 menos $\\alpha$, la tasa de aprendizaje, veces este término derivado. Echemos un vistazo a la derivada de $J$ con respecto a $w_j$. Este término en la parte superior aquí, donde como de costumbre, $j$ va de 1 a $n$, donde $n$ es el número de características. Si alguien aplicara las reglas del cálculo, puede mostrar que la derivada con respecto a $w_j$ de la función de coste $J$ es igual a esta expresión de aquí, es 1 sobre m veces la suma de 1 a m de este término de error. Esto es $f$ menos la etiqueta $y$ veces $x_j$. Aquí son sólo $x_{ij}$ es la característica $j$ del ejemplo de entrenamiento $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_28.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora veamos también la derivada de $J$ con respecto al parámetro $b$. Resulta ser esta expresión de aquí. Es bastante similar a la expresión anterior, excepto que no se multiplica por esta $x_{ij}$ al final. Sólo como un recordatorio, similar a lo que viste para la regresión lineal, la forma de llevar a cabo estas actualizaciones es utilizar actualizaciones simultáneas, lo que significa que primero se calcula el lado derecho para todas estas actualizaciones y luego simultáneamente sobrescribir todos los valores de la izquierda al mismo tiempo.  \n",
    "\n",
    "Permítanme tomar estas expresiones derivadas aquí y ponerlas en estos términos aquí. Esto nos da el descenso de gradiente para la regresión logística.  \n",
    "\n",
    "Ahora, una cosa curiosa que usted podría preguntarse es, que es raro. Estas dos ecuaciones se ven exactamente como el promedio que habíamos llegado anteriormente para la regresión lineal por lo que podría preguntarse, ¿es la regresión lineal en realidad secretamente lo mismo que la regresión logística? Bueno, aunque estas ecuaciones parezcan iguales, la razón por la que esto no es una regresión lineal es porque la definición de la función $f(x)$ ha cambiado. En la regresión lineal, $f(x)$ es, esto es $wx+b$. Pero en la regresión logística, $f(x)$ se define como la función sigmoidea aplicada a $wx+b$. Aunque el algoritmo escrito parecía el mismo para la regresión lineal y la regresión logística, en realidad son dos algoritmos muy diferentes porque la definición de $f(x)$ no es la misma. \n",
    "\n",
    "Cuando hablamos del descenso de gradiente para la regresión lineal anteriormente, viste cómo puedes controlar un descenso de gradiente para asegurarte de que converge. Puedes aplicar el mismo método para la regresión logística para asegurarte de que también converge. He escrito estas actualizaciones como si estuvieras actualizando los parámetros $w_j$ un parámetro a la vez. \n",
    "\n",
    "De manera similar a la discusión sobre las implementaciones vectorizadas de la regresión lineal, también puede utilizar la vectorización para hacer que el descenso de gradiente se ejecute más rápido para la regresión logística. No voy a entrar en los detalles de la implementación vectorizada en este vídeo. Pero también puedes aprender más sobre ella y ver el código en los laboratorios opcionales. Ahora ya sabes cómo implementar el descenso de gradiente para la regresión logística. \n",
    "\n",
    "Puede que también recuerdes el escalado de características cuando usábamos la regresión lineal. Allí vimos cómo el escalado de características, es decir, el escalado de todas las características para que tomen rangos de valores similares, por ejemplo entre 1 negativo y 1 positivo, puede ayudar al descenso por gradiente a converger más rápidamente. El escalado de características aplicado de la misma manera para escalar las diferentes características para que tomen rangos de valores similares también puede acelerar el descenso de gradiente para la regresión logística. \n",
    "\n",
    "En el próximo laboratorio opcional, también verás cómo se puede calcular el gradiente para la regresión logística en código. Esto será útil para ver porque también se implementa esto en el laboratorio de práctica al final de esta semana. Después de ejecutar el descenso de gradiente en este laboratorio, habrá un buen conjunto de gráficos animados que muestran el descenso de gradiente en acción. Verás la función sigmoidea, el gráfico de contorno del coste, el gráfico de la superficie 3D del coste y la curva de aprendizaje o la evolución a medida que se ejecuta el descenso por gradiente. Habrá otro laboratorio opcional después de eso, que es corto y dulce, pero también muy útil porque están mostrando cómo utilizar la popular biblioteca scikit-learn para entrenar el modelo de regresión logística para la clasificación. Muchos profesionales del aprendizaje automático en muchas empresas hoy en día utilizan scikit-learn regularmente como parte de su trabajo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero que también revises la función scikit-learn y eches un vistazo a cómo se utiliza. Eso es todo. Ahora deberías saber cómo implementar la regresión logística. Se trata de un algoritmo de aprendizaje muy potente y muy utilizado y ahora ya sabes cómo hacerlo funcionar por ti mismo. Enhorabuena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Gradient descent for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "¿Cuál de las dos siguientes afirmaciones es más exacta sobre el descenso de gradiente para la regresión logística?\n",
    "\n",
    "- Los pasos de actualización se parecen a los pasos de actualización para la regresión lineal, pero la definición de $f_{w,b}(x^{(i)})$ es diferente.\n",
    "- Los pasos de actualización son idénticos a los de la regresión lineal.\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Los pasos de actualización se parecen a los pasos de actualización para la regresión lineal, pero la definición de $f_{w,b}(x^{(i)})$ es diferente.\n",
    "    \n",
    "Para la regresión logística $x^{(i)}$ es la función sigmoidea en lugar de una línea recta.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE PROBLEM OF OVERFITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1XApzYKCMbqG-ZadKPtbcTiVxPBPTcql8/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora has visto un par de algoritmos de aprendizaje diferentes, la regresión lineal y la regresión logística. Funcionan bien para muchas tareas. Pero a veces, en una aplicación, el algoritmo puede encontrarse con un problema llamado **sobreajuste** (**overfitting**), que puede hacer que su rendimiento sea pobre. Lo que quiero hacer en este vídeo es mostrarte lo que es el sobreajuste, así como un problema casi opuesto, estrechamente relacionado, llamado **infraajuste** (**underfiting**). En los próximos vídeos después de éste, compartiré contigo algunas técnicas para la precisión del sobreajuste. En particular, hay un método llamado regularización. Es una técnica muy útil. La uso todo el tiempo. Entonces, la **regularización** te ayudará a minimizar este problema de sobreajuste y conseguir que tus algoritmos de aprendizaje funcionen mucho mejor. Veamos qué es el sobreajuste. \n",
    "Para ayudarnos a entender qué es el overfitting. Veamos algunos ejemplos. Volvamos a nuestro ejemplo original de predecir los precios de la vivienda con una regresión lineal. En el que se quiere predecir el precio en función del tamaño de la vivienda. Para ayudarnos a entender lo que es el sobreajuste, vamos a echar un vistazo a un ejemplo de regresión lineal. Voy a volver a nuestro ejemplo original de predicción de los precios de la vivienda con regresión lineal.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_30.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Supongamos que nuestro conjunto de datos se parece a esto, con la característica de entrada $x$ que es el tamaño de la casa, y el valor, y que está tratando de predecir el precio de la casa. Una cosa que puedes hacer es ajustar una función lineal a estos datos. Si haces eso, obtienes un ajuste de línea recta a los datos que tal vez se vea así. Pero este no es un modelo muy bueno. Mirando los datos, parece bastante claro que a medida que el tamaño de la casa aumenta, el proceso de vivienda se aplana. Este algoritmo no se ajusta muy bien a los datos de entrenamiento. El término técnico para esto es que el modelo no se ajusta a los datos de entrenamiento. Otro término es que el algoritmo tiene un **alto sesgo**. \n",
    "\n",
    "Es posible que hayas leído en las noticias sobre algunos algoritmos de aprendizaje que, por desgracia, muestran un sesgo contra ciertas etnias o ciertos géneros. En el aprendizaje automático, el término sesgo tiene múltiples significados. Comprobar si los algoritmos de aprendizaje tienen sesgos basados en características como el género o la etnia es absolutamente crítico. Pero el término compradores también tiene un segundo significado técnico, que es el que estoy utilizando aquí, que es si el algoritmo ha infraajustado los datos, lo que significa que ni siquiera es capaz de ajustarse al conjunto de entrenamiento tan bien. Hay un patrón claro en los datos de entrenamiento que el algoritmo es incapaz de capturar. Otra forma de pensar en esta forma de sesgo es como si el algoritmo de aprendizaje tuviera una preconcepción muy fuerte, o digamos un sesgo muy fuerte, de que los precios de la vivienda van a ser una función completamente lineal del tamaño a pesar de que los datos indiquen lo contrario. Esta preconcepción de que los datos son lineales hace que ajuste una línea recta que se ajusta mal a los datos, lo que le lleva a infraajustar los datos. \n",
    "\n",
    "Ahora, veamos una segunda variación de un modelo, que es si se inserta para una función cuadrática en los datos con dos características, $x$ y $x_2$, entonces cuando se ajustan los parámetros $w_1$ y $w_2$, se puede obtener una curva que se ajusta a los datos algo mejor. Tal vez se vea así. Además, si usted fuera a conseguir una nueva casa, que no está en este conjunto de cinco ejemplos de entrenamiento. Este modelo probablemente lo haría bastante bien en esa nueva casa. Si usted es un agente, la idea de que usted quiere que su algoritmo de aprendizaje para hacer bien, incluso en los ejemplos que no están en el conjunto de entrenamiento, que se llama la **generalización**. Técnicamente decimos que quieres que tu algoritmo de aprendizaje generalice bien, lo que significa hacer buenas predicciones incluso en ejemplos nuevos que nunca ha visto antes. Estos modelos cuadráticos parecen ajustarse al conjunto de entrenamiento, no perfectamente, pero sí bastante bien. Creo que se generalizaría bien a los nuevos ejemplos. \n",
    "\n",
    "Ahora veamos el otro extremo. ¿Qué pasa si se ajusta un polinomio de cuarto orden a los datos? Usted tiene $x$, $x_2$, $x_3$, y $x_4$ todos como características. Con este cuarto orden para el polinomio, se puede ajustar la curva que pasa a través de los cinco ejemplos de entrenamiento exactamente. Usted puede obtener una curva que se parece a esto. Esto, por un lado, parece hacer un trabajo extremadamente bueno ajustando los datos de entrenamiento porque pasa a través de todos los datos de entrenamiento perfectamente. De hecho, usted sería capaz de elegir los parámetros que se traducirá en la función de coste es exactamente igual a cero porque los errores son cero en los cinco ejemplos de entrenamiento. Pero esta es una curva muy ondulada, va hacia arriba y hacia abajo por todo el lugar. Si tienes todo este tamaño aquí, el modelo predeciría que esta casa es más barata que las casas que son más pequeñas que ella. No creemos que este sea un modelo particularmente bueno para predecir los precios de la vivienda. El término técnico es que diremos que este modelo ha sobreajustado los datos, o este modelo tiene un problema de sobreajuste. Porque aunque se ajusta muy bien al conjunto de entrenamiento, se ha ajustado a los datos casi demasiado bien, por lo que está sobreajustado. No parece que este modelo vaya a generalizar a nuevos ejemplos nunca vistos. Otro término para esto es que el algoritmo tiene una **alta varianza**. \n",
    "\n",
    "En el aprendizaje automático, mucha gente utilizará los términos sobreajuste y alta varianza casi indistintamente. Nosotros utilizaremos los términos sobreajuste y alta bias casi indistintamente. La intuición detrás de la sobreadaptación o la alta varianza es que el algoritmo se esfuerza por ajustarse a cada uno de los ejemplos de entrenamiento. Resulta que si tu conjunto de entrenamiento fuera incluso un poco diferente, digamos que uno de los agujeros tuviera un precio un poco más un poco menos, entonces la función que el algoritmo ajusta podría terminar siendo totalmente diferente. Si dos ingenieros de aprendizaje de máquinas diferentes fueran a ajustar este modelo polinómico de cuarto orden, a conjuntos de datos ligeramente diferentes, no podrían terminar con predicciones totalmente diferentes o predicciones muy variables. Por eso decimos que el algoritmo tiene una alta varianza. \n",
    "\n",
    "Contrastando este modelo de la derecha con el del medio para la misma casa, parece que el modelo del medio les da una predicción mucho más razonable para el precio. No hay realmente un nombre para este caso en el medio, pero voy a llamar a esto justo, porque no es ni underfit ni overfit. Se puede decir que el objetivo del aprendizaje automático es encontrar un modelo que, con suerte, no se ajuste por debajo ni por encima. En otras palabras, un modelo que no tenga ni un alto sesgo ni una alta varianza. Cuando pienso en el infraajuste y el sobreajuste, en el alto sesgo y la alta varianza. A veces me acuerdo del cuento infantil de Ricitos de Oro y los tres osos en esta cola de Troya, una niña llamada Ricitos de Oro visita la casa de una familia de osos. Hay un tazón de gachas de avena que está demasiado frío para probarlo y por eso no es bueno. También hay un bol de gachas que está demasiado caliente para comerlo. Eso tampoco es bueno. Pero hay un bol de gachas que no está ni demasiado frío ni demasiado caliente. La temperatura está en el medio, lo que es justo para comer. Recapitulando, si tienes demasiadas características, como el polinomio de cuarto orden de la derecha, entonces el modelo puede ajustarse bien al conjunto de entrenamiento, pero casi demasiado bien o sobreajustarse y tener una alta varianza. Por el contrario, si tiene muy pocas características, en este ejemplo, como el de la izquierda, se ajusta mal y tiene un sesgo alto. En este ejemplo, utilizando las características cuadráticas $x$ y $x^{2}$, parece estar bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_31.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Hasta ahora hemos visto el infraajuste y el sobreajuste del modelo de regresión lineal. Del mismo modo, el sobreajuste también se aplica a la clasificación. Aquí tenemos un ejemplo de clasificación con dos características, $x_1$ y $x_2$, donde $x_1$ es quizás el tamaño del tumor y $x_2$ es la edad del paciente. Estamos tratando de clasificar si un tumor es maligno o benigno, como se denota por estas cruces y círculos, una cosa que podría hacer es ajustar un modelo de regresión logística. Sólo un modelo simple como este, donde como siempre, $g$ es la función sigmoidea y este término aquí dentro es $z$. Si haces eso, terminas con una línea recta como límite de decisión. Esta es la línea donde $z$ es igual a cero que separa los ejemplos positivos y negativos. Esta línea recta no se ve terrible. Se ve bien, pero tampoco parece que se ajuste muy bien a los datos. Este es un ejemplo de infraajuste o de alto sesgo. \n",
    "\n",
    "Veamos otro ejemplo. Si usted agrega a sus características estos términos cuadráticos, entonces z se convierte en este nuevo término en el medio y el límite de la decisión, es decir, donde $z$ es igual a cero puede verse más como esto, más como una elipse o parte de una elipse. Esto se ajusta bastante bien a los datos, aunque no clasifica perfectamente todos los ejemplos del conjunto de entrenamiento. Obsérvese cómo algunas de estas cruces se clasifican entre los círculos. Pero este modelo parece bastante bueno. Voy a decir que es correcto. Parece que esto generalizó bastante bien a los nuevos pacientes. \n",
    "\n",
    "Por último, en el otro extremo, si usted fuera a ajustar un polinomio de orden muy alto con muchas características como estas, entonces el modelo puede tratar muy duro y contorneado o torcido a sí mismo para encontrar un límite de decisión que se ajusta a sus datos de entrenamiento perfectamente. Tener todas estas características polinómicas de orden superior permite al algoritmo elegir esto realmente sobre el límite de decisión complejo. Si las características son el tamaño del tumor en la edad, y usted está tratando de clasificar los tumores como malignos o benignos, entonces esto no parece realmente un modelo muy bueno para hacer predicciones. Una vez más, este es un caso de sobreajuste y alta varianza porque su modelo, a pesar de hacerlo muy bien en el conjunto de entrenamiento, no parece que vaya a generalizar bien a nuevos ejemplos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Nuestro objetivo al crear un modelo es poder utilizarlo para predecir correctamente los resultados de nuevos ejemplos. Un modelo que hace esto se dice que generaliza bien. \n",
    "\n",
    "Cuando un modelo se ajusta bien a los datos de entrenamiento pero no funciona bien con nuevos ejemplos que no están en el conjunto de entrenamiento, es un ejemplo de:\n",
    "\n",
    "- Un modelo que generaliza bien (ni alta varianza ni alto sesgo) \n",
    "- Ninguna de las anteriores\n",
    "- Sobreajuste (alta varianza)\n",
    "- Ajuste insuficiente (sesgo alto)\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Sobreajuste (alta varianza).\n",
    "    \n",
    "Esto ocurre cuando el modelo no se generaliza bien a nuevos ejemplos.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya has visto cómo un algoritmo puede no ajustarse o tener un sesgo alto o ajustarse en exceso y tener una varianza alta. Quizá quieras saber cómo puedes dar con un modelo que sea justo el adecuado. En el siguiente vídeo, veremos algunas formas de abordar el problema del sobreajuste. También abordaremos algunas ideas pertinentes para utilizar el infraajuste. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1Jf9o3HOQ4uwzXH3xl6Wi4YAJSESLt1st/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más adelante en esta especialización, hablaremos sobre la depuración y el diagnóstico de las cosas que pueden ir mal con los algoritmos de aprendizaje. También aprenderás sobre herramientas específicas para reconocer cuándo se está produciendo un sobreajuste o un infraajuste. Pero por ahora, cuando pienses que se ha producido un sobreajuste, vamos a hablar de lo que puedes hacer para solucionarlo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_33.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Digamos que ajustas un modelo y tiene una alta varianza, está sobreajustado. Este es nuestro modelo de predicción del precio de la vivienda sobreajustado. Una forma de abordar este problema es recoger **más datos** de entrenamiento, esa es una opción. Si eres capaz de obtener más datos, es decir, más ejemplos de entrenamiento sobre tamaños y precios de casas, entonces con el conjunto de entrenamiento más grande, el algoritmo de aprendizaje aprenderá a ajustar una función que es menos ondulada. Puedes seguir ajustando un polinomio de alto orden o alguna función con muchas características, y si tienes suficientes ejemplos de entrenamiento, lo seguirá haciendo bien. Para resumir, la herramienta número uno que puede utilizar contra el sobreajuste es obtener más datos de entrenamiento. Ahora bien, conseguir más datos no siempre es una opción. Tal vez sólo se hayan vendido tantas casas en esta ubicación, así que tal vez no haya más datos que añadir. Pero cuando los datos están disponibles, esto puede funcionar muy bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_34.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Una segunda opción para abordar el sobreajuste es ver si se pueden **utilizar menos características**. En el vídeo anterior, las características de nuestros modelos incluían el tamaño x, así como el tamaño al cuadrado, y este x2, y x3 y x4 y así sucesivamente. Eran muchas características polinómicas. En ese caso, una forma de reducir el sobreajuste es simplemente no utilizar tantas de estas características polinómicas. Pero ahora veamos un ejemplo diferente. Tal vez tengas un montón de características diferentes de una casa de la que tratar de predecir su precio, que van desde el tamaño, el número de dormitorios, el número de plantas, la edad, los ingresos medios del barrio, y así sucesivamente, la distancia total a la cafetería más cercana. Resulta que si tienes muchas características como éstas pero no tienes suficientes datos de entrenamiento, entonces tu algoritmo de aprendizaje también puede ajustarse en exceso a tu conjunto de entrenamiento. Ahora, en lugar de utilizar las 100 características, podríamos elegir sólo un subconjunto de las más útiles, como el tamaño, las habitaciones y la edad de la casa. Si cree que esas son las características más relevantes, al utilizar sólo ese subconjunto mínimo de características, es posible que su modelo ya no se ajuste tanto. La elección del conjunto de características más adecuado se denomina a veces selección de características. Una forma de hacerlo es utilizar su intuición para elegir lo que cree que es el mejor conjunto de características, lo que es más relevante para predecir el precio. Ahora bien, una de las desventajas de la selección de características es que, al utilizar sólo un subconjunto de ellas, el algoritmo está desechando parte de la información que tiene sobre las casas. Por ejemplo, tal vez todas estas características, todas las 100 de ellas son realmente útiles para predecir el precio de una casa. Tal vez usted no quiere tirar parte de la información mediante la eliminación de algunas de las características. \n",
    "Más adelante, en el curso 2, también veremos algunos algoritmos para elegir automáticamente el conjunto de características más apropiado para nuestra tarea de predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_35.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Esto nos lleva a la tercera opción para reducir el sobreajuste. Esta técnica, que veremos en mayor profundidad en el siguiente vídeo, se llama **regularización**. Si observamos un modelo sobreajustado, aquí tenemos un modelo que utiliza características polinómicas: $x$, $x_2$, $x_3$, etc. Usted encuentra que los parámetros son a menudo relativamente grande. Ahora bien, si usted fuera a eliminar algunas de estas características, por ejemplo, si usted fuera a eliminar la característica $x_4$, que corresponde a establecer este parámetro a 0. Así que el establecimiento de un parámetro a 0 es equivalente a la eliminación de una característica, que es lo que vimos en la diapositiva anterior. Resulta que la regularización es una manera de reducir más suavemente los impactos de algunas de las características sin hacer algo tan duro como eliminarlas directamente. Lo que hace la regularización es animar al algoritmo de aprendizaje a reducir los valores de los parámetros sin exigir necesariamente que el parámetro se establezca exactamente en 0. Resulta que incluso si se ajusta un polinomio de orden superior como este, siempre y cuando se pueda conseguir que el algoritmo utilice valores de parámetros más pequeños: $w_1$, $w_2$, $w_3$, $w_4$. Terminas con una curva que acaba ajustándose a los datos de entrenamiento mucho mejor. Así que lo que hace la regularización, es que le permite mantener todas sus características, pero sólo evita que las características tengan un efecto demasiado grande, que es lo que a veces puede causar el sobreajuste. \n",
    "\n",
    "Por cierto, por convención, normalmente sólo reducimos el tamaño de los parámetros $w_j$, es decir $w_1$ a $w_n$. No hay gran diferencia en regularizar también el parámetro b, puedes hacerlo si quieres o no. Yo normalmente no lo hago y está bien regularizar $w_1$, $w_2$, todo el camino hasta $w_n$, pero no animar realmente a que $b$ se haga más pequeño. En la práctica, debería haber muy poca diferencia entre regularizar $b$ o no. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_36.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Para recapitular, estas son las tres formas que has visto en este vídeo para abordar el sobreajuste. \n",
    "\n",
    "- Uno, recoger más datos. Si puede obtener más datos, esto puede ayudar a reducir el sobreajuste. A veces eso no es posible. En ese caso, algunas de las opciones son, \n",
    "- dos, tratar de seleccionar y utilizar sólo un subconjunto de las características. Aprenderá más sobre la selección de características en el Curso 2. \n",
    "- La tercera sería reducir el tamaño de los parámetros utilizando la regularización. Este será el tema del próximo vídeo también. Sólo para mí, yo uso la regularización todo el tiempo. Así que esta es una técnica muy útil para el entrenamiento de algoritmos de aprendizaje, incluyendo las redes neuronales específicamente, que verás más adelante en esta especialización también. \n",
    "\n",
    "Espero que también veas el laboratorio opcional sobre sobreajuste. En el laboratorio, podrás ver diferentes ejemplos de sobreajuste y ajustar esos ejemplos haciendo clic en las opciones de los gráficos. También podrás añadir tus propios puntos de datos haciendo clic en el gráfico y ver cómo cambia la curva que se ajusta. También puedes probar ejemplos tanto de regresión como de clasificación y cambiarás el grado del polinomio para que sea $x$, $x_2$, $x_3$, etc. El laboratorio también le permite jugar con dos opciones diferentes para abordar el sobreajuste. Puede añadir datos de entrenamiento adicionales para reducir el sobreajuste y también puede seleccionar qué características incluir o excluir como otra forma de intentar reducir el sobreajuste. Por favor, echa un vistazo a un laboratorio, que espero que te ayude a construir tu intuición sobre el sobreajuste, así como algunos métodos para abordarlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Aplicar la regularización, aumentar el número de ejemplos de entrenamiento o seleccionar un subconjunto de las características más relevantes son métodos para...\n",
    "\n",
    "- Tratar el infraajuste (alto sesgo)\n",
    "- Tratar el exceso de ajuste (alta varianza)\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Tratar el exceso de ajuste (alta varianza).\n",
    "    \n",
    "Estos métodos pueden ayudar al modelo a generalizar mejor a nuevos ejemplos que no están en el conjunto de entrenamiento.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este vídeo, también has visto la idea de la regularización a un nivel relativamente alto. Me doy cuenta de que todos estos detalles sobre la regularización pueden no tener todavía mucho sentido para ti. Pero en el próximo vídeo, empezaremos a formular exactamente cómo aplicar la regularización y qué significa exactamente la regularización. Entonces empezaremos a averiguar cómo hacer que esto funcione con nuestros algoritmos de aprendizaje para hacer que la regresión lineal y la regresión logística, y en el futuro, otros algoritmos también eviten el sobreajuste. Vamos a echar un vistazo a eso en el siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function with regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1DyxcQOyLMcKNuNL_4JLoFyt933lD5usR/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo vimos que la regularización intenta que los valores parentales $w_1$ a wn sean pequeños para reducir el sobreajuste. En este vídeo, nos basaremos en esa intuición y desarrollaremos una función de coste modificada para su algoritmo de aprendizaje que puede utilizar para aplicar realmente la regularización. Vamos a saltar. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_38.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Recordar este ejemplo del vídeo anterior en el que vimos que si se ajusta una función cuadrática a estos datos, da un ajuste bastante bueno. Pero si ajustas un polinomio de orden muy alto, terminas con una curva que se ajusta demasiado a los datos. \n",
    "\n",
    "Pero ahora considere lo siguiente, suponga que tiene una manera de hacer los parámetros $w_3$ y $w_4$ muy, muy pequeños. Digamos cerca de 0. Esto es lo que quiero decir. Digamos que en lugar de minimizar esta función objetivo, esta es una función de costo para la regresión lineal. Digamos que usted fuera a modificar la función de costo y añadir a ella 1000 veces $w_{32}$ más 1000 veces $w_{42}$. Y aquí estoy eligiendo 1000 porque es un número grande, pero cualquier otro número realmente grande estaría bien. Así que con esta función de costo modificada, de hecho, podría estar penalizando el modelo si $w_3$ y $w_4$ son grandes. Porque si quieres minimizar esta función, la única manera de hacer esta nueva función de costo pequeña es si $w_3$ y $w_4$ son ambos pequeños, ¿verdad? Porque de lo contrario este 1000 veces $w_{32}$ y 1000 veces $w_{42}$ van a ser muy, muy grande. Así que cuando usted minimiza esta función, usted va a terminar con $w_3$ cerca de 0 y $w_4$ cerca de 0. Así que estamos efectivamente casi cancelando los efectos de las características ejecutar y potencia extra de 4 y deshacerse de estos dos términos aquí. Y si hacemos eso, entonces terminamos con un ajuste de los datos que está mucho más cerca de la función cuadrática, incluyendo tal vez sólo pequeñas contribuciones de las características $x^{3}$ y extra 4. Y esto es bueno porque es un ajuste mucho mejor a los datos en comparación con si todos los parámetros podrían ser grandes y terminas con esta función cuadrática. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_39.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Más generalmente, aquí está la idea detrás de la regularización. La idea es que si hay valores más pequeños para los parámetros, entonces eso es un poco como tener un modelo más simple. Tal vez uno con menos características, que por lo tanto es menos propenso a sobreajustar. En la última diapositiva penalizamos o decimos que regularizamos sólo $w_3$ y $w_4$. Pero en general, la forma en que la regularización tiende a ser implementada es que si usted tiene un montón de características, digamos 100 características, usted no puede saber cuáles son las características más importantes y cuáles deben ser penalizadas. Así que la forma en que se implementa la regularización es penalizar todas las características o, más precisamente, penalizar todos los parámetros de $w_j$ y es posible demostrar que esto generalmente resultará en el ajuste de una función más suave y menos debil que es menos propensa al sobreajuste. Así que para este ejemplo, si se tienen datos con 100 características para cada casa, puede ser difícil elegir de antemano qué características incluir y cuáles excluir. Así que vamos a construir un modelo que utiliza todas las 100 características. Así que tienes estos 100 parámetros $w_1$ a $w_{100}$, así como 100 y el primer parámetro $b$. Porque no sabemos cuáles de estos parámetros van a ser los importantes. Vamos a penalizar todos ellos un poco y reducir todos ellos mediante la adición de este nuevo término $\\lambda$ veces la suma de $j$ es igual a 1 a través de $n$ donde $n$ es 100. El número de características de $w_j^2$. Este valor lambda aquí es el alfabeto griego $\\lambda$ y también se llama un **parámetro de regularización**. Así que similar a la elección de una tasa de aprendizaje alfa, ahora también tiene que elegir un número para $\\lambda$. \n",
    "\n",
    "Un par de cosas que me gustaría señalar por convención, en lugar de utilizar lambda veces la suma de $w_j^2$. También dividimos $\\lambda$ por $2m$ para que tanto el primer como el segundo término se escalen por 1 sobre $2m$. Resulta que al escalar ambos términos de la misma manera se hace un poco más fácil elegir un buen valor para $\\lambda$. Y en particular se encuentra que incluso si el tamaño de su conjunto de entrenamiento crece, digamos que usted encuentra más ejemplos de entrenamiento. Así que $m$ el tamaño del conjunto de entrenamiento es ahora más grande. El mismo valor de lambda que has elegido anteriormente es ahora también más probable que siga funcionando si tienes esta escala adicional de $2m$. \n",
    "\n",
    "También por cierto, por convención no vamos a penalizar el parámetro $b$ por ser grande. En la práctica, hace muy poca diferencia si lo haces o no. Y algunos ingenieros de aprendizaje de máquinas y en realidad algunas implementaciones de algoritmos de aprendizaje también incluirán lambda sobre $2m$ veces el término $b$ al cuadrado. Pero esto hace muy poca diferencia en la práctica y la convención más común que se utilizó en este curso es regularizar sólo los parámetros $w$ en lugar del parámetro $b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_40.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que para resumir en esta función de costo modificada, queremos minimizar el costo original, que es el costo del error cuadrado medio más, además, el segundo término que se llama el término de regularización. Y así, esta nueva función de coste negocia dos objetivos que podría tener. Intentar minimizar este primer término anima al algoritmo a ajustarse bien a los datos de entrenamiento minimizando las diferencias al cuadrado de las predicciones y los valores reales, y trata de minimizar el segundo término. El algoritmo también intenta mantener los parámetros $w_j$ pequeños, lo que tenderá a reducir el sobreajuste. El valor de lambda que elija, especifica la importancia relativa o la compensación relativa o cómo se equilibra entre estos dos objetivos. \n",
    "\n",
    "Echemos un vistazo a lo que los diferentes valores de lambda harán que su algoritmo de aprendizaje haga. Usemos el ejemplo de la predicción del precio de la vivienda usando la regresión lineal. Así que $f(x)$ es el modelo de regresión lineal. Si $\\lambda$ se fijó en 0, entonces usted no está utilizando el término de regularización en absoluto, porque el término de regularización se multiplica por 0. Y así, si $\\lambda$ era 0, usted termina ajustando esta curva demasiado ondulada, demasiado compleja y se ajusta demasiado. Así que eso fue un extremo de si $\\lambda$ era 0. Ahora vamos a ver el otro extremo. Si usted dijo que $\\lambda$ es un número muy, muy, muy grande, digamos que $\\lambda$ es igual a 10 a la potencia de 10, entonces usted está poniendo un peso muy pesado en este término de regularización a la derecha. Y la única manera de minimizar esto es estar seguro de que todos los valores de $w$ están muy cerca de 0. Así que si $\\lambda$ es muy, muy grande, el algoritmo de aprendizaje elegirá $w_1$, $w_2$, $w_3$ y $w_4$ para estar extremadamente cerca de 0 y por lo tanto $f(x)$ es básicamente igual a $b$ y por lo que el algoritmo de aprendizaje se ajusta a una línea recta horizontal y se ajusta por debajo. \n",
    "\n",
    "Para recapitular, si $\\lambda$ es 0, este modelo se ajustará en exceso. Si $\\lambda$ es enorme, como 10 a la potencia de 10. Este modelo se ajustará por debajo (underfit). Así que lo que se quiere es un valor de $\\lambda$ que esté en el medio que equilibre más apropiadamente estos primeros y segundos términos de negociación, minimizando el error cuadrático medio y manteniendo los parámetros pequeños. Y cuando el valor de lambda no es demasiado pequeño y no demasiado grande, pero justo, entonces es de esperar que termine capaz de ajustar un polinomio de cuarto orden, manteniendo todas estas características, pero con una función que se parece a esto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Para un modelo que incluye el parámetro de regularización λ (lambda), aumentar λ tenderá a...\n",
    "- Disminuir el tamaño del parámetro $b$.\n",
    "- Aumentar el tamaño del parámetro $b$.\n",
    "- Disminuir el tamaño de los parámetros $w_1$, $w_2$,...,$w_n$\n",
    "- Aumenta el tamaño de los parámetros $w_1$, $w_2$,...,$w_n$\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Disminuir el tamaño de los parámetros $w_1$, $w_2$,...,$w_n$.\n",
    "    \n",
    "El aumento del parámetro de regularización lambda reduce el sobreajuste al reducir el tamaño de los parámetros.  Para algunos parámetros que están cerca de cero, esto reduce el efecto de las características asociadas.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así es como funciona la regularización. Cuando hablamos de la selección del modelo, más adelante en la especialización también veremos una variedad de formas de elegir buenos valores para lambda. En los próximos dos videos se desarrollará la forma de aplicar la regularización a la regresión lineal y la regresión logística, y cómo entrenar estos modelos con descenso del gradiente, usted será capaz de evitar el exceso de ajuste con estos dos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1ac9qekLKOuh3hKfJQzZZqMnWB-RoyFK6/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este vídeo, vamos a averiguar cómo conseguir que el descenso de gradiente funcione con la regresión lineal regularizada. Vamos a empezar. Aquí hay una función de coste que hemos creado en el último vídeo para la regresión lineal regularizada. La primera parte es la función de coste de error cuadrado habitual, y ahora tienes este término de regularización adicional, donde Lambda es el parámetro de regularización, y te gustaría encontrar los parámetros $w$ y $b$ que minimizan la función de coste regularizado. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_42.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Anteriormente estábamos usando el descenso de gradiente para la función de costo original, sólo el primer término antes de añadir que el segundo término de regularización, y anteriormente, tuvimos el siguiente algoritmo de descenso de gradiente, que es que repetidamente actualizar los parámetros $w_j$ y $b$ para $j$ es igual a 1 a través de $n$ de acuerdo con esta fórmula y $b$ también se actualiza de manera similar. De nuevo, $\\alpha$ es un número positivo muy pequeño llamado **tasa de aprendizaje**. De hecho, las actualizaciones para una regresión lineal regularizada son exactamente iguales, excepto que ahora el coste, $J$, se define de forma un poco diferente. \n",
    "\n",
    "Anteriormente la derivada de $J$ con respecto a $w_j$ estaba dada por esta expresión de aquí, y la derivada con respecto a $b$ estaba dada por esta expresión de aquí. Ahora que hemos añadido este término de regularización adicional, lo único que cambia es que la expresión para la derivada con respecto a $w_j$ termina con un término adicional, esto más $\\lamda$ sobre $m$ veces $w_j$. Y en particular para la nueva definición de la función de coste $J$, estas dos expresiones de aquí, son las nuevas derivadas de $J$ con respecto a $w_j$ y la derivada de $J$ con respecto a $b$. Recordemos que no regularizamos $b$, por lo que no estamos tratando de reducir $b$. Es por eso que la $b$ actualizada sigue siendo la misma que antes, mientras que la $w$ actualizada cambia porque el término de regularización nos hace tratar de reducir $w_j$. Tomemos estas definiciones para las derivadas y pongámoslas de nuevo en la expresión de la izquierda para escribir el algoritmo de descenso de gradiente para la regresión lineal regularizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_43.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Para implementar el descenso de gradiente para la regresión lineal regularizada, esto es lo que tendría que hacer su código. Aquí está la actualización para $w_j$, para $j$ es igual a 1 a través de $n$, y aquí está la actualización para $b$. Como de costumbre, por favor, recuerde llevar a cabo actualizaciones simultáneas para todos estos parámetros. \n",
    "\n",
    "Ahora, para que usted pueda obtener este algoritmo para trabajar, esto es todo lo que necesita saber. Pero lo que me gusta hacer en el resto de este vídeo es repasar algún material opcional para transmitir una intuición un poco más profunda sobre lo que realmente hace esta fórmula, así como charlar brevemente sobre cómo se derivan estas derivadas. El resto de este vídeo es completamente opcional. No pasa nada si te saltas el resto de este vídeo, pero si te interesan mucho las matemáticas, quédate conmigo. Siempre es agradable pasar el rato con usted aquí, y a través de estas ecuaciones, tal vez usted puede construir una intuición más profunda acerca de lo que las matemáticas y lo que las derivadas están haciendo también. Echemos un vistazo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_44.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a ver la regla de actualización para wj y reescribirlo de otra manera. Estamos actualizando $w_j$ como 1 veces $w_j$ menos $\\alpha$ veces $\\alpha$ sobre $m$ veces $w_j$. He movido el término del final al frente aquí. Luego menos $\\alpha$ por 1 sobre $m$, y luego el resto de ese término por allí. Acabamos de reorganizar los términos un poco. Si simplificamos, entonces estamos diciendo que $w_j$ se actualiza como $w_j$ por 1 menos $\\alpha$ por $\\lambda$ sobre $m$, menos $\\alpha$ por este otro término de aquí. Usted puede reconocer el segundo término como la actualización habitual de descenso de gradiente para la regresión lineal no regularizada. Esta es la actualización para la regresión lineal antes de que tuviéramos la regularización, y este es el término que vimos en la semana 2 de este curso. El único cambio que añadimos a la regularización es que en lugar de que $w_j$ sea igual a $w_j$ menos $\\alpha$ veces este término es ahora w veces este número menos la actualización habitual. \n",
    "\n",
    "Esto es lo que teníamos en la semana 1 de este curso. ¿Qué es este primer término de aquí? Bueno, $\\alpha$ es un número positivo muy pequeño, digamos 0.01. $\\lambda$ es usualmente un número pequeño, digamos 1 o tal vez 10. Digamos que $\\lambda$ es 1 para este ejemplo y m es el tamaño del conjunto de entrenamiento, digamos 50. Cuando se multiplica $\\frac{\\alpha\\lambda}{m}$, digamos 0,01 por 1 dividido por 50, este término acaba siendo un pequeño número positivo, digamos 0,0002, y por tanto, 1 menos $\\frac{\\alpha\\lambda}{m}$ va a ser un número ligeramente inferior a 1, en este caso, 0,9998. El efecto de este término es que en cada iteración del descenso de gradiente, estás tomando $w_j$ y multiplicándolo por 0,9998, es decir, por algunos números ligeramente inferiores a uno y para llevar a cabo la actualización habitual. Lo que la regularización está haciendo en cada iteración es que estás multiplicando $w$ por un número ligeramente inferior a 1, y eso tiene el efecto de reducir el valor de $w_j$ sólo un poco. Esto nos da otra visión de por qué la regularización tiene el efecto de reducir los parámetros $w_j$ un poco en cada iteración, y así es como funciona la regularización. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_45.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Si tienes curiosidad por saber cómo se calculan estos términos derivados, tengo una última diapositiva opcional que repasa un poco el cálculo del término derivado. De nuevo, esta diapositiva y el resto de este video son completamente opcionales, lo que significa que no necesitarás nada de esto para hacer los laboratorios de práctica y los exámenes. \n",
    "\n",
    "Pasemos rápidamente al cálculo de la derivada. La derivada de $J$ con respecto a $w_j$ tiene este aspecto. Recordemos que $f(x)$ para la regresión lineal se define como $w·x+b$ o $w·x+b$. \n",
    "\n",
    "Resulta que por las reglas del cálculo, las derivadas se ven así, es $\\frac{1}{2m}$ veces la suma $i$ es igual a 1 a través de $m$ de $((w·x+b)-y)2x_j$ más la derivada del término de regularización, que es $\\frac{\\lambda}{2m}$ veces $2w_j$. Observa que el segundo término ya no tiene el término de suma de $j$ igual a 1 hasta $n$. Los 2 se cancelan aquí y aquí, y también aquí y aquí. Se simplifica a esta expresión de aquí.\n",
    "\n",
    "Por último, recuerda que $w·x+b$ es $f(x)$, por lo que puedes reescribirla como esta expresión de aquí abajo. Por eso esta expresión se utiliza para calcular el gradiente en la regresión lineal regularizada. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Recordemos que el algoritmo de descenso de gradiente utiliza el cálculo del gradiente:\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/practica1.png\"   style=\"width:603px;height:167px;\" >\n",
    "</figure>\n",
    " \n",
    "Donde cada iteración realiza actualizaciones simultáneas en jw para todos los j.\n",
    "En la conferencia, esto fue reordenado para enfatizar el impacto de la regularización:\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/practica2.png\"   style=\"width:531px;height:85px;\" >\n",
    "</figure>\n",
    "\n",
    "Se reordena para que sea:\n",
    " \n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/practica3.png\"   style=\"width:525px;height:93px;\" >\n",
    "</figure>\n",
    "\n",
    "Suponiendo que $\\alpha$, la tasa de aprendizaje, es un número pequeño como 0,001, $\\lambda$ es 1, y $m$=50, ¿cuál es el efecto de la \"parte nueva\" en la actualización de $w_j$? \n",
    "\n",
    "- La parte nueva disminuye el valor de $w_j$ en cada iteración.\n",
    "- La parte nueva aumenta el valor de $w_j$ en cada iteración un poco.\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "La parte nueva disminuye el valor de $w_j$ en cada iteración.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabes cómo implementar la regresión lineal regularizada. Usando esto, realmente se reduce el sobreajuste cuando se tiene una gran cantidad de características y un conjunto de entrenamiento relativamente pequeño. Esto debería permitirte conseguir que la regresión lineal funcione mucho mejor en muchos problemas. En el siguiente vídeo, tomaremos esta idea de regularización y la aplicaremos a la regresión logística para evitar el sobreajuste de la regresión logística también. Vamos a echar un vistazo a eso en el siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/10vQa194zAmzvwcnA9ldPLkJ3TVpqR7b3/view?usp=sharing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este vídeo, verá cómo implementar la regresión logística regularizada. Al igual que la actualización del gradiente para la regresión logística ha parecido sorprendentemente similar a la actualización del gradiente para la regresión lineal, encontrará que la actualización del descenso del gradiente para la regresión logística regularizada también se parecerá a la actualización para la regresión lineal regularizada. Echemos un vistazo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_47.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "La idea es la siguiente. Hemos visto antes que la regresión logística puede ser propensa a un sobreajuste si se ajusta con características polinómicas de orden muy alto como esta. Aquí, $z$ es un polinomio de alto orden que se pasa a la función sigmoidea así para calcular $f$. En particular, puede terminar con un límite de decisión que es demasiado complejo y sobreajusta como conjunto de entrenamiento. En general, cuando se entrena la regresión logística con muchas características, ya sean polinómicas o de otro tipo, puede haber un mayor riesgo de sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W3_Página_48.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Esta es la función de coste de la regresión logística. Si quieres modificarla para utilizar la regularización, todo lo que tienes que hacer es añadirle el siguiente término. Añadamos $\\lambda$ al parámetro de regularización sobre $2m$ veces la suma de $j$ igual a 1 a través de $n$, donde $n$ es el número de características como es habitual de $w_j^{2}$. Cuando se minimiza esta función de coste en función de $w$ y $b$, tiene el efecto de penalizar los parámetros $w_1$, $w_2$ hasta $w_n$, y evitar que sean demasiado grandes. Si usted hace esto, entonces a pesar de que usted está ajustando un polinomio de alto orden con un montón de parámetros, usted todavía consigue un límite de decisión que se parece a esto. Algo que parece más razonable para separar los ejemplos positivos y negativos, mientras que también generaliza con suerte a los nuevos ejemplos que no están en el conjunto de entrenamiento. \n",
    "\n",
    "Cuando se utiliza la regularización, incluso cuando se tiene una gran cantidad de características. ¿Cómo se puede implementar esto? ¿Cómo se puede minimizar esta función de coste $J(w,b)$ que incluye el término de regularización? Bueno, vamos a utilizar el descenso de gradiente como antes. Aquí tenemos una función de coste que queremos minimizar. Para implementar el descenso de gradiente, como antes, llevaremos a cabo las siguientes actualizaciones simultáneas sobre $w_j$ y $b$. Estas son las reglas de actualización habituales para el descenso de gradiente. Al igual que la regresión lineal regularizada, cuando se calcula donde hay estos términos derivados, lo único que cambia ahora es que la derivada respecto a $w_j$ obtiene este término adicional, lambda sobre $m$ veces $w_j$ añadido aquí al final. De nuevo, se parece mucho a la actualización de la regresión lineal regularizada. De hecho, es exactamente la misma ecuación, excepto por el hecho de que la definición de $f$ ya no es la función lineal, es la función logística aplicada a $z$. Al igual que la regresión lineal, vamos a regularizar sólo los parámetros $w_j$, pero no el parámetro $b$, que es la razón por la que no hay ningún cambio en la actualización que hará para $b$. \n",
    "\n",
    "En el laboratorio opcional final de esta semana, se revisa el sobreajuste. En el gráfico interactivo del laboratorio opcional, ahora puedes elegir regularizar tus modelos, tanto de regresión como de clasificación, activando la regularización durante el descenso de gradiente seleccionando un valor para lambda. Por favor, eche un vistazo al código para implementar la regresión logística regularizada en particular, porque usted mismo implementará esto en el laboratorio de práctica al final de esta semana. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Para la regresión **logística** regularizada, ¿cómo se comparan los pasos de actualización del descenso de gradiente con los pasos de la regresión lineal?\n",
    "\n",
    "- Se parecen mucho, pero la $f(x)$ no es la misma.\n",
    "- Son idénticos\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "    \n",
    "Se parecen mucho, pero la $f(x)$ no es la misma.\n",
    "    \n",
    "Para la regresión logística, $f(x)$ es la función sigmoidea (logística), mientras que para la regresión lineal, $f(x)$ es una función lineal.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya sabes cómo implementar la regresión logística regularizada. Cuando paseo por Silicon Valley, hay muchos ingenieros que utilizan el aprendizaje automático para crear un montón de valor, a veces haciendo mucho dinero para las empresas. Sé que sólo has estado estudiando estas cosas durante unas semanas, pero si entiendes y puedes aplicar la regresión lineal y la regresión logística, eso es en realidad todo lo que necesitas para crear algunas aplicaciones muy valiosas. Aunque los resultados específicos del aprendizaje que utilizas son importantes, saber cosas como cuándo y cómo reducir el sobreajuste resulta ser una de las habilidades muy valiosas en el mundo real también. \n",
    "\n",
    "Quiero felicitarte por lo lejos que has llegado y decirte que has hecho un gran trabajo por llegar hasta el final de este vídeo. Espero que también trabajes con los laboratorios de práctica y los cuestionarios. Dicho esto, todavía hay muchas más cosas interesantes que aprender. En el segundo curso de esta especialización, aprenderás sobre las redes neuronales, también llamadas algoritmos de aprendizaje profundo. Las redes neuronales son las responsables de muchos de los últimos avances en la actualidad, desde el reconocimiento práctico del habla hasta los ordenadores que reconocen con precisión objetos e imágenes, pasando por los coches que se conducen solos. La forma en que se construyen las redes neuronales utiliza en realidad mucho de lo que ya has aprendido, como las funciones de coste, y el descenso de gradiente, y las funciones sigmoides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: The problem of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "¿Cuál de las siguientes opciones puede abordar el overfitting?\n",
    "- Seleccionar un subconjunto de las características más relevantes. \n",
    "- Eliminar un conjunto aleatorio de ejemplos de entrenamiento\n",
    "- Recoger más datos de entrenamiento \n",
    "- Aplicar la regularización \n",
    "\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "Usted ajusta la regresión logística con características polinómicas a un conjunto de datos, y su modelo tiene el siguiente aspecto.\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./imagenes/practica4.png\"   style=\"width:165px;height:135px;\" >\n",
    "</figure>\n",
    "\n",
    "¿A qué conclusión llegaría? (Elija una)\n",
    "\n",
    "- El modelo tiene un alto sesgo (infraajuste). Por lo tanto, es probable que añadir datos ayude\n",
    "- El modelo tiene una alta varianza (sobreajuste). Por lo tanto, es poco probable que añadir datos ayude por sí mismo. \n",
    "- El modelo tiene una alta varianza (sobreajuste). Por lo tanto, es probable que añadir datos ayude\n",
    "- El modelo tiene un sesgo elevado (infraajuste). Por lo tanto, añadir datos es, por sí mismo, poco probable que ayude. \n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "Suponga que tiene un modelo de regresión lineal regularizado. Si aumenta el parámetro de regularización $\\lambda$, ¿qué espera que ocurra con los parámetros $w_1$,$w_2$,...,$w_n$.\n",
    "- Esto reducirá el tamaño de los parámetros $w_1$,$w_2$,...,$w_n$\n",
    "- Esto aumentará el tamaño de los parámetros $w_1$,$w_2$,...,$w_n$\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1:\n",
    " \n",
    "- Seleccionar un subconjunto de las características más relevantes.\n",
    "- Recoger más datos de entrenamiento\n",
    "- Aplicar la regularización\n",
    "\n",
    "Respuesta 2: El modelo tiene una alta varianza (sobreajuste). Por lo tanto, es probable que añadir datos ayude.\n",
    "    \n",
    "Respuesta 3: Esto reducirá el tamaño de los parámetros $w_1$,$w_2$,...,$w_n$.\n",
    "   \n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
