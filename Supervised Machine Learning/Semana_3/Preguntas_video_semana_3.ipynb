{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas Videos Semana 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivations\n",
    "\n",
    "### ¿Cuál de los siguientes es un ejemplo de tarea de clasificación?\n",
    "\n",
    "\n",
    "- Estimar el peso de un gato a partir de su altura.\n",
    "- **Decidir si un animal es un gato o no es un gato.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "<img src=\"pre_video_logistic_regression.png\">\n",
    "\n",
    "Recordemos que la función sigmoidea es $ g(z) = \\frac{1}{1+e^{-z}}$  \n",
    "Si z es un número negativo grande entonces\n",
    "\n",
    "- **$g(z)$ está cerca de cero**\n",
    "- $g(z)$ está cerca de uno negativo (-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary\n",
    "\n",
    "### Digamos que está creando un algoritmo de detección de tumores. Su algoritmo se utilizará para marcar posibles tumores para su futura inspección por parte de un especialista. ¿Qué valor debería utilizar para el umbral?\n",
    "\n",
    "\n",
    "- ¿Alto, por ejemplo un umbral de 0,9?\n",
    "- **¿Bajo, digamos un umbral de 0,2?**\n",
    "\n",
    "Correcto: No querrá pasar por alto un posible tumor, por lo que querrá un umbral bajo. Un especialista revisará la salida del algoritmo, lo que reduce la posibilidad de un \"falso positivo\". El punto clave de esta pregunta es observar que el valor del umbral no tiene por qué ser 0,5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function for logistic regression\n",
    "\n",
    "### ¿Por qué no se utiliza el coste del error cuadrado en la regresión logística?\n",
    "\n",
    "- **La naturaleza no lineal del modelo da lugar a una función de costes \"ondulada\" y no convexa con muchos mínimos locales potenciales.**\n",
    "- En la regresión logística se utiliza el error cuadrático medio.\n",
    "\n",
    "Correcto\n",
    "Si se utiliza el error cuadrático medio para la regresión logística, la función de coste es \"no convexa\", por lo que es más difícil para el descenso de gradiente encontrar un valor óptimo para los parámetros w y b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Cost Function for Logistic Regression\n",
    "\n",
    "### Para la función de pérdida simplificada:\n",
    "\n",
    "$ L(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}),y^{(i)})=  -y^{(i)}log(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))-(1-y^{(i)})log(1-f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})) $\n",
    "\n",
    "si el modelo predice $ f_{\\vec{w},b}(\\mathbf{x}^{(i)})= 1 $   \n",
    "\n",
    "¿a qué se simplifica esta expresión?\n",
    "\n",
    "\n",
    "- $-(1-y^{(i)})log(1-f_{\\mathbf{\\vec{w}},b}(\\mathbf{x}^{(i)})) $\n",
    "\n",
    "-  * $ -y^{(i)}log(f_{\\vec{w},b}(\\mathbf{x}^{(i)}) $\n",
    "\n",
    "El segundo término de la expresión se reduce a cero cuando $ f_{\\vec{w},b}(\\mathbf{x}^{(i)})=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Implementation\n",
    "\n",
    "<img src=\"pre_video_gradient_descent_imp.png\">\n",
    "\n",
    "### ¿Cuál de las dos siguientes afirmaciones es más exacta sobre el descenso de gradiente para la regresión logística?\n",
    "\n",
    "\n",
    "- **Los pasos de actualización se parecen a los de la regresión lineal, pero la definición de $f_{\\vec{w},b}(\\mathbf{x}^{(i)})$ ed diferente.**\n",
    "- Los pasos de actualización son idénticos a los de la regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem of overfitting\n",
    "\n",
    "### Nuestro objetivo al crear un modelo es poder utilizarlo para predecir correctamente los resultados de nuevos ejemplos. Un modelo que hace esto se dice que generaliza bien. \n",
    "### Cuando un modelo se ajusta bien a los datos de entrenamiento pero no funciona bien con nuevos ejemplos que no están en el conjunto de entrenamiento, es un ejemplo de:\n",
    "\n",
    "\n",
    "- Un modelo que generaliza bien (ni alta varianza ni alto sesgo) \n",
    "- Un modelo que no se ajusta bien (con una varianza y un sesgo elevados) \n",
    "- Ninguna de las anteriores\n",
    "- **Sobreajuste (alta varianza) Overfiting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing overfitting\n",
    "\n",
    "### Aplicar la regularización, aumentar el número de ejemplos de entrenamiento o seleccionar un subconjunto de las características más relevantes son métodos para...\n",
    "\n",
    "\n",
    "+ Tratar el infraajuste (alto sesgo)\n",
    "- **Abordar la sobreadaptación (alta varianza)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cost function with regularization\n",
    "\n",
    "\n",
    "### Para un modelo que incluye el parámetro de regularización $ \\lambda $ (lambda), el aumento de $\\lambda $ tenderá a...\n",
    "\n",
    "- Aumenta el tamaño de los parámetros $ w_1, w_2,...w_n $\n",
    "- Aumentar el tamaño del parámetro $b$.\n",
    "- Disminuir el tamaño del parámetro ${b}$.\n",
    "- **Disminuir el tamaño de los parámetros $ w_1, w_2,...w_n $**\n",
    "\n",
    "El aumento del parámetro de regularización lambdalambda reduce el exceso de ajuste al reducir el tamaño de los parámetros.  En el caso de algunos parámetros cercanos a cero, esto reduce el efecto de las características asociadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Recordemos que el algoritmo de descenso de gradiente utiliza el cálculo del gradiente:\n",
    "\n",
    "\n",
    " $$ \\begin{align*} &\\text{repetir hasta la convergencia:} \\; \\lbrace \\\\ &  \\; \\; \\;w_j = w_j -  \\alpha \\left[ \\frac{1}{m} \\sum\\limits_{i = 1}^{m} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} + \\frac{\\lambda}{m}w_j\\right]  \\; & \\text{para  {J} = 1..n} \\\\ &  \\; \\; \\;  \\; \\;b = b -  \\alpha \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\\\ &\\rbrace \\end{align*} $$\n",
    "\n",
    " de cada iteración realiza actualizaciones simultáneas en $ w_{j}$  para todos los $j$.\n",
    "\n",
    " En la conferencia, esto se reordenó para enfatizar el impacto de la regularización:  \n",
    " \n",
    "\n",
    " $$ w_j = w_j -  \\alpha \\left[ \\frac{1}{m} \\sum\\limits_{i = 1}^{m} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} + \\frac{\\lambda}{m}w_j\\right]  \\;\\;  \\text{for j = 1..n} $$\n",
    "\n",
    " se reorganiza para ser:\n",
    "\n",
    " $$ w_j = w_j \\underbrace{ \\left(1 - \\alpha \\frac{\\lambda}{m}\\right) }_{Regulacion} - \\underbrace{ \\alpha \\frac{1}{m} \\sum\\limits_{i = 1}^{m} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} }_{Formula Original}  \\;\\;  \\text{for j = 1..n} $$\n",
    "\n",
    " ### Suponiendo que $\\alpha$, la tasa de aprendizaje, es un número pequeño como 0.001, $\\lambda$ is 1, and $ {m}=50$, ¿cuál es el efecto de la \"RegulacionRegulacion\" en la actualización de  $ w_{j}$?\n",
    "\n",
    " \n",
    "- **La Regulacion disminuye el valor de $w_{j}$ en cada iteración.**\n",
    "- La Regulacion aumenta el valor de $w_{j}$ en cada iteración.\n",
    "- El impacto de las Regulacion varía cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
