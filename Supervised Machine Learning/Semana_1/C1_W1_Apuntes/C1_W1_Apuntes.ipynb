{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/00_Logo.jpg\"   style=\"width:116px;height:218px;\" >\n",
    "</figure>\n",
    "\n",
    "# **MACHINE LEARNING SPECIALIZATION**\n",
    "# Curso 1: Supervised Machine Learning: Regression and Classification\n",
    "# Semana 1: INTRODUCTION TO MACHINE LEARNING\n",
    "\n",
    "*A continuación se presentan los apuntes tomados de los videos de la Especialización de Machine Learning dictada por DeepLearning.AI y la Universidad de Stanford que se encuentra disponible en Cursera.org*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW OF ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcom to ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1gAoPm-jbyjF6grxR1B8lHYKC8k6XhP7j/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido a Machine learning. ¿Qué es el aprendizaje automático? Probablemente lo utilices muchas veces al día sin saberlo:\n",
    "\n",
    "- Cada vez que quieres averiguar algo, como, por ejemplo, ¿cómo hago un rollo de sushi? Puedes hacer una búsqueda en Google, Bing o Baidu para averiguarlo. Y eso funciona tan bien porque su software de aprendizaje automático ha averiguado cómo clasificar las páginas web. \n",
    "- O cuando subes fotos a Instagram o Snapchat y piensas: quiero etiquetar a mis amigos para que puedan ver sus fotos. Pues estas aplicaciones pueden reconocer a tus amigos en tus fotos y etiquetarlos también. Eso también es aprendizaje automático. \n",
    "- O si acabas de ver una película de Star Wars en el servicio de streaming de vídeo y piensas ¿qué otras películas similares puedo ver? Pues el servicio de streaming probablemente utilizará el aprendizaje automático para recomendarte algo que pueda gustarte. \n",
    "- Cada vez que usas la función de voz a texto en tu teléfono para escribir un mensaje de texto. >> Hola Andrew, ¿cómo te va?. O le digas a tu teléfono: Oye Siri pon una canción de Rihanna, o pídele a tu otro teléfono ok Google muéstrame restaurantes indios cerca de mí. Eso también es aprendizaje automático. \n",
    "- Cada vez que recibes un correo electrónico titulado ¡Felicidades! Has ganado un  millón de dólares. Bueno, puede que seas rico, enhorabuena. O, más probablemente, tu servicio de correo electrónico lo marcará como spam. Eso también es una aplicación del aprendizaje automático. \n",
    "\n",
    "Más allá de las aplicaciones de consumo que usted podría utilizar, la IA también se está abriendo paso rápidamente en las grandes empresas y en las aplicaciones industriales. Por ejemplo:\n",
    "\n",
    "- me preocupa mucho el cambio climático, y me alegra ver que el aprendizaje automático ya espera optimizar la generación de energía de las turbinas eólicas. \n",
    "- O en la sanidad, está empezando a abrirse camino en los hospitales para ayudar a los médicos a realizar diagnósticos precisos. \n",
    "- O recientemente en Landing AI han estado trabajando mucho, poniendo la visión por ordenador en las fábricas para ayudar a inspeccionar si algo que sale de la línea de montaje tiene algún defecto. Eso es el aprendizaje automático.La ciencia de conseguir que los ordenadores aprendan sin ser programados explícitamente. \n",
    "\n",
    "En este curso, aprenderás sobre el aprendizaje automático y podrás implementar el aprendizaje automático y el código tú mismo. Millones de personas han tomado la versión anterior de este curso, que es, por supuesto, la que llevó a la fundación de Coursera. Y muchos estudiantes terminaron construyendo emocionantes sistemas de aprendizaje automático o incluso siguiendo carreras muy exitosas en la IA. Estoy emocionado de que estés en este viaje conmigo. Bienvenido y vamos a empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1mVsFrqsUeUWMBPLHQgvVlKxmFypyQ06E/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase, se aprende sobre el estado del arte y también se practica la implementación de algoritmos de aprendizaje automático por sí mismo. Aprenderás sobre los algoritmos de aprendizaje automático más importantes, algunos de los cuales son exactamente los que se están utilizando en las grandes empresas de IA o de tecnología hoy en día, y te harás una idea de cuál es el estado del arte en la IA. Sin embargo, más allá de aprender los algoritmos, en esta clase también se aprenden todos los consejos y trucos prácticos importantes para que funcionen bien. Podrás ponerlos en práctica y ver cómo funcionan por ti mismo.\n",
    "\n",
    "¿Por qué se utiliza tanto el aprendizaje automático hoy en día? El aprendizaje automático creció como un subcampo de la IA o inteligencia artificial. Queríamos construir máquinas inteligentes. Resulta que hay algunas cosas básicas que podemos programar para que haga una máquina, como encontrar el camino más corto de a a b, como en tu GPS. Pero, en su mayor parte, no sabíamos cómo escribir un programa explícito para hacer muchas de las cosas más interesantes, como realizar búsquedas en la web, reconocer el habla humana, diagnosticar enfermedades a partir de rayos X o construir un coche que se conduzca solo. \n",
    "\n",
    "La única forma que conocíamos de hacer estas cosas era que una máquina aprendiera a hacerlo por sí misma. En mi caso, cuando fundé y dirigí el equipo de Google Brain, trabajé en problemas como el reconocimiento del habla, la visión por ordenador para Google Maps, las imágenes de Street View y la publicidad, o la dirección de la IA por dos. Trabajé en todo, desde la IA para la realidad aumentada, pasando por la lucha contra el pago a plazos, hasta liderar un equipo de coches autoconducidos. Más recientemente, una IA de aterrizaje, el fondo de la IA en la Universidad de Stanford de nuevo para trabajar en las aplicaciones en la fábrica, la agricultura a gran escala, la atención de la salud, el comercio electrónico, y otros problemas.\n",
    "\n",
    "Hoy en día, hay cientos de miles, tal vez millones de personas que trabajan en aplicaciones de aprendizaje automático que podría decirle en las historias sobre su trabajo con el aprendizaje automático. Cuando hayas aprendido estos conocimientos, espero que tú también encuentres la gran diversión de adentrarte en emocionantes aplicaciones diferentes y quizás incluso en diferentes industrias. De hecho, me resulta difícil pensar en cualquier industria que el aprendizaje automático no pueda tocar de manera significativa ahora o en un futuro próximo.\n",
    "\n",
    "Mirando aún más hacia el futuro, mucha gente, incluido yo, está entusiasmada con el sueño de la IA de construir algún día máquinas tan inteligentes como usted o yo. Esto se llama a veces Inteligencia General Artificial o AGI. Creo que la AGI se ha exagerado y que todavía estamos muy lejos de ese objetivo. No lo sé. Tardaremos 50 años o 500 años o más en llegar. Pero la mayoría de los investigadores de IA creen que la mejor manera de acercarse a ese objetivo es utilizando algoritmos de aprendizaje. Quizá unos que se inspiren en el funcionamiento del cerebro humano. Más adelante en este curso se hablará un poco más de esta búsqueda de la IA.\n",
    "\n",
    "Según un estudio de McKinsey, se estima que la IA y el aprendizaje automático crearán un valor adicional de 13 billones de dólares anuales para el año 2023. Aunque el aprendizaje automático ya está creando enormes cantidades de valor en la industria del software, creo que podría haber incluso un valor mucho mayor que aún no se ha creado fuera de la industria del software en sectores como el comercio minorista, los viajes, el transporte, la automoción, la fabricación de materiales, etc. Debido a las enormes oportunidades sin explotar en tantos sectores diferentes, hoy en día hay una gran demanda insatisfecha de este conjunto de habilidades. Por eso es un momento tan bueno para aprender sobre el aprendizaje automático.\n",
    "\n",
    "Si las aplicaciones del aprendizaje automático te resultan interesantes, espero que me acompañes en esta clase. Casi puedo garantizar que el dominio de estas habilidades valdrá la pena. En el próximo vídeo, veremos una definición más formal de lo que es el aprendizaje automático. Y empezaremos a hablar de los principales tipos de problemas y algoritmos de aprendizaje automático. Recogeremos algo de la principal terminología del aprendizaje automático y empezaremos a tener una idea de cuáles son los diferentes algoritmos y cuándo puede ser apropiado cada uno de ellos. Así que pasemos al siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPERVISED VS UNSUPERVISED ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/16l6ZUlv6JY4LlXu89AYSNO3NOZ3MqA-i/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es el aprendizaje automático? En este vídeo, aprenderás la definición de lo que es y también tendrás una idea de cuándo podrías querer aplicarlo. Echemos un vistazo juntos.\n",
    "\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_07.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "\n",
    "Esta es una definición de lo que es el aprendizaje automático que se atribuye a Arthur Samuel. Definió el aprendizaje automático como el campo de estudio que da a los ordenadores la capacidad de aprender sin ser programados explícitamente. El reclamo de Samuel a la fama fue que, en la década de 1950, escribió el programa para jugar a las damas. Y lo sorprendente de este programa es que el propio Arthur Samuel no era muy buen jugador de damas. Lo que hizo fue programar el ordenador para que jugara tal vez decenas de miles de partidas contra sí mismo y, observando qué tipo de posiciones del tablero solían conducir a la victoria y qué posiciones solían conducir a la derrota. El programa de juego de damas aprendió con el tiempo qué posiciones del tablero eran buenas o malas. Intentando llegar a las posiciones buenas y evitar las malas, su programa aprendió a ser cada vez mejor jugando a las damas. Como el ordenador tuvo la paciencia de jugar decenas de miles de partidas contra sí mismo, fue capaz de obtener tanta experiencia en el juego de las damas que finalmente se convirtió en un mejor jugador de damas que el propio Arthur Samuel. \n",
    "\n",
    "Ahora, a lo largo de estos vídeos, además de intentar hablar de cosas, de vez en cuando te hago una pregunta para asegurarme de que entiendes el contenido. Aquí hay una sobre qué pasa si el ordenador hubiera jugado muchas menos partidas. Por favor, echa un vistazo y elige la que creas que es una respuesta mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:**\n",
    "\n",
    "Si al programa de juego de damas de Arthur Samuel se le hubiera permitido jugar sólo 10 partidas (en lugar de decenas de miles de partidas) contra sí mismo, ¿cómo habría afectado esto a su rendimiento?:\n",
    "- Lo habría mejorado\n",
    "- Habría empeorado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Habría empeorado.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias por mirar el cuestionario. Si has elegido esta respuesta, lo habrías hecho peor, entonces has acertado. En general, cuantas más oportunidades le des a un algoritmo de aprendizaje para aprender, mejor será su rendimiento. Si no seleccionaste la respuesta correcta la primera vez, tampoco pasa nada. El objetivo de estas preguntas no es ver si las aciertas todas en el primer intento, sino ayudarte a practicar el concepto que estás aprendiendo.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_09.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "La definición de Arthur Samuel era bastante informal, pero en los dos próximos vídeos profundizaremos juntos en uno de los principales tipos de algoritmos de aprendizaje automático. En esta clase, aprenderás sobre muchos algoritmos de aprendizaje diferentes. Los dos tipos principales de aprendizaje automático son el **aprendizaje supervisado** y el **aprendizaje no supervisado**. Definiremos mejor el significado de estos términos en los próximos vídeos.  \n",
    "\n",
    "De estos dos, el aprendizaje supervisado es el tipo de aprendizaje automático que más se utiliza en muchas aplicaciones del mundo real, y que ha visto el avance y la innovación más rápidos. Sin embargo, en esta especialización que tiene tres cursos, la primera y la segunda se centrarán en el aprendizaje supervisado y la tercera en el aprendizaje no supervisado.  \n",
    "\n",
    "Es posible que también haya oído hablar del **aprendizaje por refuerzo**. Este es otro tipo de algoritmo de aprendizaje de la máquina no habló brevemente, pero, con mucho, los dos tipos de álbumes de aprendizaje más utilizados hoy en día son el aprendizaje supervisado y el aprendizaje no supervisado. Por eso pasaremos la mayor parte de esta clase hablando de ellos.  \n",
    "\n",
    "La otra cosa a la que vamos a dedicar mucho tiempo en esta especialización son los consejos prácticos para aplicar los algoritmos de aprendizaje. Esto es algo que considero muy importante. Enseñar sobre algoritmos de aprendizaje es como dar a alguien un conjunto de herramientas. Y tan importante o más que asegurarse de que tiene grandes herramientas es asegurarse de que sabe cómo aplicarlas. \n",
    "Porque de qué sirve que alguien te dé un martillo de acero o un taladro de mano de acero y te diga buena suerte, ahora tienes todas las herramientas que necesitas para construir una casa de tres pisos, realmente no funciona así. Y así también en el aprendizaje automático, asegurarse de tener las herramientas es realmente importante. Y así como asegurarse de que usted sabe cómo aplicar las herramientas de aprendizaje automático con eficacia. Así que eso es lo que obtienes en esta clase, las herramientas, así como las habilidades y la aplicación de ellos con eficacia.  \n",
    "\n",
    "Visito regularmente a amigos y equipos en algunas de las principales empresas de tecnología. E incluso hoy en día, veo a los equipos de aprendizaje automático experimentados aplicar algoritmos de aprendizaje automático a algunos problemas y, a veces, han estado trabajando en ello durante seis meses sin mucho éxito. Y cuando veo lo que están haciendo, a veces siento que podría haberles dicho hace seis meses que el enfoque actual no va a funcionar y que hay una forma diferente de utilizar estas herramientas que les dará una oportunidad mucho mayor de éxito. Así que, en esta clase, una de las cosas relativamente únicas que se aprende es que se aprende mucho sobre las mejores prácticas de cómo desarrollar realmente un sistema de aprendizaje automático práctico y valioso. De esta manera, es menos probable que termines en uno de esos equipos que terminan perdiendo seis meses yendo en la dirección equivocada.  \n",
    "\n",
    "En esta clase, obtendrás una idea de cómo los ingenieros de aprendizaje automático más hábiles construyen sistemas, y espero que termines esta clase como una de esas muy raras personas en el mundo de hoy que saben cómo diseñar y construir sistemas de aprendizaje automático serios. Así que eso es el aprendizaje automático. En el siguiente vídeo, vamos a profundizar en lo que es el aprendizaje supervisado y también en lo que es el aprendizaje no supervisado. Además, aprenderás cuándo podrías querer utilizar cada uno de ellos, el aprendizaje supervisado y el no supervisado. Nos vemos en el próximo vídeo.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/196zlqVXLcJCHnaDQbeHHGWlkpQZnTrVM/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje automático está creando un enorme valor económico hoy en día. Creo que el 99% del valor económico creado por el aprendizaje automático hoy en día es a través de un tipo de aprendizaje automático, que se llama **aprendizaje supervisado**. Echemos un vistazo a lo que eso significa.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_11.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "El aprendizaje automático supervisado o, más comúnmente, el aprendizaje supervisado, se refiere a los algoritmos que aprenden las relaciones entre $x$ e $y$ o entre la entrada y la salida. La característica clave del aprendizaje supervisado es que usted le da a su algoritmo de aprendizaje ejemplos de los que aprender. Esto incluye las respuestas correctas, es decir, la etiqueta correcta y para una entrada dada $(x, y)$ es viendo pares correctos de entrada $x$ y la etiqueta de salida deseada $y$ que el algoritmo de aprendizaje eventualmente aprende a tomar sólo la entrada sin la etiqueta de salida y da una predicción o conjetura razonablemente precisa de la salida. Veamos algunos ejemplos.    \n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_12.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Si la entrada $x$ es un correo electrónico y la salida $y$ es este correo, spam o no spam, esto te da tu ***filtro de spam***. O si la entrada es un clip de audio y el trabajo del algoritmo es la salida de la transcripción del texto, entonces esto es el ***reconocimiento de voz***. O si se quiere introducir el inglés y obtener la correspondiente traducción al español, al árabe, al hindi, al chino, al japonés o a cualquier otra cosa, entonces se trata de la ***traducción automática***. O la forma más lucrativa de aprendizaje supervisado hoy en día se utiliza probablemente en la ***publicidad online***. Casi todas las grandes plataformas de publicidad en línea tienen un algoritmo de aprendizaje que introduce cierta información sobre un anuncio y cierta información sobre usted y luego intenta averiguar si hará clic en ese anuncio o no. Porque al mostrarte anuncios en los que es un poco más probable que hagas clic, para estas grandes plataformas de publicidad en línea, cada clic es un ingreso, esto realmente impulsa una gran cantidad de ingresos para estas empresas. Esto es algo en lo que una vez trabajé mucho, tal vez no sea la aplicación más inspiradora, pero ciertamente tiene un impacto económico significativo en algunos países hoy en día. O si se quiere construir un coche de autoconducción, el algoritmo de aprendizaje tomaría como entrada una imagen y alguna información de otros sensores, como un radar u otras cosas, y luego trataría de dar salida a la posición de, digamos, otros coches para que su coche de ***autoconducción*** pueda conducir con seguridad alrededor de los otros coches. O bien, la fabricación. De hecho, he trabajado mucho en este sector en el aprendizaje de la IA. Un algoritmo de aprendizaje puede tomar como entrada una foto de un producto fabricado, por ejemplo un teléfono móvil que acaba de salir de la línea de producción, y hacer que el algoritmo de aprendizaje indique si hay o no un rasguño, una abolladura u otro defecto en el producto. Esto se llama ***inspección visual*** y ayuda a los fabricantes a reducir o prevenir los defectos en sus productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todas estas aplicaciones, primero se entrena el modelo con ejemplos de entradas $x$ y las respuestas correctas, es decir, las etiquetas $y$. Después de que el modelo haya aprendido de estos pares de (entrada, salida) o $(x,y)$, puede tomar una entrada nueva $x$, algo que nunca ha visto antes, y tratar de producir la salida correspondiente adecuada $y$. Vamos a profundizar en un ejemplo específico.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_13.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Digamos que quieres predecir el precio de la vivienda en función del tamaño de la misma. Has recogido algunos datos y digamos que graficas los datos y se ve así. Aquí en el eje horizontal está el tamaño de la casa en pies cuadrados. Sí, vivo en los Estados Unidos donde todavía usamos los pies cuadrados. Sé que la mayor parte del mundo utiliza metros cuadrados. Aquí en el eje vertical está el precio de la casa en, digamos, miles de dólares. Con estos datos, digamos que un amigo quiere saber cuál es el precio de su casa de 750 pies cuadrados. ¿Cómo puede ayudarle el algoritmo de aprendizaje? Una cosa que un algoritmo de aprendizaje podría hacer, es decir, para la línea recta a los datos y la lectura de la línea recta, parece que la casa de su amigo podría ser vendido por tal vez alrededor de, no sé, 150.000 dólares. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero ajustar una línea recta no es el único algoritmo de aprendizaje que se puede utilizar. Hay otros que podrían funcionar mejor para esta aplicación. Por ejemplo, si se rastrea y se ajusta una línea recta, podrías decidir que es mejor ajustar una curva, una función que es ligeramente más complicada o más compleja que una línea recta. Si haces eso y haces una predicción aquí, entonces parece que, bueno, la casa de tu amigo podría venderse por más de 200.000 dólares.  \n",
    "\n",
    "Una de las cosas que verás más adelante en esta clase es cómo puedes decidir si ajustar una línea recta, una curva u otra función que sea aún más compleja a los datos. Ahora bien, no parece apropiado elegir la que le da a tu amigo el mejor precio, pero una cosa que ves es cómo conseguir que un algoritmo elija sistemáticamente la línea o curva u otra cosa más apropiada para ajustar a estos datos. Lo que has visto en esta diapositiva es un ejemplo de aprendizaje supervisado. Porque hemos dado al algoritmo un conjunto de datos en el que la llamada respuesta correcta, es decir, la etiqueta o el precio correcto y se da para cada casa en la parcela. La tarea del algoritmo de aprendizaje es producir más de estas respuestas correctas, concretamente predecir cuál es el precio probable de otras casas como la de su amigo. Por eso se trata de un aprendizaje supervisado.  \n",
    "\n",
    "Para definir un poco más la terminología, esta predicción del precio de la vivienda es el tipo particular de aprendizaje supervisado llamado **regresión**. Por regresión, quiero decir que estamos tratando de predecir un número a partir de infinitos números posibles como el precio de la vivienda en nuestro ejemplo, que podría ser 150.000 o 70.000 o 183.000 o cualquier otro número intermedio. Eso es el aprendizaje supervisado, el aprendizaje de mapeos de entrada, salida o de $x$ a $y$.  \n",
    "\n",
    "En este vídeo has visto un ejemplo de regresión en el que la tarea es predecir un número. Pero también hay un segundo tipo principal de problema de aprendizaje supervisado llamado clasificación. Veamos qué significa esto en el siguiente vídeo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1cJPFhNrvCYyOW4UZ8c3kfp7l3RX-Jmmx/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que los algoritmos de aprendizaje supervisado aprenden a predecir la entrada, la salida o el mapeo de $x$ a $y$. Y en el último vídeo has visto que los algoritmos de regresión, que es un tipo de algoritmo de aprendizaje supervisado, aprenden a predecir números de entre infinitos números posibles. Hay un segundo tipo principal de algoritmo de aprendizaje supervisado llamado algoritmo de **clasificación**. Veamos qué significa esto.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_15.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Tomemos la detección del cáncer de mama como ejemplo de un problema de clasificación. Digamos que estás construyendo un sistema de aprendizaje automático para que los médicos puedan tener una herramienta de diagnóstico para detectar el cáncer de mama. Esto es importante porque la detección temprana podría salvar la vida de un paciente. Utilizando los registros médicos de un paciente, tu sistema de aprendizaje automático intenta averiguar si un tumor que es un bulto es maligno, es decir, canceroso o peligroso. O si ese tumor, ese bulto es benigno, lo que significa que es sólo un bulto que no es canceroso y no es tan peligroso... Algunos de mis amigos han estado trabajando en este problema específico.  \n",
    "\n",
    "Así que tal vez su conjunto de datos tiene tumores de varios tamaños. Y estos tumores están etiquetados como benignos, que designaré en este ejemplo con un 0 o malignos, que designaré en este ejemplo con un 1. Entonces puedes trazar tus datos en un gráfico como este donde el eje horizontal representa el tamaño del tumor y el eje vertical toma sólo dos valores 0 o 1 dependiendo de si el tumor es benigno, 0 o maligno 1. \n",
    "Una de las razones por las que esto es diferente de la regresión es que estamos tratando de predecir sólo un pequeño número de posibles salidas o categorías. En este caso, dos posibles salidas 0 o 1, benigno o maligno. Esto es diferente de la regresión, que trata de predecir cualquier número, todos los números posibles infinitos. El hecho de que sólo haya dos resultados posibles es lo que hace esta clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las razones por las que esto es diferente de la regresión es que estamos tratando de predecir sólo un pequeño número de posibles salidas o categorías. En este caso, dos posibles salidas 0 o 1, benigno o maligno. Esto es diferente de la regresión, que trata de predecir cualquier número, todos los números posibles infinitos. El hecho de que sólo haya dos resultados posibles es lo que hace esta clasificación. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_16.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Debido a que sólo hay dos posibles salidas o dos posibles categorías en este ejemplo, también puede trazar este conjunto de datos en una línea como esta. En este momento, voy a utilizar dos símbolos diferentes para denotar la categoría utilizando un círculo una O para denotar los ejemplos benignos y una cruz para denotar los ejemplos malignos. Y si un nuevo paciente entra para un diagnóstico y tiene un bulto de este tamaño, entonces la pregunta es, ¿clasificará su sistema este tumor como benigno o maligno?.\n",
    "\n",
    "Resulta que en los problemas de clasificación también puedes tener más de dos categorías de salida posibles. Quizás tu algoritmo de aprendizaje puede dar como resultado múltiples tipos de diagnóstico de cáncer si resulta ser maligno. Así que llamemos a dos tipos diferentes de cáncer tipo 1 y tipo 2. En este caso la media tendría tres posibles categorías de salida que podría predecir. Y, por cierto, en la clasificación, los términos **clases de salida** y **categorías de salida** se utilizan a menudo indistintamente. Así que lo que digo clase o categoría cuando me refiero a la salida, significa lo mismo. \n",
    "\n",
    "Así que para resumir los algoritmos de clasificación predicen categorías. Las categorías no tienen por qué ser números. Pueden ser no numéricas, por ejemplo, pueden predecir si una foto es de un gato o de un perro. Y puede predecir si un tumor es benigno o maligno. Las categorías también pueden ser números como 0, 1 o 0, 1, 2. Pero lo que diferencia a la clasificación de la regresión a la hora de interpretar los números es que la clasificación predice un pequeño conjunto limitado de posibles categorías de salida, como 0, 1 y 2, pero no todos los posibles números intermedios, como 0,5 o 1,7.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_17.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En el ejemplo de aprendizaje supervisado que hemos visto, sólo teníamos un valor de entrada, el tamaño del tumor. Pero también se puede utilizar más de un valor de entrada para predecir una salida. Aquí tenemos un ejemplo, en lugar de conocer sólo el tamaño del tumor, digamos que también tenemos la edad de cada paciente en años. Su nuevo conjunto de datos tiene ahora dos entradas, la edad y el tamaño del tumor. En este nuevo conjunto de datos vamos a utilizar círculos para mostrar los pacientes cuyos tumores son benignos y cruces para mostrar los pacientes con un tumor maligno. Así que cuando un nuevo paciente llega, el médico puede medir el tamaño del tumor del paciente y también registrar la edad del paciente.  \n",
    "\n",
    "Y así, dado esto, ¿cómo podemos predecir si el tumor de este paciente es benigno o maligno? Bueno, dado el día dicho así, lo que el algoritmo de aprendizaje podría hacer es encontrar algún límite que separe los tumores malignos de los benignos. Así que el algoritmo de aprendizaje tiene que decidir cómo ajustar una línea de límite a través de estos datos. La línea divisoria encontrada por el algoritmo de aprendizaje ayudaría al médico en el diagnóstico. En este caso, es más probable que el tumor sea benigno. En este ejemplo hemos visto cómo se pueden utilizar como entradas la edad del paciente y el tamaño del tumor. En otros problemas de aprendizaje automático a menudo se requieren muchos más valores de entrada. Mis amigos que han trabajado en la detección del cáncer de mama utilizan muchas entradas adicionales, como el grosor del grupo de tumores, la uniformidad del tamaño de las células, la uniformidad de la forma de las células, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_18.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que, para recapitular, el aprendizaje supervisado asigna la entrada $x$ a la salida $y$, donde el algoritmo de aprendizaje aprende de las respuestas correctas citadas. Los dos tipos principales de aprendizaje supervisado son la regresión y la clasificación. En una aplicación de regresión, como la predicción de los precios de las casas, el algoritmo de aprendizaje tiene que predecir números a partir de infinitos números de salida posibles. Mientras que en la clasificación el algoritmo de aprendizaje tiene que hacer una predicción de una categoría, de un pequeño conjunto de posibles salidas. \n",
    "\n",
    "**Pregunta:**\n",
    "\n",
    "El aprendizaje supervisado es cuando damos a nuestro algoritmo de aprendizaje la respuesta correcta y para cada ejemplo del que debe aprender.  ¿Cuál es un ejemplo de aprendizaje supervisado?\n",
    "- Calcular la edad media de un grupo de clientes.\n",
    "- El filtrado de spam. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: El filtrado de spam.\n",
    "    \n",
    "*Por ejemplo, los correos electrónicos etiquetados como \"spam\" o \"no spam\" son ejemplos utilizados para entrenar un algoritmo de aprendizaje supervisado. El algoritmo entrenado podrá entonces predecir con cierto grado de precisión si un correo electrónico no visto es spam o no.*\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que ya sabes qué es el aprendizaje supervisado, que incluye tanto la regresión como la clasificación. Espero que te diviertas. A continuación, hay un segundo tipo importante de aprendizaje automático llamado aprendizaje no supervisado. Pasemos al siguiente vídeo para ver en qué consiste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1JpeYORVXUUdY-zZZe0y17N5ZtZFLZC8b/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del aprendizaje supervisado, la forma más utilizada de aprendizaje automático es el **aprendizaje no supervisado**. Echemos un vistazo a lo que eso significa.  \n",
    "\n",
    "Hemos hablado del aprendizaje supervisado y este vídeo es sobre el aprendizaje no supervisado. Pero no dejes que el nombre de no supervisado para usted, el aprendizaje no supervisado es, creo, tan super como el aprendizaje supervisado.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_21.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Cuando estamos viendo el aprendizaje supervisado en el último video recordado, se ve algo así en el caso de un problema de clasificación. Cada ejemplo, se asoció con una etiqueta de salida y como benigno o maligno, designado por los circulos y cruces. \n",
    "\n",
    "En el aprendizaje no supervisado se dan datos que no están asociados con ninguna etiqueta de salida $y$, digamos que se dan datos sobre pacientes y el tamaño de su tumor y la edad del paciente. Pero no si el tumor era benigno o maligno, por lo que el conjunto de datos se ve así a la derecha. No se nos pide que diagnostiquemos si el tumor es benigno o maligno, porque no se nos da ninguna etiqueta. Por qué en el conjunto de datos, en cambio, nuestro trabajo es encontrar alguna estructura o algún patrón o simplemente encontrar algo interesante en los datos. Esto es aprendizaje no supervisado, lo llamamos no supervisado porque no estamos tratando de supervisar el algoritmo. Para dar alguna cita respuesta correcta para cada entrada, en su lugar, le pedimos a la nuestra habitación para averiguar todo por sí mismo lo que es interesante. O qué patrones o estructuras que podrían estar en estos datos. Con este conjunto de datos en particular, un algoritmo de aprendizaje no supervisado, podría decidir que los datos pueden ser asignados a dos grupos diferentes o dos *clusters* diferentes. Y así podría decidir que hay un grupo de clústeres por aquí, y que hay otro clúster o grupo por aquí. Este es un tipo particular de aprendizaje no supervisado, llamado **algoritmo de clustering**. Porque coloca los datos no etiquetados, en diferentes clusters y esto resulta ser utilizado en muchas aplicaciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_22.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Por ejemplo, el clustering se utiliza en Google News, lo que hace Google News es que cada día va. Y mira cientos de miles de artículos de noticias en Internet, y agrupa las historias relacionadas. Por ejemplo, aquí hay una muestra de Google News, donde el titular del artículo principal, es el panda gigante da a luz a crías gemelas en el zoológico más antiguo de Japón. Este artículo me ha llamado la atención, porque a mi hija le encantan los pandas y por eso hay un montón de juguetes de panda. Y viendo los vídeos de pandas en mi casa, y viendo esto, puede que te des cuenta de que debajo de esto hay otros artículos relacionados. Tal vez sólo por los titulares, se puede empezar a adivinar lo que la agrupación podría estar haciendo. Fíjate en que la palabra panda aparece aquí, aquí, aquí y aquí (señala en azul) y fíjate en que la palabra gemelo también aparece en los cinco artículos (señala en rojo). Y la palabra Zoo también aparece en todos estos artículos (señala en amarillo), así que el algoritmo de agrupación está encontrando artículos. Todos los cientos de miles de artículos de noticias en Internet ese día, encontrando los artículos que mencionan palabras similares y agrupándolos en clusters. Ahora, lo que es genial es que este algoritmo de agrupación se da cuenta por sí mismo que las palabras sugieren, que ciertos artículos están en el mismo grupo.  \n",
    "\n",
    "Lo que quiero decir es que no hay un empleado en Google News que le diga al algoritmo que encuentre artículos con la palabra panda, gemelos y zoo para ponerlos en el mismo grupo, los temas de las noticias cambian cada día. Y hay tantas noticias, que simplemente no es factible que la gente haga esto todos los días para todos los temas que utilizan portadas. En su lugar, el algoritmo tiene que averiguar por su cuenta, sin supervisión, cuáles son los clústeres de artículos de noticias de hoy. Por eso este algoritmo de clustering, es un tipo de algoritmo de aprendizaje no supervisado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_23.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos el segundo ejemplo de aprendizaje no supervisado aplicado a la agrupación de datos genéticos o de ADN. Esta imagen muestra una foto de datos de microarreglos de ADN, que parecen pequeñas cuadrículas de una hoja de cálculo. Y cada pequeña columna representa la actividad genética o de ADN de una persona. Así que, por ejemplo, toda esta columna de aquí es del ADN de una persona, y esta otra columna es de otra persona, cada fila representa un gen en particular (personas amarilla y roja). Así que sólo como un ejemplo, tal vez este papel aquí podría representar un gen que afecta al color de los ojos (señala en el ojo amarillo), o este papel aquí es un gen que afecta a la altura de alguien (personas lilas). Los investigadores han encontrado incluso un vínculo genético con la aversión a ciertas verduras, como el brócoli, las coles de Bruselas o los espárragos (verduras dibujadas). Así que la próxima vez que alguien te pregunte por qué no te has terminado la ensalada, puedes decirle que quizá sea genético por la microrraza del ADN.  \n",
    "\n",
    "La idea es medir la cantidad de ciertos genes, se expresan para cada persona individual. Así que estos colores rojo, verde, gris, y así sucesivamente, muestran el grado en que diferentes individuos hacen, o no tienen un gen específico activo. Y lo que se puede hacer es ejecutar un algoritmo de agrupación para agrupar a los individuos en diferentes categorías. O diferentes tipos de personas como tal vez estos individuos que se agrupan, y vamos a llamar a este tipo 1. Y estas personas se agrupan en el tipo 2, y estas personas se agrupan como tipo 3. Este es el aprendizaje no supervisado, porque no estamos diciendo el algoritmo de antemano, que hay un tipo de persona con ciertas características. O una persona de tipo 2 con ciertas características, en cambio lo que estamos diciendo es aquí hay un montón de datos. No sé cuáles son los diferentes tipos de personas, pero puedes encontrar automáticamente la estructura en los datos. Y automáticamente averiguar si los principales tipos de individuos, ya que no estamos dando el algoritmo la respuesta correcta para los ejemplos de antemano. Este es el aprendizaje no supervisado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_24.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está el tercer ejemplo, muchas empresas tienen enormes bases de datos de información de los clientes dados estos datos. Pueden agrupar automáticamente a sus clientes, en diferentes segmentos de mercado para poder atenderlos más eficientemente. Concretamente el equipo de DeepLearning.AI hizo una investigación para entender mejor la comunidad de DeepLearning.AI. Y por qué diferentes personas toman estas clases, se suscriben al boletín semanal de lotes o asisten a nuestros eventos de IA. Vamos a visualizar la comunidad de DeepLearning.AI, como esta colección de personas que ejecutan la agrupación. Es decir, la segmentación del mercado encontró algunos grupos distintos de individuos, la motivación principal de un grupo es la búsqueda de conocimientos para hacer crecer sus habilidades. Tal vez este es usted, y por lo que es grande, la motivación principal de un segundo grupo está buscando una manera de desarrollar su carrera. Tal vez quiera conseguir un ascenso o un nuevo puesto de trabajo, o progresar en su carrera, si esto le describe, también es estupendo. Y otro grupo quiere estar al día sobre el impacto de la IA en su campo de trabajo. Esta es una agrupación que nuestro equipo utilizó para tratar de servir mejor a nuestra comunidad, ya que estamos tratando de averiguar las principales categorías de los estudiantes en la comunidad más profunda. Y, así que, si cualquiera de estos es su principal motivación para el aprendizaje, eso es genial. Y espero poder ayudarte en tu viaje, o en caso de que seas tú, y quieras algo totalmente diferente a las otras tres categorías. Eso está bien también, y quiero que sepas, que te quiero igual.\n",
    "\n",
    "Así que para resumir un algoritmo de clustering. Que es un tipo de algoritmo de aprendizaje no supervisado, toma datos sin etiquetas y trata de agruparlos automáticamente en clusters. Y así, quizás la próxima vez que veas o pienses en un panda, quizás también pienses en clustering. Y además de la agrupación, también hay otros tipos de aprendizaje no supervisado. Pasemos al siguiente vídeo, para echar un vistazo a otros tipos de algoritmos de aprendizaje no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1FGEBlfUpX2u3YWBi8t38Q992bwE9TQtr/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, hemos visto qué es el aprendizaje no supervisado y un tipo de aprendizaje no supervisado llamado clustering. Vamos a dar una definición algo más formal del aprendizaje no supervisado y a echar un vistazo rápido a otros tipos de aprendizaje no supervisado distintos del clustering.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_26.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Mientras que, en el aprendizaje supervisado, los datos vienen con entradas $x$ y etiquetas de entrada $y$, en el aprendizaje no supervisado, los datos vienen sólo con entradas $x$ pero no con etiquetas de salida $y$, y el algoritmo tiene que encontrar alguna estructura o algún patrón o algo interesante en los datos. Estamos viendo un ejemplo de aprendizaje no supervisado llamado **algoritmo de clustering**, que agrupa puntos de datos similares. En esta especialización, aprenderás sobre clustering así como otros dos tipos de aprendizaje no supervisado. Uno se llama **detección de anomalías**, que se utiliza para detectar eventos inusuales. Esto resulta ser realmente importante para la detección de fraudes en el sistema financiero, donde los eventos inusuales, las transacciones inusuales podrían ser signos de fraude y para muchas otras aplicaciones. También se aprende sobre la **reducción de la dimensionalidad**. Esto permite tomar un gran conjunto de datos y comprimirlo casi mágicamente a un conjunto de datos mucho más pequeño, perdiendo la menor información posible. En caso de que la detección de anomalías y la reducción de la dimensionalidad no parezcan tener mucho sentido para usted todavía. No se preocupe por ello. Llegaremos a esto más adelante en la especialización.  \n",
    "\n",
    "Ahora, me gustaría hacerte otra pregunta para ayudarte a comprobar tu comprensión, y sin presión, si no la aciertas a la primera, está totalmente bien. Por favor, selecciona cualquiera de los siguientes que creas que son ejemplos de aprendizaje no supervisado. Dos son ejemplos de aprendizaje no supervisado y dos son ejemplos de aprendizaje supervisado. Por favor, echa un vistazo.\n",
    "\n",
    "**Pregunta:**\n",
    "De los siguientes ejemplos, ¿cuál abordaría utilizando un algoritmo de aprendizaje no supervisado?  (Marque todas las que correspondan).\n",
    "\n",
    "- Dado un conjunto de artículos de noticias encontrados en la web, agruparlos en conjuntos de artículos sobre las mismas historias.\n",
    "- Dado un correo electrónico etiquetado como spam/no spam, aprender un filtro de spam.\n",
    "- Dada una base de datos de clientes, descubrir automáticamente segmentos de mercado y agrupar a los clientes en diferentes segmentos de mercado.\n",
    "- Dado un conjunto de datos de pacientes diagnosticados como diabéticos o no, aprender a clasificar a los nuevos pacientes como diabéticos o no.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuestas:\n",
    "- Dado un conjunto de artículos de noticias encontrados en la web, agruparlos en conjuntos de artículos sobre las mismas historias.\n",
    "- Dada una base de datos de clientes, descubrir automáticamente segmentos de mercado y agrupar a los clientes en diferentes segmentos de mercado.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá recuerde el problema del filtrado de spam. Si tienes datos etiquetados que ahora etiquetas como correo electrónico spam o no spam, puedes tratar esto como un problema de aprendizaje supervisado. El segundo ejemplo, el de las noticias. Es exactamente el ejemplo de Google News y tangible que viste en el último vídeo. Puedes abordarlo utilizando un algoritmo de clustering para agrupar los artículos de noticias, que utilizaremos el aprendizaje no supervisado. El ejemplo de segmentación de mercado del que hablé un poco antes. Puedes hacer eso como un problema de aprendizaje no supervisado también porque puedes darle a tu algoritmo algunos datos y pedirle que descubra segmentos de mercado automáticamente. El último ejemplo sobre el diagnóstico de la diabetes. Bueno, en realidad es muy parecido a nuestro ejemplo del cáncer de mama de los vídeos de aprendizaje supervisado. Sólo que, en lugar de tumores benignos o malignos, tenemos diabetes o no diabetes. Puedes enfocar esto como un problema de aprendizaje supervisado, igual que hicimos con el problema de clasificación de tumores de mama. Aunque en el último vídeo hemos hablado principalmente de clustering, en vídeos posteriores, en esta especialización, profundizaremos mucho más en la detección de anomalías y en la reducción de la dimensionalidad. Eso es aprendizaje no supervisado. Antes de terminar esta sección, quiero compartir con ustedes algo que me parece realmente emocionante, y útil, que es el uso de Jupyter Notebooks en el aprendizaje automático. Vamos a echar un vistazo a eso en el siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1DV0H1RX_ELck0H6psmsHIeHwNmUMXb86/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los vídeos, has visto el aprendizaje supervisado y el aprendizaje no supervisado y también ejemplos de ambos. Para que entiendas más profundamente estos conceptos, me gustaría invitarte en esta clase a que veas, aprendas y quizás más tarde escribas tú mismo códigos para implementar estos conceptos. La herramienta más utilizada por los profesionales del aprendizaje automático y la ciencia de datos hoy en día es el **Jupyter Notebook**. Este es el entorno por defecto que muchos de nosotros utilizamos para codificar y experimentar y probar cosas. En esta clase, aquí mismo en tu navegador web, construirás un entorno de Jupyter Notebook de usuario para probar algunas de estas ideas por ti mismo también. No se trata de un entorno simplificado, sino de los mismos entornos, la misma herramienta, el Jupyter Notebook que los desarrolladores están utilizando en muchos países grandes ahora mismo.  \n",
    "\n",
    "Un tipo de laboratorio que verás a lo largo de esta clase son los laboratorios opcionales, que son los que puedes abrir y ejecutar una línea a la vez sin necesidad de escribir ningún código. Los laboratorios opcionales están diseñados para ser muy fáciles y puedo garantizar que obtendrás la máxima puntuación, en todos y cada uno de ellos, porque no hay marcas. Todo lo que tienes que hacer es abrirlo y ejecutar el código que te hemos proporcionado. Al leer y ejecutar el código en los laboratorios opcionales, verás cómo se ejecuta el código de aprendizaje automático. Deberías completarlos relativamente rápido simplemente ejecutando una línea a la vez de arriba a abajo. Los laboratorios opcionales son completamente opcionales, así que no tienes que hacerlos si no quieres, pero espero que les eches un vistazo porque ejecutarlos te dará una sensación más profunda, te dará un poco más de experiencia con lo que son los algoritmos de aprendizaje automático, cómo es el código de aprendizaje automático.  \n",
    "\n",
    "A partir de la próxima semana, también habrá algunos laboratorios de práctica que te darán la oportunidad de escribir algo de ese código por ti mismo, pero llegaremos a eso la próxima semana. No te preocupes por eso por ahora y espero que sólo pases por el siguiente laboratorio opcional y que termines el resto del contenido de esta semana.  \n",
    "\n",
    "Veamos un ejemplo de cuaderno. Esto es lo que ves cuando vas al primer laboratorio opcional. Siéntete libre de desplazarte hacia arriba y hacia abajo y de navegar y pasar el ratón por los diferentes menús y echar un vistazo a las diferentes opciones aquí. Puedes notar que hay dos tipos de estos bloques, también llamados **celdas** en el cuaderno y hay dos tipos de celdas. Una es lo que se llama **celda Markdown**, que significa un montón de textos. Aquí puedes editar el texto si no te gusta el texto que escribimos, pero este es un texto que describe el código. Luego hay un segundo tipo de bloque o celda que se parece a esto, que tiene una **celda de código**. Aquí, ya hemos proporcionado el código y si quieres ejecutar esta celda de código, presionando Shift Enter se ejecutará el código en esta celda de código, y, por cierto, si haces clic en una celda de markdown, así que esto muestra todo este formato, sigue adelante y presiona Shift Enter en tu teclado también y eso también se convertirá de nuevo en este texto bien formateado. Este laboratorio opcional muestra un código Python común, así que puedes seguir adelante y ejecutar esto después en tu propio cuaderno Jupyter. Cuando entres en este cuaderno, lo que me gustaría que hicieras es seleccionar las celdas y pulsar Shift Enter. Lee el código, mira si tiene sentido, trata de hacer una predicción sobre lo que crees que haría este código y luego pulsa Shift Enter y luego ve lo que el código realmente hace, y si te gusta, siéntete libre de ir y editar el código, cambiar el código, y luego ejecutarlo y ver qué pasa. Si no has jugado en el entorno de Jupyter Notebook para, espero que te familiarices con Python en un Jupyter Notebook. Yo paso muchas horas jugando en los Jupyter Notebooks y espero que tú también te diviertas con ellos.  \n",
    "\n",
    "Después de esto, espero veros en el siguiente vídeo en el que tomaremos el problema de aprendizaje supervisado para empezar a dar cuerpo a nuestro primer algoritmo de aprendizaje supervisado. Espero que sea divertido para ti y espero verte allí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Supervised vs unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 1**\n",
    "¿Cuáles son los dos tipos habituales de aprendizaje supervisado? (Elija dos)\n",
    "- Clustering\n",
    "- Regresión\n",
    "- Clasificación\n",
    "\n",
    "**Pregunta 2**\n",
    "¿Cuál de estos es un tipo de aprendizaje no supervisado?\n",
    "- Regresión\n",
    "- Agrupación\n",
    "- Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuestas:\n",
    "   \n",
    "*Pregunta 1*\n",
    "- Regresión\n",
    "- Clasificación\n",
    "\n",
    "*Pregunta 2*\n",
    "- Agrupación\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1UfhEk7czXHEc0ypz4qk9B64BYVU3ppVY/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este vídeo, veremos cómo es el proceso general del aprendizaje supervisado. En concreto, verás el primer modelo de este curso, el **Modelo de Regresión Lineal**. Esto significa simplemente ajustar una línea recta a tus datos. Es probablemente el algoritmo de aprendizaje más utilizado en la actualidad. A medida que te familiarices con la regresión lineal, muchos de los conceptos que veas aquí también se aplicarán a otros modelos de aprendizaje automático que verás más adelante en esta especialización. Comencemos con un problema que puedes abordar utilizando la regresión lineal.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_30.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Digamos que quieres predecir el precio de una casa basándote en el tamaño de la misma. Este es el ejemplo que hemos visto esta semana. Vamos a utilizar un conjunto de datos sobre tamaños y precios de casas de Portland, una ciudad de Estados Unidos. Aquí tenemos un gráfico donde el eje horizontal es el tamaño de la casa en pies cuadrados, y el eje vertical es el precio de una casa en miles de dólares. Vamos a seguir adelante y trazar los puntos de datos para varias casas en el conjunto de datos. Aquí cada punto de datos, cada una de estas pequeñas cruces es una casa con el tamaño y el precio por el que se vendió recientemente. Ahora, digamos que eres un agente inmobiliario en Portland y estás ayudando a un cliente a vender su casa. Ella te pregunta: ¿cuánto crees que puedo conseguir por esta casa? Este conjunto de datos podría ayudarte a estimar el precio que podría obtener por ella. Empiezas midiendo el tamaño de la casa, y resulta que la casa tiene 1250 pies cuadrados. ¿Por cuánto crees que podría venderse esta casa? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa que podrías hacer es construir un modelo de regresión lineal a partir de este conjunto de datos. Tu modelo ajustará una línea recta a los datos, que podría tener este aspecto. Sobre la base de esta línea recta ajustada a los datos, se puede ver que la casa es de 1250 pies cuadrados, que se cruzan con la línea de mejor ajuste aquí, y si usted traza que el eje vertical de la izquierda, se puede ver el precio es tal vez por aquí, digamos alrededor de $220,000. Este es un ejemplo de lo que se llama un modelo de aprendizaje supervisado. Lo llamamos aprendizaje supervisado porque primero se entrena un modelo dando datos que tienen respuestas correctas porque se obtienen los ejemplos del modelo de casas con el tamaño de la casa, así como el precio que el modelo debe predecir para cada casa. Pues bien, aquí están los precios, es decir, se dan las respuestas correctas para cada casa del conjunto de datos. Este modelo de regresión lineal es un tipo particular de modelo de aprendizaje supervisado. Se llama modelo de regresión porque predice números como salida, como los precios en dólares. Cualquier modelo de aprendizaje supervisado que predice un número como 220.000 o 1,5 o -33,2 está abordando lo que se llama un **problema de regresión**. La regresión lineal es un ejemplo de modelo de regresión.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero también hay otros modelos para abordar problemas de regresión. Veremos algunos de ellos más adelante en el curso 2 de esta especialización. Sólo para recordarle, en contraste con el modelo de regresión, el otro tipo más común de modelo de aprendizaje supervisado se llama **modelo de clasificación**. El modelo de clasificación predice categorías o categorías discretas, como, por ejemplo, predecir si una foto es de un gato, miau o de un perro, guau, o si dada una historia clínica, tiene que predecir si un paciente tiene una enfermedad concreta. Verás más sobre los modelos de clasificación más adelante en este curso también. Como recordatorio de la diferencia entre clasificación y regresión, en la clasificación, sólo hay un pequeño número de posibles resultados. Si su modelo está reconociendo a los gatos frente a los perros, eso son dos posibles salidas. O tal vez se trata de reconocer cualquiera de las 10 posibles condiciones médicas de un paciente, por lo que hay un conjunto discreto y finito de posibles resultados. Lo llamamos problema de clasificación, mientras que en la regresión hay infinitos números posibles que el modelo podría obtener.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_31.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Además de visualizar estos datos como un gráfico aquí a la izquierda, hay otra forma de ver los datos que sería útil, y es una tabla de datos aquí a la derecha. Los datos comprenden un conjunto de entradas. Esto sería el tamaño de la casa, que es esta columna aquí. También tiene salidas. Usted está tratando de predecir el precio, que es esta columna aquí (señalado en amarillo). Observa que los ejes horizontal y vertical corresponden a estas dos columnas, el tamaño y el precio. Si tienes, digamos, 47 filas en esta tabla de datos, entonces hay 47 de estas pequeñas cruces en el gráfico de la izquierda, cada cruz corresponde a una fila de la tabla. Por ejemplo, la primera fila de la tabla es una casa con el tamaño, 2.104 pies cuadrados, por lo que es alrededor de aquí, y esta casa se vende por $ 400.000 que es alrededor de aquí. Esta primera fila de la tabla se traza como este punto de datos aquí. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_32.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, veamos alguna notación para describir los datos. Esta es una notación que encontrarás útil a lo largo de tu viaje en el aprendizaje automático. A medida que te familiarices con la terminología del aprendizaje automático, esta sería la terminología que pueden utilizar para hablar de los conceptos de aprendizaje automático con los demás también, ya que mucho de esto es bastante estándar a través de la IA, verás esta notación varias veces en esta especialización, así que está bien si no recuerdas todo para asignar a través, se convertirá naturalmente más familiar.  \n",
    "\n",
    "El conjunto de datos que acabas de ver y que se utiliza para entrenar el modelo se llama **conjunto de entrenamiento**. Ten en cuenta que la casa de tu cliente no está en este conjunto de datos porque todavía no se ha vendido, así que nadie sabe cuál es el precio. Para predecir el precio de la casa de tu cliente, primero entrenas tu modelo para que aprenda del conjunto de entrenamiento y ese modelo puede entonces predecir el precio de la casa de tu cliente. En el aprendizaje automático, la notación estándar para denotar la entrada aquí es $x$ en minúscula, y la llamamos **variable de entrada**, también se llama **característica** o **rasgo de entrada**. Por ejemplo, para la primera casa de su conjunto de entrenamiento, $x$ es el tamaño de la casa, por lo que $x$ es igual a 2.104.  \n",
    "\n",
    "La notación estándar para denotar la variable de salida que se intenta predecir, también llamada a veces **variable objetivo**, es $y$ en minúscula. El conjunto de datos tiene una fila para cada casa y en este conjunto de entrenamiento hay 47 filas, cada una de las cuales representa un **ejemplo de entrenamiento** diferente.  \n",
    "\n",
    "Vamos a utilizar la $m$ en minúsculas para referirnos al **número total de ejemplos de entrenamiento**, por lo que aquí $m$ es igual a 47. Para indicar el ejemplo de entrenamiento individual, vamos a utilizar la notación paréntesis $(x, y)$. Para el primer ejemplo de entrenamiento, $(x, y)$, este par de números es $(2.104, 400)$.  \n",
    "\n",
    "Ahora tenemos muchos ejemplos de entrenamiento diferentes. De hecho, tenemos 47. Para referirse a un ejemplo de entrenamiento específico, que corresponderá a una fila específica en esta tabla de la izquierda, voy a utilizar la notación $(x^{(i)},y^{(i)})$. El superíndice nos dice que este es el i-ésimo ejemplo de entrenamiento, como el primero, el segundo o el tercero hasta el 47º ejemplo de entrenamiento. $i$ se refiere a una fila específica de la tabla. Por ejemplo, aquí está el primer ejemplo, cuando $i$ es igual a 1 en el conjunto de entrenamiento, y así $x^{(1)}$ es igual a 2.104 e $y^{(1)}$ es igual a 400 y vamos a añadir este superíndice 1 aquí también. Sólo para tener en cuenta, este superíndice i entre paréntesis no es una exponenciación. Cuando escribo esto, esto no es x al cuadrado. Esto no es x a la potencia 2. Sólo se refiere al segundo ejemplo de entrenamiento. Esta $i$, es sólo un índice en el conjunto de entrenamiento y se refiere a la fila $i$ en la tabla.  \n",
    "\n",
    "En este vídeo, has visto cómo es un conjunto de entrenamiento, así como una notación estándar para describir este conjunto de entrenamiento. En el siguiente vídeo, vamos a ver lo que rota para tomar este conjunto de entrenamiento que acabas de ver y alimentar al algoritmo de aprendizaje para que el algoritmo pueda aprender de estos datos. Veamos eso en el siguiente video.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1xXDndcYyLVfMhPDvfJPNEsfWeYk_D5id/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en este vídeo el proceso de funcionamiento del aprendizaje supervisado. El algoritmo de aprendizaje supervisado introduce un conjunto de datos y, a continuación, ¿qué hace exactamente y qué produce? Averigüémoslo en este vídeo.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_34.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Recordemos que un conjunto de entrenamiento en el aprendizaje supervisado incluye tanto las características de entrada (**feature**), como el tamaño de la casa, como los objetivos de salida (**targets**), como el precio de la casa. Los objetivos de salida son las respuestas correctas para el modelo del que vamos a aprender. Para entrenar el modelo, se alimenta el conjunto de entrenamiento, tanto las características de entrada como los objetivos de salida, al algoritmo de aprendizaje. Entonces tu algoritmo de aprendizaje supervisado producirá alguna **función**. Escribiremos esta función como $f$ minúscula, donde $f$ significa función. Históricamente, esta función solía llamarse *hipótesis*, pero en esta clase la llamaré simplemente función $f$. El trabajo con $f$ es tomar una nueva entrada $x$ y la salida $y$, la estimación o una predicción, que voy a llamar y-hat, y se escribe como la variable y con este pequeño símbolo de sombrero en la parte superior. En el aprendizaje automático, la convención es que y-hat es la estimación o la predicción para y. La función f se llama el modelo, x se llama la entrada o la característica de entrada, y la salida del modelo es la predicción, $\\hat{y}$. La predicción del modelo es el valor estimado de $y$. Cuando el símbolo es sólo la letra $y$, se refiere al objetivo, que es el valor real del conjunto de entrenamiento. En cambio, $\\hat{y}$ es una estimación. Puede ser o no el valor real. Si estás ayudando a tu cliente a vender la casa, bueno, el verdadero precio de la casa es desconocido hasta que la vendan. Tu modelo $f$, dado el tamaño, emite el precio que es el estimador, es decir, la predicción de cuál será el verdadero precio.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, cuando diseñamos un algoritmo de aprendizaje, una pregunta clave es: ¿cómo vamos a representar la función $f$? O en otras palabras, ¿cuál es la fórmula matemática que vamos a utilizar para calcular $f$? Por ahora, vamos a quedarnos con que $f$ es una línea recta. Su función se puede escribir como $f_{w,b}(x) = wx + b$. Definiré $w$ y $b$ pronto. Pero por ahora, sólo sé que $w$ y $b$ son números, y los valores elegidos para $w$ y $b$ determinarán la predicción $\\hat{y}$ basada en la característica de entrada x. Este $f_{w,b}(x)$ significa que $f$ es una función que toma $x$ como entrada, y dependiendo de los valores de $w$ y $b$, $f$ dará salida a algún valor de una predicción $\\hat{y}$. Como alternativa a escribir esto, $f_{w,b}(x)$, a veces simplemente escribo $f(x)$ sin incluir explícitamente $w$ y $b$ en el subíndice. Es sólo una notación más simple que significa exactamente lo mismo que $f_{w,b}(x)$.  \n",
    "\n",
    "Vamos a trazar el conjunto de entrenamiento en el gráfico donde la característica de entrada $x$ está en el eje horizontal y el objetivo de salida y está en el eje vertical. Recordemos que el algoritmo aprende de estos datos y genera la línea de mejor ajuste, como quizás esta de aquí. Esta línea recta es la función lineal $f_{w,b}(x) = wx + b$. O más simplemente, podemos dejar de lado $w$ y $b$ y simplemente escribir $f_{w,b}(x) = wx + b$. Esto es lo que hace esta función, está haciendo predicciones para el valor de $y$ usando una función lineal de $x$. Puedes preguntar, ¿por qué estamos eligiendo una función lineal, donde función lineal es sólo un término elegante para una línea recta en lugar de alguna función no lineal como una curva o una parábola? Bueno, a veces también se quieren ajustar funciones no lineales más complejas, como una curva como ésta. Pero como esta función lineal es relativamente simple y fácil de trabajar, vamos a utilizar una línea como base que eventualmente te ayudará a llegar a modelos más complejos que son no lineales. Este modelo en particular tiene un nombre, se llama **regresión lineal**. Más específicamente, se trata de una regresión lineal con una variable, donde la frase una variable significa que hay una sola variable de entrada o característica $x$, a saber, el tamaño de la casa. Otro nombre para un modelo lineal con una variable de entrada es **regresión lineal univariante**, donde *uni* significa uno en latín, y donde variate significa variable. Univariante es sólo una forma elegante de decir una variable. En un vídeo posterior, también verás una variación de la regresión en la que querrás hacer una predicción basada no sólo en el tamaño de una casa, sino en un montón de otras cosas que puedes saber sobre la casa, como el número de habitaciones y otras características. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "Para la regresión lineal, el modelo se representa por $f_{w,b}(x) = wx + b$.  ¿Cuál de las siguientes es la variable de salida o \"objetivo\"?\n",
    "- $y$\n",
    "- $x$\n",
    "- $\\hat{y}$\n",
    "- $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: $y$\n",
    "\n",
    "$y$ es el valor verdadero de ese ejemplo de entrenamiento, denominado variable de salida o \"objetivo\".\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cierto, cuando termines con este vídeo, hay otro laboratorio opcional. No necesitas escribir ningún código. Sólo tienes que revisarlo, ejecutar el código y ver lo que hace. Eso te mostrará cómo definir en Python una función de línea recta. El laboratorio te permitirá elegir los valores de $w$ y $b$ para intentar ajustar los datos de entrenamiento. No tienes que hacer el laboratorio si no quieres, pero espero que juegues con él cuando termines de ver este vídeo.  \n",
    "\n",
    "Eso es la regresión lineal. Para que esto funcione, una de las cosas más importantes que tienes que hacer es construir una función de coste. La idea de una función de coste es una de las ideas más universales e importantes en el aprendizaje automático, y se utiliza tanto en la regresión lineal como en el entrenamiento de muchos de los modelos de IA más avanzados del mundo. Pasemos al siguiente vídeo y veamos cómo se puede construir una función de coste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1RIqD4zZYKWkkdGzIZxWIk8Bwrw0nG0JH/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar la regresión lineal el primer paso clave es definir algo llamado **función de coste**. Esto es algo que construiremos en este vídeo, y la función de coste nos dirá lo bien que lo está haciendo el modelo para que podamos intentar que lo haga mejor. Veamos qué significa esto.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_36.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Recordemos que tenemos un conjunto de entrenamiento que contiene características de entrada $x$ y objetivos de salida $y$. El modelo que vamos a utilizar para ajustar este conjunto de entrenamiento es esta función lineal \n",
    "$f_{w,b}(x) = wx + b$. Para introducir un poco más de terminología, $w$ y $b$ se llaman los **parámetros del modelo**. En el aprendizaje automático, los parámetros del modelo *son las variables que se pueden ajustar durante el entrenamiento para mejorar el modelo*. A veces también se oye hablar de los parámetros $w$ y $b$ como **coeficientes** o como **pesos**. Veamos ahora qué hacen estos parámetros $w$ y $b$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de los valores que hayas elegido para $w$ y $b$ obtendrás una función $f_(x)$ diferente, que genera una línea diferente en la gráfica. Recuerda que podemos escribir $f_(x)$ como una abreviatura de $f_{w,b}(x)$. Vamos a ver algunas gráficas de $f_(x)$ en un gráfico. Tal vez ya estés familiarizado con el trazado de líneas en gráficos, pero incluso si esto es un repaso para ti, espero que esto te ayude a construir una intuición sobre cómo $w$ y $b$ los parámetros determinan $f$:\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_37.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "- Cuando $w$ es igual a 0 y $b$ es igual a 1,5, entonces $f$ se parece a esta línea horizontal. En este caso, la función $f_(x)$ es 0 veces $x$ más 1,5 por lo que $f$ es siempre un valor constante. Siempre predice 1.5 para el valor estimado de $y$. El $\\hat{y}$ es siempre igual a $b$ y aquí $b$ también se llama la **intercepción de $y$** porque es donde cruza el eje vertical o el eje de $y$ en este gráfico. \n",
    "\n",
    "- Como segundo ejemplo, si $w$ es 0.5 y $b$ es igual a 0, entonces $f_(x)$ es 0.5 veces $x$. Cuando $x$ es 0, la predicción también es 0, y cuando $x$ es 2, entonces la predicción es 0.5 veces 2, que es 1. Obtienes una línea que se parece a esta y nota que la pendiente es 0.5 dividida por 1. El valor de $w$ te da la pendiente de la línea, que es 0.5. \n",
    "\n",
    "- Finalmente, si $w$ es igual a 0,5 y $b$ es igual a 1, entonces $f_(x)$ es 0,5 veces $x$ más 1 y cuando $x$ es 0, entonces $f_(x)$ es igual a $b$, que es 1 por lo que la recta corta el eje vertical en $b$, la intercepción $y$. También cuando $x$ es 2, entonces $f_(x)$ es 2, por lo que la línea se ve así. De nuevo, esta pendiente es 0,5 dividido por 1, por lo que el valor de $w$ nos da la pendiente, que es 0,5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_38.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Recuerda que tienes un conjunto de entrenamiento como el que se muestra aquí. Con la regresión lineal, lo que quieres hacer es elegir los valores de los parámetros $w$ y $b$ para que la línea recta que obtienes de la función $f$ se ajuste bien a los datos. Como, por ejemplo, esta línea que se muestra aquí. Cuando veo que la línea se ajusta a los datos visualmente, puedes pensar que esto significa que la línea definida por $f$ pasa aproximadamente a través de los ejemplos de entrenamiento o en algún lugar cercano a ellos, en comparación con otras posibles líneas que no están tan cerca de estos puntos.\n",
    "\n",
    "Sólo para recordarte algo de notación, un ejemplo de entrenamiento como este punto aquí se define por $(x^{(i)},y^{(i)})$, donde $y$ es el objetivo. Para una entrada dada $x^{(i)}$, la función $f$ también hace un valor predictivo para $y$ y un valor que predice a $y$ es $\\hat{y}$ mostrado aquí. Para nuestra elección de un modelo $f(x^{(i)})$ es $w$ veces $x^{(i)}$ más $b$. Dicho de otra manera, la predicción $\\hat{y}$ es $f_{w,b}(x^{(i)})$ donde para el modelo que estamos usando $f(x^{(i)})=wx^{(i)}+b$. Ahora la pregunta es cómo encontrar valores para $w$ y $b$ de manera que la predicción $\\hat{y}$ se acerque al verdadero objetivo $\\hat{y}$ para muchos o quizás todos los ejemplos de entrenamiento $(x^{(i)},y^{(i)})$. \n",
    "\n",
    "Para responder a esta pregunta, veamos primero cómo medir lo bien que se ajusta una recta a los datos de entrenamiento. Para ello, vamos a construir una función de coste. La función de coste toma la predicción $\\hat{y}$ y la compara con el objetivo y tomando $\\hat{y}-y$. Esta diferencia se llama **error**, estamos midiendo lo lejos que está la predicción del objetivo. A continuación, vamos a calcular el cuadrado de este error. Además, vamos a querer calcular este término para diferentes ejemplos de entrenamiento $i$ en el conjunto de entrenamiento. Al medir el error, para el ejemplo $i$, calcularemos este término de error al cuadrado. Por último, queremos medir el error en todo el conjunto de entrenamiento.  \n",
    "\n",
    "En particular, vamos a sumar los errores al cuadrado así (muestra la ecuación $J(w,b)$). Sumaremos desde $i$ igual a 1,2,3 hasta $m$ y recordemos que $m$ es el número de ejemplos de entrenamiento, que es 47 para este conjunto de datos. Observe que si tenemos más ejemplos de entrenamiento $m$ es mayor y su función de coste calculará un número mayor. Esto es la suma de más ejemplos. Para construir una función de coste que no se haga automáticamente más grande a medida que el tamaño del conjunto de entrenamiento se hace más grande por convención, vamos a calcular el error cuadrado promedio en lugar del error cuadrado total y lo hacemos dividiendo por $m$ así. Ya casi estamos. Sólo una última cosa.\n",
    "\n",
    "Por convención, la función de coste que la gente demachine learning utiliza en realidad divide por 2 veces $m$. La división extra por 2 es sólo para hacer que algunos de nuestros cálculos posteriores parezcan más ordenados, pero la función de coste todavía funciona si se incluye esta división por 2 o no. Esta expresión aquí es la función de costo y vamos a escribir $J(w,b)$ para referirse a la función de costo. Esto también se llama la **función de costo de error al cuadrado**, y se llama así porque estás tomando el cuadrado de estos términos de error. En el aprendizaje automático, diferentes personas utilizarán diferentes funciones de coste para diferentes aplicaciones, pero la función de coste de error cuadrado es, con mucho, la más utilizada para la regresión lineal y, para el caso, para todos los problemas de regresión, donde parece dar buenos resultados para muchas aplicaciones.  \n",
    "\n",
    "Sólo como un recordatorio, la predicción $\\hat{y}-y$ es igual a las salidas del modelo $f(x)$. Podemos reescribir la función de coste $J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$. Al final vamos a querer encontrar valores de $w$ y $b$ que hagan que la función de coste sea pequeña. Pero antes de ir allí, primero vamos a ganar más intuición acerca de lo que J(w,b) es realmente calcular. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "La función de coste utilizada para la regresión lineal es $J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$\n",
    " \n",
    "¿Cuáles son los parámetros del modelo que se pueden ajustar?\n",
    "- $w$ y $b$\n",
    "- $f_{w,b}(x^{(i)})$\n",
    "- $w$ solamente, porque debemos elegir $b=0$\n",
    "- $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: $w$ y $b$\n",
    "\n",
    "w y b son parámetros del modelo, que se ajustan a medida que el modelo aprende de los datos. También se denominan \"coeficientes\" o \"pesos\".\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto puedes pensar que hemos hecho un montón de matemáticas para definir la función de coste. Pero, ¿qué hace exactamente? Pasemos al siguiente vídeo, en el que veremos un ejemplo de lo que la función de coste está calculando realmente, que espero que te ayude a intuir lo que significa que $J(w,b)$ sea grande frente a que el coste $j$ sea pequeño. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1aP7zy1blMHQOgweR2VStIb3-CqToDIJ4/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos viendo la definición matemática de la función de coste. Ahora, vamos a construir algo de intuición sobre lo que la función de coste está haciendo realmente. En este video, vamos a recorrer un ejemplo para ver cómo la función de coste se puede utilizar para encontrar los mejores parámetros para su modelo. Sé que este vídeo es un poco más largo que los demás, pero tened paciencia, creo que merecerá la pena.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_40.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Para recapitular, esto es lo que hemos visto sobre la función de coste hasta ahora. Quieres ajustar una línea recta a los datos de entrenamiento, así que tienes este modelo, $f_{w,b}(x) = wx + b$. Aquí, los parámetros del modelo son $w$ y $b$. Ahora, dependiendo de los valores elegidos para estos parámetros, obtienes diferentes líneas rectas como esta. Se desea encontrar valores para $w$, y $b$, de manera que la línea recta se ajuste bien a los datos de entrenamiento. Para medir qué tan bien una elección de $w$, y $b$ se ajusta a los datos de entrenamiento, se tiene una función de costo $J$. Lo que hace la función de costo $J$ es que mide la diferencia entre las predicciones del modelo, y los valores reales de $y$. Lo que se ve después, es que la regresión lineal trataría de encontrar valores para $w$, y $b$, luego hacer que $J(w)$ sea lo más pequeño posible. En matemáticas, lo escribimos así. Queremos minimizar, $J$ como una función de $w$ y $b$.  \n",
    "\n",
    "Ahora, para que podamos visualizar mejor la función de costo $J$, este trabajo de una versión simplificada del modelo de regresión lineal. Vamos a utilizar el modelo $f_{w}(x)=wx$. Usted puede pensar en esto como tomar el modelo original de la izquierda, y deshacerse del parámetro $b$, o el establecimiento del parámetro $b$ igual a 0. Sólo se va de la ecuación, por lo que $f$ es ahora sólo $w$ por $x$. Ahora tiene sólo un parámetro $w$, y su función de costo $J$, se ve similar a lo que era antes. Tomando la diferencia, y elevándola al cuadrado, excepto que ahora, $f$ es igual a $wx^{(i)}$, y $J$ es ahora una función de sólo $w$. El objetivo se vuelve un poco diferente también, porque usted tiene sólo un parámetro, $w$, no $w$ y $b$. Con este modelo simplificado, el objetivo es encontrar el valor de $w$, que minimiza $J(w)$. \n",
    "\n",
    "Para ver esto visualmente, lo que esto significa es que, si $b$ se establece en 0, entonces $f$ define una línea que se parece a esto. Se ve que la línea pasa por el origen aquí, porque cuando $x$ es 0, $f_(x)$ es 0 también. Ahora, utilizando este modelo simplificado, vamos a ver cómo cambia la función de coste a medida que se eligen diferentes valores para el parámetro $w$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_41.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En particular, vamos a ver los gráficos del modelo $f(x)$, y la función de coste $J$. Voy a trazar estos lado a lado, y usted será capaz de ver cómo los dos están relacionados.  \n",
    "\n",
    "En primer lugar, observe que para $f_{w}$, cuando el parámetro $w$ es fijo, es decir, es siempre un valor constante, entonces $f_{w}$ es sólo una función de $x$, lo que significa que el valor estimado de $y$ depende del valor de la entrada $x$.\n",
    "\n",
    "Por el contrario, mirando a la derecha, la función de coste $J$, es una función de $w$, donde $w$ controla la pendiente de la línea definida por $f_{w}$. El coste definido por $J$, depende de un parámetro, en este caso, el parámetro $w$. Vamos a seguir adelante, y trazar estas funciones, $f_{w,b}(x)$, y $J(w)$ de lado a lado para que pueda ver cómo se relacionan. \n",
    "\n",
    "Empezaremos con el modelo, es decir, la función $f_{w}(x)$ a la izquierda. Aquí están la función de entrada $x$ está en el eje horizontal, y el valor de salida y está en el eje vertical. Aquí están los gráficos de tres puntos que representan el conjunto de entrenamiento en las posiciones (1, 1), (2, 2), y (3,3). Vamos a elegir un valor para $w$. Digamos que $w$ es 1. Para esta elección de $w$, la función $f_{w}$, dirán esta línea recta con una pendiente de 1.  \n",
    "\n",
    "Ahora, lo que puede hacer a continuación es calcular el costo $J$ cuando $w$ es igual a 1. Usted puede recordar que la función de costo se define como sigue, es la función de costo de error al cuadrado. Si sustituyes $f_{w}(x^{(i)})$ por $w$ veces $x^{(i)}$, la función de coste queda así (como muestra la figura). Donde esta expresión es ahora $wx^{(i)}-y^{(i)}$. Para este valor de $w$, resulta que el término de error dentro de la función de coste, este $wx^{(i)}-y^{(i)}$ es igual a 0 para cada uno de los tres puntos de datos. Porque para este conjunto de datos, cuando $x$ es 1, entonces $y$ es 1. Cuando $w$ es también 1, entonces $f(x)$ es igual a 1, por lo que $f(x)=y$ para este primer ejemplo de entrenamiento, y la diferencia es 0. Si se introduce esto en la función de coste $J$, se obtiene 0 al cuadrado. Del mismo modo, cuando $x$ es 2, entonces $y$ es 2, y $f(x)$ también es 2. De nuevo, $f(x)$ es igual a $y$, para el segundo ejemplo de entrenamiento. En la función de coste, el error al cuadrado para el segundo ejemplo es también 0 al cuadrado. Por último, cuando $x$ es 3, entonces y es 3 y $f(3)$ también es 3. En la función de coste, el tercer término de error al cuadrado también es 0 al cuadrado. Para los tres ejemplos de este conjunto de entrenamiento, $f(x^{(i)})$ es igual a $y^{(i)}$ para cada ejemplo de entrenamiento $i$, por lo que $f(x^{(i)})-y^{(i)}$ es 0. Para este conjunto de datos en particular, cuando $w$ es 1, entonces el coste $J$ es igual a 0.  \n",
    "\n",
    "Ahora, lo que puedes hacer a la derecha es trazar la función de coste $J$. Observe que debido a que la función de costo es una función del parámetro $w$, el eje horizontal es ahora etiquetado $w$ y no $x$, y el eje vertical es ahora $J$ y no $y$. Usted tiene $J(1)$ es igual a 0. En otras palabras, cuando $w$ es igual a 1, $J(w)$ es 0, así que permítanme seguir adelante y trazar eso.  \n",
    "\n",
    "Ahora, vamos a ver cómo $f$ y $J$ cambian para diferentes valores de $w$, donde $w$ puede tomar un rango de valores, por lo que $w$ puede tomar valores negativos, $w$ puede ser 0, y puede tomar valores positivos también. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_42.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "¿Qué pasa si w es igual a 0.5 en lugar de 1, cómo se verían estas gráficas entonces? Vamos a seguir adelante y trazar eso. Pongamos que $w$ es igual a 0,5, y en este caso, la función $f(x)$ ahora se ve así, es una línea con una pendiente igual a 0,5. Calculemos también el coste $J$, cuando $w$ es 0,5. Recordemos que la función de coste está midiendo el error al cuadrado o la diferencia entre el valor del estimador, es decir $\\hat{y}$, que es $f(x^{(i)})$, y el valor real, es decir $y^{(i)}$ para cada ejemplo $i$. Visualmente se puede ver que el error o la diferencia es igual a la altura de esta línea vertical aquí cuando $x$ es igual a 1. Porque esta línea inferior es la brecha entre el valor real de $y$ y el valor que la función $f$ predijo, que es un poco más abajo aquí. Para este primer ejemplo, cuando $x$ es 1, $f(x)$ es 0.5. El error al cuadrado en el primer ejemplo es 0,5 menos 1 al cuadrado. Recuerda la función de coste, sumaremos sobre todos los ejemplos de entrenamiento en el conjunto de entrenamiento. Pasemos al segundo ejemplo de entrenamiento. Cuando $x$ es 2, el modelo está prediciendo que $f(x)$ es 1 y el valor real de $y$ es 2. El error para el segundo ejemplo es igual a la altura de este pequeño segmento de línea aquí, y el error al cuadrado es el cuadrado de la longitud de este segmento de línea, por lo que se obtiene 1 menos 2 al cuadrado. Hagamos el tercer ejemplo. Repitiendo este proceso, el error aquí, también mostrado por este segmento de línea, es 1,5 menos 3 al cuadrado. A continuación, sumamos todos estos términos, que resulta ser igual a 3,5. Luego multiplicamos este término por 1 sobre 2$m$, donde $m$ es el número de ejemplos de entrenamiento. Como hay tres ejemplos de entrenamiento, $m$ es igual a 3, así que esto es igual a 1 sobre 2 por 3, donde este $m$ aquí es 3. Si hacemos las cuentas, esto resulta ser 3,5 dividido por 6. El coste $J$ es aproximadamente 0,58.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_43.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a seguir adelante y trazar que allí a la derecha. Ahora, probemos un valor más para $w$. ¿Qué tal si w es igual a 0? ¿Cómo se ven los gráficos de $f$ y $J$ cuando $w$ es igual a 0? Resulta que, si $w$ es igual a 0, entonces $f(x)$ es sólo esta línea horizontal que está exactamente en el eje $x$. El error para cada ejemplo es una línea que va desde cada punto hasta la línea horizontal que representa que $f(x)$ es igual a 0. El coste $J$ cuando $w$ es igual a 0 es 1 sobre 2m veces la cantidad, 12 más 22 más 32, y eso es igual a 1 sobre 6 veces 14, que es aproximadamente 2,33. Vamos a graficar este punto donde $w$ es 0 y $J$ de 0 es 2,33 por aquí. Puedes seguir haciendo esto para otros valores de $w$. Como $w$ puede ser cualquier número, también puede ser un valor negativo. Si $w$ es negativo 0,5, entonces la recta $f$ es una recta de pendiente descendente como ésta. Resulta que cuando $w$ es negativo 0,5 entonces usted termina con un costo aún mayor, alrededor de 5,25, que es este punto aquí arriba. Se puede seguir calculando la función de coste para diferentes valores de $w$ y así sucesivamente y trazarlos. Resulta que, calculando un rango de valores, puedes trazar lentamente cómo es la función de coste $J$ y eso es lo que es $J$.  \n",
    "\n",
    "Para recapitular, cada valor del parámetro w corresponde a un ajuste de línea recta diferente, $f(x)$, en el gráfico de la izquierda. Para el conjunto de entrenamiento dado, esa elección para un valor de $w$ corresponde a un único punto en el gráfico de la derecha porque para cada valor de $w$, puedes calcular el coste $J(w)$. Por ejemplo, cuando $w$ es igual a 1, esto corresponde a este ajuste de línea recta a través de los datos y también corresponde a este punto en el gráfico de $J$, donde $w$ es igual a 1 y el coste $J$ de 1 es igual a 0. Mientras que cuando $w$ es igual a 0,5, esto te da esta línea que tiene una pendiente más pequeña. Esta línea en combinación con el conjunto de entrenamiento corresponde a este punto en el gráfico de la función de coste en $w$ igual a 0,5. Para cada valor de w se obtiene una línea diferente y sus costes correspondientes, $J(w)$, y se pueden utilizar estos puntos para trazar este gráfico de la derecha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_44.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Teniendo en cuenta esto, ¿cómo se puede elegir el valor de w que hace que la función $f$ se ajuste bien a los datos? Bueno, como puedes imaginar, elegir un valor de $w$ que haga que $J(w)$ sea lo más pequeño posible parece una buena apuesta. $J$ es la función de coste que mide lo grande que son los errores al cuadrado, así que elegir w que minimice estos errores al cuadrado, los haga lo más pequeños posible, nos dará un buen modelo. En este ejemplo, si eligiéramos el valor de $w$ que da como resultado el menor valor posible de $J(w)$ acabaríamos eligiendo $w$ igual a 1. Como puedes ver, esa es una elección bastante buena. El resultado es la línea que se ajusta muy bien a los datos de entrenamiento. Así es como en la regresión lineal usas la función de coste para encontrar el valor de $w$ que minimiza $J$. En el caso más general en el que tenemos los parámetros $w$ y $b$ en lugar de sólo $w$, encuentras los valores de $w$ y $b$ que minimizan $J$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "¿Cuándo se ajusta el modelo a los datos relativamente bien, en comparación con otras opciones del parámetro $w$?\n",
    "\n",
    "- Cuando $f_{w}(x)$ está en o cerca de un mínimo para todos los valores de $x$ en el conjunto de entrenamiento. \n",
    "- Cuando $x$ está en o cerca de un mínimo.\n",
    "- Cuando $w$ es cercano a cero.\n",
    "- Cuando el coste $J$ está en o cerca de un mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Cuando el coste $J$ está en o cerca de un mínimo.\n",
    "\n",
    "Cuando el coste es relativamente pequeño, más cercano a cero, significa que el modelo se ajusta mejor a los datos en comparación con otras opciones para $w$ y $b$.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resumir, has visto las gráficas de $f$ y $J$ y has trabajado en cómo se relacionan ambas. A medida que varías $w$ o varías $w$ y $b$ terminas con diferentes líneas rectas y cuando esa línea recta pasa por los datos, la causa $J$ es pequeña. El objetivo de la regresión lineal es encontrar los parámetros $w$ o $w$ y $b$ que den como resultado el menor valor posible para la función de coste $J$. Ahora, en este vídeo, hemos trabajado a través de nuestro ejemplo con un problema simplificado utilizando sólo $w$. En el siguiente vídeo, vamos a visualizar cómo se ve la función de coste para la versión completa de la regresión lineal utilizando tanto w como b. Verás algunos gráficos 3D interesantes. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1O_IT_GRIpB5JSboKW194TOPb9Ab46uUc/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el último vídeo, has visto una visualización de la función de coste $J(w)$ o $J(w,b)$. Vamos a ver otras visualizaciones más ricas para que puedas intuir aún mejor lo que hace la función de coste.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_46.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Esto es lo que hemos visto hasta ahora. Está el modelo, los parámetros del modelo $w$ y $b$, la función de coste $J(w,b)$, así como el objetivo de la regresión lineal, que es minimizar la función de coste $J(w,b)$ sobre los parámetros $w$ y $b$. En el último vídeo, habíamos puesto temporalmente $b$ a cero para simplificar las visualizaciones. Ahora, volvamos al modelo original con los parámetros $w$ y $b$ sin poner $b$ a cero.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_47.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Igual que la última vez, queremos obtener una comprensión visual de la función del modelo, $f(x)$, que se muestra aquí a la izquierda, y cómo se relaciona con la función de coste $J(w,b)$, que se muestra aquí a la derecha. Aquí tenemos un conjunto de entrenamiento de tamaños y precios de casas. Digamos que eliges una función posible de $x$, como ésta. Aquí, he fijado $w$ en 0,06 y $b$ en 50. $f(x)$ es 0,06 veces $x$ más 50. Observe que este no es un modelo particularmente bueno para este conjunto de entrenamiento, es en realidad un modelo bastante malo. Parece que subestima sistemáticamente los precios de la vivienda. \n",
    "Dados estos valores para $w$ y $b$, veamos cómo puede ser la función de coste $J(w,b)$. Recordemos que lo que vimos la última vez fue cuando sólo teníamos $w$, porque temporalmente pusimos $b$ a cero para simplificar las cosas, pero entonces habíamos llegado a un gráfico de la función de coste que se veía así como una función de w solamente. Cuando teníamos sólo un parámetro, $w$, la función de coste tenía esta curva en forma de U, con forma de plato de sopa. Eso suena delicioso. Ahora, en este ejemplo del precio de la vivienda que tenemos en esta diapositiva, tenemos dos parámetros, $w$ y $b$. Los gráficos se vuelven un poco más complejos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_48.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Resulta que la función de coste también tiene una forma similar a la de un plato de sopa, excepto en tres dimensiones en lugar de dos. De hecho, dependiendo de tu conjunto de entrenamiento, la función de coste se parecerá a esto. A mí me parece un plato de sopa, quizá porque tengo un poco de hambre, o quizá a ti te parezca un plato de comida curvado o una hamaca. En realidad, eso también suena relajante, y ahí tienes tu bebida de coco. Tal vez cuando termines este curso, deberías regalarte unas vacaciones y relajarte en una hamaca como ésta. Lo que ves aquí es un gráfico de superficie 3D donde los ejes están etiquetados w y b. A medida que varías w y b, que son los dos parámetros del modelo, obtienes diferentes valores para la función de coste $J(w,b)$. Esto es muy parecido a la curva en forma de U que viste en el último vídeo, excepto que en lugar de tener un parámetro w como entrada para la j, ahora tienes dos parámetros, w y b como entradas en este plato de sopa o esta función en forma de hamaca $J$. Sólo quiero señalar que cualquier punto individual en esta superficie representa alguna elección particular de $w$ y $b$. Por ejemplo, si $w$ era -10 y $b$ era -15, entonces la altura de la superficie sobre este punto es el valor de $J$ cuando $w$ es -10 y $b$ es -15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_51.jpg\"   style=\"width:250px;height:140px;\" >\n",
    "</figure>\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_50.jpg\"   style=\"width:250px;height:140px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, con el fin de mirar aún más de cerca en puntos específicos, hay otra manera de trazar la función de coste $J$ que sería útil para la visualización, que es, en lugar de utilizar estos gráficos de superficie 3D, me gusta tomar esta misma función $J$. No estoy cambiando la función $J$ en absoluto y trazarla utilizando algo llamado un gráfico de contorno. Si alguna vez has visto un mapa topográfico que muestre la altura de diferentes montañas, las curvas de nivel en un mapa topográfico son básicamente cortes horizontales del paisaje de, por ejemplo, una montaña. Esta imagen es del Monte Fuji en Japón. Todavía recuerdo a mi familia visitando el monte Fuji cuando era adolescente. Es una vista preciosa. Si vuelas directamente por encima de la montaña, eso es lo que parece este mapa de contornos. Muestra todos los puntos, están a la misma altura para diferentes alturas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_52.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En la parte inferior de esta diapositiva hay un gráfico de la superficie 3D de la función de coste $J$. Sé que no parece tener forma de cuenco, pero en realidad es un cuenco muy estirado, por eso tiene ese aspecto. En un laboratorio opcional, que se realizará en breve, podrás ver esto en 3D y girar alrededor de la superficie tú mismo y se verá más obviamente en forma de cuenco allí. A continuación, aquí en la parte superior derecha es un gráfico de contorno de esta misma función de coste que se muestra en la parte inferior. Los dos ejes en este gráfico de contorno son $b$, en el eje vertical, y $w$ en el eje horizontal. Lo que muestra cada uno de estos óvalos, también llamados **elipses**, son los puntos centrales de la superficie 3D que están exactamente a la misma altura. En otras palabras, el conjunto de puntos que tienen el mismo valor para la función de coste $J$.  \n",
    "\n",
    "Para obtener los gráficos de contorno, se toma la superficie 3D en la parte inferior y se utiliza un cuchillo para cortarla horizontalmente.  Si tomas cortes horizontales de esa superficie 3D y obtienes todos los puntos, están a la misma altura. Por lo tanto, cada rebanada horizontal termina siendo mostrada como una de estas elipses o uno de estos óvalos. Concretamente, si tomas ese punto, y ese punto, y ese punto, todos estos tres puntos tienen el mismo valor para la función de coste $J$, aunque tengan diferentes valores para $w$ y $b$. En la figura de la parte superior izquierda, ves también que estos tres puntos corresponden a diferentes funciones, $f$, las tres son realmente bastante malas para predecir los precios de la vivienda en este caso.  \n",
    "\n",
    "Ahora, el fondo del cuenco, donde la función de coste $J$ está en un mínimo, es este punto de aquí, en el centro de estos óvalos concéntricos. Si no has visto mucho los gráficos de contorno, me gustaría que te imaginaras, si quieres, que estás volando muy por encima del cuenco en un avión o en un cohete, y estás mirando directamente hacia abajo. Es como si pusieras el monitor de tu ordenador plano en tu escritorio mirando hacia arriba y la forma del cuenco saliera directamente de tu pantalla, elevándose por encima de tu escritorio. Imagina que la forma de cuenco sale de la pantalla de tu ordenador tumbada así, de modo que cada uno de estos óvalos tiene la misma altura sobre tu pantalla y el mínimo del cuenco está justo ahí abajo, en el centro del óvalo más pequeño.  \n",
    "\n",
    "Resulta que los gráficos de contorno son una forma conveniente de visualizar la función de coste $J$ en 3D, pero en cierto modo, se traza sólo en 2D. En este vídeo, has visto cómo el trazado de la superficie en forma de cuenco 3D también puede visualizarse como un trazado de contorno. Usando esta visualización también, en el siguiente video, vamos a visualizar algunas opciones específicas de w y b en el modelo de regresión lineal para que puedas ver cómo estas diferentes opciones afectan la línea recta que estás ajustando a los datos. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1HLIZ_-2DcR5f61Ts0tYevJ7dYUw_pjvY/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas visualizaciones más de w y b. Aquí hay un ejemplo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_54.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí, tienes un punto particular en el gráfico $J$. Para este punto, $w$ es igual a 0,15 negativo y $b$ es igual a 800. Este punto corresponde a un par de valores para $w$ y $b$ que utilizan un costo particular $J$. De hecho, este par de valores para $w$ y $b$ corresponde a esta función $f(x)$, que es esta línea que puedes ver a la izquierda. Esta línea cruza el eje vertical en 800 porque b es igual a 800 y la pendiente de la línea es negativa 0,15, porque $w$ es igual a 0,15 negativo. Ahora, si miras los puntos de datos en el conjunto de entrenamiento, puedes notar que esta línea no se ajusta bien a los datos. Para esta función $f(x)$, con estos valores de $w$ y $b$, muchas de las predicciones para el valor de y están bastante lejos del valor objetivo real de y que está en los datos de entrenamiento. Debido a que esta línea no es un buen ajuste, si usted mira el gráfico de $J$, el costo de esta línea está aquí, que es bastante lejos del mínimo. Hay un costo bastante alto porque esta elección de $w$ y $b$ no es un buen ajuste para el conjunto de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_55.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, vamos a ver otro ejemplo con una elección diferente de $w$ y $b$. Ahora, aquí hay otra función que todavía no es un gran ajuste para los datos, pero tal vez un poco menos malo. Este punto aquí representa el costo de este par de libretas de $w$ y $b$ que crea esa línea. El valor de $w$ es igual a 0 y el valor $b$ es aproximadamente 360. Este par de parámetros corresponde a esta función, que es una línea plana, porque $f(x)$ es igual a 0 por x más 360. Espero que tenga sentido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_56.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos otro ejemplo. Aquí hay una opción más para $w$ y $b$, y con estos valores, usted termina con esta línea $f(x)$. De nuevo, no es un gran ajuste a los datos, es en realidad más lejos del mínimo en comparación con el ejemplo anterior. Recuerda que el mínimo está en el centro de esa elipse más pequeña. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_57.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "El último ejemplo, si miras $f(x)$ a la izquierda, parece un ajuste bastante bueno para el conjunto de entrenamiento. Puedes ver a la derecha, este punto que representa el coste está muy cerca del centro de la elipse más pequeña, no es exactamente el mínimo, pero está bastante cerca. Para este valor de $w$ y $b$, se llega a esta línea, $f(x)$. Puedes ver que, si mides las distancias verticales entre los puntos de datos y los valores predichos en la línea recta, obtendrías el error para cada punto de datos. La suma de los errores al cuadrado para todos estos puntos de datos está bastante cerca de la mínima suma posible de errores al cuadrado entre todos los posibles ajustes de la línea recta. Espero que, al mirar estas figuras, puedas tener una mejor idea de cómo las diferentes opciones de los parámetros afectan a la línea $f(x)$ y cómo esto corresponde a diferentes valores para el coste $J$, y espero que puedas ver cómo las líneas de mejor ajuste corresponden a puntos en la gráfica de $J$ que están más cerca del coste mínimo posible para esta función de coste $J(w,b)$. \n",
    "\n",
    "En el laboratorio opcional que sigue a este vídeo, podrás ejecutar algunos códigos y recuerda que todo el código está dado, así que sólo tienes que pulsar Shift Enter para ejecutarlo y echarle un vistazo y el laboratorio te mostrará cómo se implementa la función de coste en el código. Dado un pequeño conjunto de entrenamiento y diferentes opciones para los parámetros, podrás ver cómo varía el coste dependiendo de lo bien que el modelo se ajuste a los datos. En el laboratorio opcional, también puedes jugar con el gráfico de la consola interactiva. Comprueba esto. Puedes utilizar el cursor del ratón para hacer clic en cualquier parte del gráfico de contorno y verás la línea recta definida por los valores que elegiste para los parámetros w y b. Verás un punto aquí arriba también en el gráfico de superficie 3D que muestra el coste. Por último, el laboratorio opcional también tiene un gráfico de superficie en 3D que puedes girar y rotar manualmente con el cursor del ratón para ver mejor el aspecto de la función de coste.  \n",
    "\n",
    "Espero que disfrutes jugando con el laboratorio opcional. Ahora, en la regresión lineal, en lugar de tener que tratar de leer manualmente un gráfico de contorno para el mejor valor de w y b, que no es realmente un buen procedimiento y también no funcionará una vez que lleguemos a modelos de aprendizaje automático más complejos. Lo que realmente quieres es un algoritmo eficiente que puedas escribir en código para encontrar automáticamente los valores de los parámetros w y b que te den la línea de mejor ajuste. Que minimice la función de coste j. Hay un algoritmo para hacer esto llamado descenso de gradiente. Este algoritmo es uno de los más importantes en el aprendizaje automático. El descenso de gradiente y las variaciones del descenso de gradiente se utilizan para entrenar, no sólo la regresión lineal, sino algunos de los modelos más grandes y más complejos en toda la IA. Vayamos al siguiente video para sumergirnos en este algoritmo realmente importante llamado descenso de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 1**\n",
    "Para la regresión lineal, el modelo es $f_{w,b}(x) = wx + b$\n",
    "¿Cuáles de las siguientes son las entradas, o características, que se introducen en el modelo y con las que se espera que éste haga una predicción?\n",
    "- $w$ y $b$\n",
    "- $(x,y)$\n",
    "- $x$\n",
    "- $m$\n",
    "\n",
    "**Pregunta 2**\n",
    "En el caso de la regresión lineal, si encuentras los parámetros $w$ y $b$ de forma que $J(w,b)$ sea muy cercano a cero, ¿qué puedes concluir?\n",
    "- Los valores seleccionados de los parámetros $w$ y $b$ hacen que el algoritmo se ajuste muy mal al conjunto de entrenamiento.\n",
    "- Los valores seleccionados de los parámetros $w$ y $b$ hacen que el algoritmo se ajuste al conjunto de entrenamiento realmente bien.\n",
    "- Esto no es posible: debe haber un error en el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuestas: \n",
    "\n",
    "*Pregunta 1*\n",
    "    \n",
    "$x$\n",
    "    \n",
    "*Pregunta 2*\n",
    "    \n",
    "Los valores seleccionados de los parámetros $w$ y $b$ hacen que el algoritmo se ajuste al conjunto de entrenamiento realmente bien\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL WITH GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1golfHG3WUOUooqnEr5hVhiSi6NFL30R1/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido de nuevo. En el último vídeo, vimos visualizaciones de la función de coste $J$ y cómo puedes probar diferentes opciones de los parámetros $w$ y $b$ y ver qué valor de coste te dan. Sería bueno si tuviéramos una manera más sistemática de encontrar los valores de $w$ y $b$, que resulta en el menor costo posible, $J(w,b)$. Resulta que hay un algoritmo llamado descenso de gradiente que se puede utilizar para hacer eso. El descenso de gradiente se utiliza en todas partes en el aprendizaje de máquinas, no sólo para la regresión lineal, sino para la formación, por ejemplo, algunos de los más avanzados modelos de redes neuronales, también llamados modelos de aprendizaje profundo. Los modelos de aprendizaje profundo son algo que aprendiste en el segundo curso. El aprendizaje de estos dos de descenso de gradiente le pondrá en marcha uno de los bloques de construcción más importantes en el aprendizaje de máquinas.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_59.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está una visión general de lo que vamos a hacer con el descenso de gradiente. Tienes la función de coste $J(w,b)$ justo aquí que quieres minimizar. En el ejemplo que hemos visto hasta ahora, se trata de una función de coste para la regresión lineal, pero resulta que el descenso de gradiente es un algoritmo que se puede utilizar para tratar de minimizar cualquier función, no sólo una función de coste para la regresión lineal. Sólo para hacer esta discusión sobre el descenso de gradiente más general, resulta que el descenso de gradiente se aplica a funciones más generales, incluyendo otras funciones de coste que trabajan con modelos que tienen más de dos parámetros. Por ejemplo, si usted tiene una función de coste $J$ como una función de $w_1$, $w_2$ hasta $w_n$ y $b$, su objetivo es minimizar J sobre los parámetros $w_1$ a $w_n$ y $b$. En otras palabras, usted quiere elegir los valores de $w_1$ a $w_n$ y $b$, que le da el menor valor posible de $J$. Resulta que el descenso de gradiente es un algoritmo que se puede aplicar para tratar de minimizar esta función de coste $J$ también.  \n",
    "\n",
    "Lo que vas a hacer es comenzar con algunas conjeturas iniciales para $w$ y $b$. En la regresión lineal, no importará demasiado cuál es el valor inicial, por lo que una opción común es establecer ambos en 0. Por ejemplo, puedes establecer $w$ en 0 y $b$ en 0 como conjetura inicial. Con el algoritmo de descenso de gradiente, lo que vas a hacer es, seguir cambiando los parámetros $w$ y $b$ un poco cada vez para tratar de reducir el costo $J(w,b)$ hasta que con suerte $J$ se establece en o cerca de un mínimo. Una cosa que debo señalar es que para algunas funciones $J$ que pueden no ser una forma de arco o una forma de hamaca, es posible que haya más de un mínimo posible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_60.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos un ejemplo de un gráfico de superficie $J$ más complejo para ver lo que hace el gradiente. Esta función no es una función de coste de error cuadrado. Para la regresión lineal con la función de coste de error cuadrado, siempre se termina con una forma de arco o una forma de hamaca. Pero este es un tipo de función de coste que podrías obtener si estás entrenando un modelo de red neuronal. Fíjate en los ejes, es decir, $w$ y $b$ en el eje inferior. Para diferentes valores de $w$ y $b$, obtienes diferentes puntos en esta superficie, $J(w,b)$, donde la altura de la superficie en algún punto es el valor de la función de coste. Ahora, imaginemos que este gráfico de la superficie es en realidad una vista de un parque al aire libre ligeramente ondulado o un campo de golf donde los puntos altos son colinas y los puntos bajos son valles, así. Me gustaría que imaginaras, si quieres, que estás físicamente de pie en este punto de la colina. Si te ayuda a relajarte, imagina que hay un montón de hierba verde muy bonita y mariposas y flores es una colina muy bonita. Tu objetivo es empezar aquí y llegar al fondo de uno de estos valles de la manera más eficiente posible. Lo que hace el algoritmo de descenso de pendiente es que vas a girar 360 grados y mirar a tu alrededor y preguntarte, si voy a dar un pequeño paso en una dirección, y quiero ir cuesta abajo lo más rápido posible a uno de estos valles. ¿Qué dirección elijo para dar ese pasito?.  \n",
    "\n",
    "Bueno, si quieres bajar esta colina de la manera más eficiente posible, resulta que si estás parado en este punto de la colina y miras a tu alrededor, te darás cuenta de que la mejor dirección para dar tu próximo paso cuesta abajo es aproximadamente esa dirección. Matemáticamente, esta es la dirección de descenso más pronunciada. Significa que cuando das un pequeño paso de bebé, éste te lleva cuesta abajo más rápido que un pequeño paso de bebé que podrías haber dado en cualquier otra dirección.  \n",
    "\n",
    "Después de dar este primer paso, ahora estás en este punto de la colina de aquí. Ahora vamos a repetir el proceso. De pie en este nuevo punto, vas a girar de nuevo 360 grados y preguntarte: ¿en qué dirección daré el siguiente pasito para ir cuesta abajo? Si lo haces y das otro paso, acabarás moviéndote un poco en esa dirección y podrás seguir avanzando. Desde este nuevo punto, puedes volver a mirar a tu alrededor y decidir qué dirección te llevaría cuesta abajo más rápidamente. Da otro paso, otro paso, y así sucesivamente, hasta que te encuentres en el fondo de este valle, en este mínimo local, justo aquí.  \n",
    "\n",
    "Lo que acabas de hacer es pasar por múltiples pasos de descenso de gradiente. Resulta que el descenso de gradiente tiene una propiedad interesante. Recuerde que usted puede elegir un punto de partida en la superficie mediante la elección de los valores de partida para los parámetros $w$ y $b$. Cuando se realiza el descenso por gradiente hace un momento, que había comenzado en este punto aquí. Ahora, imagina que vuelves a realizar el descenso por gradiente, pero esta vez eliges un punto de partida diferente, eligiendo los parámetros que sitúan tu punto de partida un par de pasos a la derecha por aquí. Si entonces repites el proceso de descenso por gradiente, lo que significa que miras a tu alrededor, das un pequeño paso en la dirección del ascenso más pronunciado y terminas aquí (camino azul). Entonces vuelves a mirar a tu alrededor, das otro paso, y así sucesivamente. Si se ejecuta el descenso de gradiente esta segunda vez, comenzando sólo un par de pasos a la derecha de donde lo hicimos la primera vez, entonces se termina en un valle totalmente diferente. Este mínimo diferente aquí a la derecha. \n",
    "Los fondos del primer y segundo valle se llaman mínimos locales. Porque si empiezas a bajar por el primer valle, el descenso por gradiente no te llevará al segundo valle, y lo mismo ocurre si empiezas a bajar por el segundo valle, te quedas en ese segundo mínimo y no encuentras el camino hacia el primer mínimo local. Esta es una propiedad interesante del algoritmo de descenso de gradiente, y verás más sobre esto más adelante.  \n",
    "\n",
    "En este vídeo, has visto cómo el descenso de gradiente te ayuda a ir cuesta abajo. En el siguiente vídeo, vamos a ver las expresiones matemáticas que puedes implementar para que el descenso de gradiente funcione. Pasemos al siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/15U0wiHCIDEM5_sXKrytIbwRGTyqMCC3i/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_62.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos cómo se puede implementar el algoritmo de descenso de gradiente. Permítanme escribir el algoritmo de descenso de gradiente. Aquí está. En cada paso, $w$, el parámetro, se actualiza al valor antiguo de $w$ menos $\\alpha$ veces este término $\\frac{d}{dw}$ de la función costo $J(w,b)$. Lo que esta expresión está diciendo es, después de su parámetro $w$ tomando el valor actual de $w$ y ajustándolo una pequeña cantidad, que es esta expresión a la derecha, menos $\\alpha$ veces este término por aquí. Si sientes que hay mucho en esta ecuación, está bien, no te preocupes. La desmenuzaremos juntos. \n",
    "\n",
    "Primero, esta notación igual aquí. Ahora, desde que dije que estamos asignando w un valor usando este signo de igualdad, así que en este contexto, este signo de igualdad es el operador de asignación. Específicamente, en este contexto, si escribes un código que dice a es igual a $c$, significa tomar el valor $c$ y almacenarlo en tu computadora, en la variable $a$. O si escribes $a$ es igual a $a$ más 1, significa establecer el valor de a para que sea igual a $a$ más 1, o incrementa el valor de $a$ en uno. La codificación del operador de asignación es diferente a las afirmaciones de verdad en matemáticas. Cuando escribo a es igual a $c$, estoy afirmando, es decir, estoy afirmando que los valores de $a$ y $c$ son iguales entre sí. Afortunadamente, nunca escribiré una aserción de verdad $a$ igual a más 1 porque es imposible que sea cierta. En Python y en otros lenguajes de programación, las aserciones de verdad se escriben a veces como igual a igual, así que puedes ver oh, eso dice $a$ igual a $c$ si estás probando si $a$ es igual a $c$. Pero en la notación matemática, como la usamos convencionalmente, como en estos vídeos, el signo igual puede usarse tanto para asignaciones como para aserciones de verdad. Trato de asegurarme de que cuando escribo un signo igual, quede claro si estamos asignando un valor a una variable, o si estamos afirmando la verdad de la igualdad de dos valores.  \n",
    "\n",
    "Ahora, esta inmersión más profunda en lo que los símbolos en esta ecuación significa. El símbolo aquí es el alfabeto griego $\\alpha$. En esta ecuación, Alpha también se llama la **tasa de aprendizaje**. La tasa de aprendizaje es usualmente un pequeño número positivo entre 0 y 1 y podría ser digamos, 0.01. Lo que hace $\\alpha$ es, básicamente, controlar qué tan grande es el paso que se da hacia abajo. Si $\\alpha$ es muy grande, entonces corresponde a un procedimiento de descenso de gradiente muy agresivo en el que estás tratando de dar pasos enormes cuesta abajo. Si $\\alpha$ es muy pequeño, entonces estarías dando pequeños pasos de bebé cuesta abajo. Volveremos más tarde para profundizar en cómo elegir una buena tasa de aprendizaje $\\alpha$.  \n",
    "\n",
    "Finalmente, este término de aquí, es el término derivado de la función de costo $J$. No nos preocupemos por los detalles de esta derivada en este momento. Pero más adelante, podrás ver más sobre el término derivado. Pero por ahora, puedes pensar en este término derivado que dibujé un cuadro magenta alrededor como diciéndote en qué dirección quieres dar tu paso de bebé. En combinación con la tasa de aprendizaje $\\alpha$, también determina el tamaño de los pasos que desea tomar cuesta abajo.  \n",
    "\n",
    "Ahora, quiero mencionar que las derivadas provienen del cálculo. Incluso si no estás familiarizado con el cálculo, no te preocupes. Incluso sin saber nada de cálculo, serás capaz de averiguar todo lo que necesitas saber sobre este término de la derivada en este vídeo y en el siguiente.  \n",
    "\n",
    "Una cosa más. Recuerda que tu modelo tiene dos parámetros, no sólo $w$, sino también $b$. También tienes una operación de asignación de actualización del parámetro $b$ que se parece mucho. A $b$ se le asigna el valor antiguo de b menos la tasa de aprendizaje $\\alpha$ por este término derivado ligeramente diferente, $\\frac{d}{dw}$ de $J(w,b)$. Recuerde que en el gráfico de la parcela de la superficie donde usted está tomando pasos de bebé hasta llegar a la parte inferior del valor, así, para el algoritmo de descenso de gradiente, que va a repetir estos dos pasos de actualización hasta que el algoritmo converge. Por converge, me refiero a que usted alcanza el punto en un mínimo local donde los parámetros $w$ y $b$ ya no cambian mucho con cada paso adicional que usted toma.  \n",
    "\n",
    "Ahora, hay un detalle más sutil acerca de cómo correctamente en el descenso de gradiente semántico, vas a actualizar dos parámetros, $w$ y $b$. Esta actualización se lleva a cabo para ambos parámetros, $w$ y $b$. Un detalle importante es que para el descenso de gradiente, quieres actualizar simultáneamente $w$ y $b$, lo que significa que quieres actualizar ambos parámetros al mismo tiempo. Lo que quiero decir con esto, es que en esta expresión, vas a actualizar $w$ desde el antiguo $w$ a un nuevo $w$, y también estás actualizando $b$ desde su valor más antiguo a un nuevo valor de $b$. La forma de implementar esto es calcular el lado derecho, calculando esta cosa para $w$ y $b$, y simultáneamente al mismo tiempo, actualizar $w$ y $b$ a los nuevos valores. Echemos un vistazo a lo que esto significa.  \n",
    "\n",
    "Aquí está la forma correcta de implementar el descenso de gradiente que hace una actualización simultánea. Esto establece una variable $temp_w$ igual a esa expresión, que es $w$ menos ese término aquí. También hay un conjunto en otra variable $temp_b$ a eso, que es $b$ menos ese término. Calculas ambos lados de la mano, ambas actualizaciones, y las almacenas en las variables $temp_w$ y $temp_b$. Entonces copias el valor de $temp_w$ en $w$, y también copias el valor de $temp_b$ en $b$. Ahora, una cosa que puedes notar es que este valor de $w$ es del for $w$ se actualiza. Aquí, me di cuenta de que la pre-actualización de w es donde va en el término derivado de aquí.  \n",
    "\n",
    "En contraste, aquí hay una implementación incorrecta del descenso de gradiente que no hace una actualización simultánea. En esta implementación incorrecta, calculamos $temp_w$, igual que antes, hasta aquí está bien. Ahora aquí es donde las cosas comienzan a diferir. Entonces actualizamos $w$ con el valor de $temp_w$ antes de calcular el nuevo valor para el otro parámetro a ser. A continuación, calculamos $temp_b$ como $b$ menos ese término aquí, y finalmente, actualizamos $b$ con el valor en $temp_b$. La diferencia entre las implementaciones del lado derecho y del lado izquierdo es que si miras aquí, este w ya ha sido actualizado a este nuevo valor, y este es el $w$ actualizado que realmente entra en la función de coste $J(w, b)$. Esto significa que este término aquí a la derecha no es el mismo que este término de aquí que ves a la izquierda. Eso también significa que este término $temp_b$ de la derecha no es el mismo que el término $temp_b$ de la izquierda, y por lo tanto este valor actualizado para $b$ a la derecha no es el mismo que este valor actualizado para la variable $b$ a la izquierda. La forma en que se implementa el descenso de gradiente en el código, en realidad resulta ser más natural implementarlo de la forma correcta con actualizaciones simultáneas.  \n",
    "\n",
    "Cuando escuchas a alguien hablar de descenso de gradiente, siempre se refieren a los descensos de gradiente en los que se realiza una actualización simultánea de los parámetros. Sin embargo, si se implementa una actualización no simultánea, resulta que probablemente funcionará más o menos de todos modos. Pero hacerlo así no es realmente la forma correcta de implementarlo, es en realidad algún otro algoritmo con propiedades diferentes. Te aconsejo que te quedes con la actualización simultánea correcta y no uses esta versión incorrecta de la derecha. Eso es el descenso de gradiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "El descenso gradual es un algoritmo para encontrar los valores de los parámetros $w$ y $b$ que minimizan la función de coste $J$. ¿Qué hace este enunciado de actualización? (Supongamos que $\\alpha$ es pequeño). \n",
    "\n",
    "$w = w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}$\n",
    "\n",
    "- Comprueba si $w$ es igual a  $w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}$\n",
    "- Actualiza el parámetro $w$ en una pequeña cantidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: Actualiza el parámetro $w$ en una pequeña cantidad\n",
    "\n",
    "Esto actualiza el parámetro en una pequeña cantidad, con el fin de reducir el coste $J$.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el próximo video, entraremos en detalles del término de la derivada que viste en este video, pero del que no hablamos en detalle. Las derivadas son parte del cálculo, y de nuevo, si no estás familiarizado con el cálculo, no te preocupes. No necesitas saber cálculo en absoluto para completar este curso o esta especialización, y tienes toda la información que necesitas para implementar el descenso de gradiente. En el próximo vídeo, repasaremos juntos las derivadas, y saldrás con la intuición y el conocimiento que necesitas para poder implementar y aplicar el descenso de gradiente por ti mismo. Creo que será una cosa emocionante para que usted sepa cómo implementar. Pasemos al siguiente vídeo para ver cómo hacerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1YrsJMrb3l_ghPZhrstuhUqKzDfWSG13A/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a profundizar en el descenso de gradiente para intuir mejor lo que hace y por qué puede tener sentido.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_64.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está el algoritmo de descenso de gradiente que has visto en el vídeo anterior. Como recordatorio, esta variable, este símbolo griego $\\alpha$, es la **tasa de aprendizaje**. La tasa de aprendizaje controla qué tan grande es el paso que se da al actualizar los parámetros del modelo, $w$ y $b$. Este término aquí, este $\\frac{d}{dw}$, es un término derivado. Por convención en matemáticas, esta $d$ se escribe con esta fuente divertida aquí. En caso de que alguien viendo esto tenga un doctorado en matemáticas o sea un experto en cálculo multivariante, puede que se pregunte, eso no es la derivada, es la derivada parcial. Sí, tienen razón. Pero para los propósitos de la implementación de un algoritmo de aprendizaje automático, sólo voy a llamarlo derivada. No te preocupes por estas pequeñas distinciones. En lo que nos vamos a centrar ahora es en conseguir más intuición sobre lo que esta tasa de aprendizaje y lo que esta derivada están haciendo y por qué cuando se multiplican juntos así, resulta en actualizaciones de los parámetros $w$ y $b$. Eso tiene sentido.  \n",
    "\n",
    "Para hacer esto vamos a utilizar un ejemplo un poco más simple donde trabajamos en la minimización de un solo parámetro. Digamos que tenemos una función de coste $J$ de un solo parámetro $w$ con $w$ es un número. Esto significa que el descenso del gradiente ahora se ve así: $w$ se actualiza a $w$ menos la tasa de aprendizaje $\\alpha$ veces $\\frac{d}{dw}$ de $J(w)$. Usted está tratando de minimizar el costo mediante el ajuste del parámetro $w$.\n",
    "\n",
    "Esto es como nuestro ejemplo anterior donde habíamos establecido temporalmente $b$ igual a 0 con un parámetro $w$ en lugar de dos, usted puede mirar a los gráficos de dos dimensiones de la función de coste $J$, en lugar de gráficos de tres dimensiones. Veamos lo que hace el descenso de gradiente sólo en la función $J(w)$. Aquí en el eje horizontal está el parámetro $w$, y en el eje vertical está el coste $J(w)$. Ahora menos inicializamos el descenso de gradiente con algún valor inicial para $w$. Vamos a inicializarlo en este punto. Imagina que comienzas en este punto justo aquí en la función $J$, lo que el descenso de gradiente hará es que actualizará $w$ para ser $w$ menos la tasa de aprendizaje $\\alpha$ veces $\\frac{d}{dw}$ de $J(w)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_65.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos lo que significa este término derivado aquí (recuadra en magenta). Una forma de pensar en la derivada en este punto de la línea es dibujar una línea tangente, que es una línea recta que toca esta curva en ese punto. En fin, la pendiente de esta recta es la derivada de la función $J$ en este punto. Para obtener la pendiente, puedes dibujar un pequeño triángulo como este. Si calculas la altura dividida por el ancho de este triángulo, esa es la pendiente. Por ejemplo, esta pendiente podría ser 2 sobre 1, y cuando la línea tangente apunta hacia arriba y hacia la derecha, la pendiente es positiva, lo que significa que esta derivada es un número positivo, por lo que es mayor que 0. La w actualizada va a ser $w$ menos la tasa de aprendizaje por algún número positivo. La tasa de aprendizaje es siempre un número positivo. Si tomas $w$ menos un número positivo, terminas con un nuevo valor para $w$, que es más pequeño. En el gráfico, te estás moviendo hacia la izquierda, estás disminuyendo el valor de $w$. Puedes notar que esto es lo correcto si tu objetivo es disminuir el costo $J$, porque cuando nos movemos hacia la izquierda en esta curva, el costo $J$ disminuye, y te estás acercando al mínimo para $J$, que está aquí.  \n",
    "\n",
    "Hasta ahora, el descenso de gradiente, parece estar haciendo lo correcto. Ahora, vamos a ver otro ejemplo. Tomemos la misma función $J(w)$ como arriba, y ahora digamos que usted inicializó el descenso de gradiente en un lugar diferente. Digamos que eligiendo un valor inicial para $w$ que está aquí a la izquierda. Ese es este punto de la función $J$. Ahora, el término derivado, recuerde es $\\frac{d}{dw}$ de $J(w)$, y cuando miramos la línea tangente en este punto aquí, la pendiente de esta línea es una derivada de J en este punto. Pero esta línea tangente tiene una pendiente hacia la derecha. Esta línea inclinada hacia la derecha tiene una pendiente negativa. En otras palabras, la derivada de $J$ en este punto es un número negativo. Por ejemplo, si usted dibuja un triángulo, entonces la altura así es negativo 2 y la anchura es 1, la pendiente es negativo 2 dividido por 1, que es negativo 2, que es un número negativo. Cuando actualizas $w$, obtienes $w$ menos la tasa de aprendizaje por un número negativo. Esto significa que se resta de w, un número negativo. Pero restar un número negativo significa añadir un número positivo, y así terminas aumentando $w$. Porque restar un número negativo es lo mismo que añadir un número positivo a $w$. Este paso del descenso de gradiente hace que $w$ aumente, lo que significa que te estás moviendo a la derecha del gráfico y tu coste $J$ ha disminuido hasta aquí. De nuevo, parece que el descenso por gradiente está haciendo algo razonable, te está acercando al mínimo.  \n",
    "\n",
    "Esperemos que estos dos últimos ejemplos muestren algo de la intuición detrás de lo que un término derivado está haciendo y por qué este cambio de descenso de gradiente anfitrión w para acercarte al mínimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "El descenso del gradiente es un algoritmo para encontrar los valores de los parámetros $w$ y $b$ que minimizan la función de coste $J$.\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "Asumiendo que $\\alpha$ es un número positivo (mayor que cero): Cuando  es un número positivo (mayor que cero) -- como en el ejemplo de la parte superior de la diapositiva mostrada arriba -- ¿qué sucede con w después de un paso de actualización?\n",
    "\n",
    "- $w$ aumenta\n",
    "- $w$ disminuye\n",
    "- No es posible saber si $w$ aumenta o disminuye. \n",
    "- $w$ permanece igual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: $w$ disminuye.\n",
    "\n",
    "La tasa de aprendizaje α es siempre un número positivo, por lo que si se toma w menos un número positivo, se obtiene un nuevo valor de w que es menor.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero que este vídeo te haya dado una idea de por qué tiene sentido el término derivado en el descenso de gradiente. Otra cantidad clave en el algoritmo de descenso de gradiente es la tasa de aprendizaje $\\alpha$. ¿Cómo se elige $\\alpha$? ¿Qué pasa si es demasiado pequeña o qué pasa cuando es demasiado grande? En el siguiente vídeo, vamos a profundizar en el parámetro $\\alpha$ para ayudar a construir intuiciones sobre lo que hace, así como la forma de hacer una buena elección de un buen valor de $\\alpha$ para su implementación del descenso de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1lFB60Vex910Zskf-2taft-RpiHb7E8wK/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La elección de la tasa de aprendizaje, $\\alpha$, tendrá un gran impacto en la eficiencia de su implementación del descenso de gradiente. Y si $\\alpha$, la tasa de aprendizaje se elige mal la tasa de descenso puede incluso no funcionar en absoluto. En este video, vamos a echar un vistazo más profundo a la tasa de aprendizaje. Esto también le ayudará a elegir mejores tasas de aprendizaje para sus implementaciones de descenso de gradiente. Así que aquí de nuevo, es la gran regla de inter-sentido.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_67.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "$w$ se actualiza para ser $w$ menos la tasa de aprendizaje, $\\alpha$ veces el término derivado. Para saber más sobre lo que hace la tasa de aprendizaje $\\alpha$. Veamos lo que podría suceder si la tasa de aprendizaje $\\alpha$ es demasiado pequeña o si es demasiado grande. \n",
    "Para el caso en que la tasa de aprendizaje es demasiado pequeña. Aquí hay un gráfico donde el eje horizontal es $w$ y el eje vertical es el costo $J$. Y aquí está el gráfico de la función $J(w)$. Vamos a empezar a calificar el descenso en este punto aquí, si la tasa de aprendizaje es demasiado pequeña. Entonces lo que sucede es que usted multiplica su término derivado por algún número muy, muy pequeño. Así que vas a estar multiplicando por el número $\\alpha$. Eso es realmente pequeño, como 0,0000001. Y así terminas tomando un paso de bebé muy pequeño como ese. Luego, a partir de este punto, vas a dar otro pequeño paso de bebé. Pero como la tasa de aprendizaje es tan pequeña, el segundo paso también es minúsculo. El resultado de este proceso es que acabas disminuyendo el coste $J$ pero increíblemente lento. Entonces, aquí hay otro paso y otro paso, otro paso minúsculo hasta que finalmente te acercas al mínimo. Pero como puedes notar vas a necesitar muchos pasos para llegar al mínimo.  \n",
    "\n",
    "Así que para resumir, si la tasa de aprendizaje es demasiado pequeña, entonces el descenso por gradiente funcionará, pero será lento. Tomará mucho tiempo porque va a tomar estos pequeños pasos de bebé. Y va a necesitar muchos pasos antes de acercarse al mínimo.  \n",
    "\n",
    "Ahora, veamos un caso diferente. ¿Qué sucede si la tasa de aprendizaje es demasiado grande? Aquí hay otro gráfico de la función de costo. Y digamos que empezamos el descenso del gradiente con $w$ en este valor de aquí. Así que en realidad ya está bastante cerca del mínimo. Así que los puntos decorativos a la derecha. Pero si la tasa de aprendizaje es demasiado grande, entonces se actualiza $w$ paso muy gigante para ser todo el camino por aquí. Y eso es este punto aquí en la función J. Así que usted se mueve de este punto a la izquierda, todo el camino a este punto a la derecha. Y ahora el coste ha empeorado. Ha aumentado porque comenzó en este valor aquí y después de un paso, en realidad aumentó a este valor aquí. Ahora la derivada en este nuevo punto dice que hay que disminuir $w$ pero cuando la tasa de aprendizaje es demasiado grande. Entonces puedes dar un gran paso yendo desde aquí hasta aquí. Así que ahora has llegado a este punto aquí y de nuevo, si la tasa de aprendizaje es demasiado grande. Entonces das otro gran paso con una aceleración y vuelves a sobrepasar el mínimo. Así que ahora estás en este punto de la derecha y una vez más haces otra actualización. Y terminar todo el camino aquí y por lo que ahora está en este punto aquí. Así que, como puedes notar, te estás alejando cada vez más del mínimo. Así que si la tasa de aprendizaje es demasiado grande, a continuación, crear el sentido puede sobrepasar y nunca puede llegar al mínimo. Y otra forma de decirlo es que la gran intersección puede no converger e incluso divergir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_68.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que, aquí hay otra pregunta, usted puede preguntarse uno de sus parámetros $w$ ya está en este punto aquí. Así que su costo $J$ ya está en un mínimo local. ¿Qué piensas? ¿Un paso de descenso de gradiente será suficiente si ya has alcanzado un mínimo? Así que este es un tema complicado. Cuando estaba aprendiendo estas cosas por primera vez, me llevó mucho tiempo entenderlo. Pero vamos a trabajar en esto juntos. Supongamos que tienes una función de costo $J$. Y la que ves aquí no es una función de costo de error cuadrado y esta función de costo tiene dos mínimos locales que corresponden a los dos valles que ves aquí. Ahora supongamos que después de algún número de pasos de descenso de gradiente, su parámetro $w$ está aquí, digamos igual a cinco. Y entonces este es el valor actual de $w$. Esto significa que estás en este punto de la función de coste $J$. Y eso resulta ser un mínimo local, resulta que si llamas la atención sobre la función en este punto. La pendiente de esta línea es cero y por lo tanto el término derivado. Aquí es igual a cero para el valor actual de $w$. Y por lo que está graduando la actualización de descenso se convierte en $w$ se actualiza a w menos la tasa de aprendizaje veces cero. Estamos aquí que es porque el término derivado es igual a cero. Y esto es lo mismo que decir que pongamos $w$ a ser igual a w. Así que esto significa que si ya estás en un mínimo local, el descenso de gradiente deja w sin cambios. Porque sólo actualiza el nuevo valor de $w$ para que sea exactamente el mismo valor anterior de $w$. Así que concretamente, digamos que si el valor actual de $w$ es cinco. Y $\\alpha$ es 0.1 después de una iteración, actualizas $w$ como $w$ menos $\\alpha$ por cero y sigue siendo igual a cinco. Así que si tus parámetros ya te han llevado a un mínimo local, entonces más pasos de descenso de gradiente a absolutamente nada. No cambia los parámetros, que es lo que quieres, porque mantiene la solución en ese mínimo local. Esto también explica por qué el descenso de gradiente puede llegar a un mínimo local, incluso con una tasa de aprendizaje fija $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_69.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Esto es lo que quiero decir, para ilustrar esto, veamos otro ejemplo. Aquí está la función de coste $J(w)$ que queremos minimizar. Vamos a inicializar el descenso de gradiente aquí en este punto. Si tomamos un paso de actualización, tal vez nos llevará a ese punto. Y debido a que esta derivada es bastante grande, la clasificación, el descenso toma un paso relativamente grande a la derecha. Ahora, estamos en este segundo punto donde tomamos otro paso. Y usted puede notar que la pendiente no es tan empinada como lo fue en el primer punto. Así que la derivada no es tan grande. Y por lo que el siguiente paso de actualización no será tan grande como ese primer paso. Ahora, lea este tercer punto aquí y la derivada es más pequeña de lo que era en el paso anterior. Y tomará un paso aún más pequeño a medida que nos acercamos al mínimo. La derivada se acerca más y más a cero. Así que a medida que ejecutamos el descenso de gradiente, eventualmente estamos tomando pasos muy pequeños hasta que finalmente llegue a un mínimo local.  \n",
    "\n",
    "Así que sólo para recapitular, a medida que nos acercamos a un mínimo local el descenso por gradiente automáticamente tomará pasos más pequeños. Y eso es porque a medida que nos acercamos al mínimo local, la derivada automáticamente se hace más pequeña. Y eso significa que los pasos de actualización también se reduce automáticamente. Incluso si la tasa de aprendizaje alfa se mantiene en algún valor fijo. Así que ese es el algoritmo de descenso de gradiente, se puede utilizar para tratar de minimizar cualquier función de coste $J$. No sólo la función de coste de error cuadrático medio que estamos utilizando para la nueva regresión.  \n",
    "\n",
    "En el siguiente video, vamos a tomar la función $J$ y volver a ser exactamente la función de coste de los modelos de regresión lineal. La función de coste del error medio cuadrático que se nos ocurrió antes. Y poner juntos grandes en desacuerdo con esta función de costo que le dará su primer algoritmo de aprendizaje, el algoritmo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1GZZVKpO_dahLX8QloXHc41YT2Hu4oUWf/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente, usted echó un vistazo al modelo de regresión lineal y luego la función de costo, y luego el algoritmo de descenso de gradiente. En este video, vamos a sacar juntos y utilizar la función de coste de error cuadrado para el modelo de regresión lineal con el descenso de gradiente. Esto nos permitirá entrenar el modelo de regresión lineal para que se ajuste a una línea recta para conseguir los datos de entrenamiento. Vamos a ello.  \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_71.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está el modelo de regresión lineal. A la derecha está la función de coste del error cuadrado. Abajo está el algoritmo de descenso de gradiente. Resulta que si calculas estas derivadas, estos son los términos que obtendrías. La derivada con respecto a $w$ es este $\\frac{1}{m}$, la suma de $i$ es igual a 1 a través de $m$. Entonces el término de error, que es la diferencia entre la predicción y los valores reales veces la característica de entrada $x^{(i)}$. La derivada con respecto a b es esta fórmula aquí, que se ve igual que la ecuación anterior, excepto que no tiene ese término $x^{(i)}$ al final. Si usas estas fórmulas para calcular estas dos derivadas e implementas el descenso de gradiente de esta manera, funcionará.  \n",
    "\n",
    "Ahora, te estarás preguntando, ¿de dónde he sacado estas fórmulas? Se derivan utilizando el cálculo. Si quieres ver la derivación completa, voy a correr rápidamente a través de la derivación en la siguiente diapositiva. Pero si no recuerdas o no te interesa el cálculo, no te preocupes. Puedes saltarte los materiales de la siguiente diapositiva por completo y aún así ser capaz de implementar el descenso de gradiente y terminar esta clase y todo funcionará bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_72.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "En esta diapositiva, que es una de las diapositivas más matemáticas de toda la especialización, y de nuevo es completamente opcional, te mostraremos cómo calcular los términos de la derivada. Empecemos con el primer término. La derivada de la función de coste $J$ con respecto a $w$. Empezaremos por introducir la definición de la función de coste $J$. $J(w,b)$ es esto. $\\frac{1}{2m}$ veces esta suma de los términos de error al cuadrado. Ahora recuerda también que $fw,b(x(i))$ es igual a este término de aquí, que es $wx^{(i)}+b$. Lo que nos gustaría hacer es calcular la derivada, también llamada la derivada parcial con respecto a $w$ de esta ecuación aquí a la derecha. Si has tomado una clase de cálculo antes, y de nuevo está totalmente bien si no lo has hecho, puedes saber que por las reglas del cálculo, la derivada es igual a este término aquí. Por lo que el dos de aquí y el dos de aquí se cancelan, dejándonos con esta ecuación que viste en la diapositiva anterior. Esta es la razón por la que tuvimos que encontrar la función de costo con el 1,5 a principios de esta semana es porque hace que la derivada parcial más ordenada. Anula las dos que aparecen al calcular la derivada.  \n",
    "\n",
    "Para la otra derivada con respecto a b, es bastante similar. Puedo escribirlo así, y una vez más, enchufando la definición de $f_{w,b}(x^{(i)})$, dando esta ecuación. Por las reglas del cálculo, esto es igual a esto donde ya no hay $x^{(i)}$ al final. Los 2's cancelan uno pequeño y terminas con esta expresión para la derivada con respecto a $b$. Ahora tienes estas dos expresiones para las derivadas. Puedes introducirlas en el algoritmo de descenso de gradiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_73.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí está el algoritmo de descenso de gradiente para la regresión lineal. Realiza repetidamente estas actualizaciones de $w$ y $b$ hasta la convergencia. Recuerde que esta $f(x)$ es un modelo de regresión lineal, por lo que como igual a $w$ veces $x$ más $b$. Esta expresión aquí es la derivada de la función de coste con respecto a $w$. Esta expresión es la derivada de la función de coste con respecto a $b$. Sólo como un recordatorio, que desea actualizar $w$ y $b$ simultáneamente en cada paso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_74.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, vamos a familiarizarnos con el funcionamiento del descenso por gradiente. Uno de los problemas que vimos con el descenso de gradiente es que puede conducir a un mínimo local en lugar de un mínimo global. Si el mínimo global significa el punto que tiene el menor valor posible para la función de coste $J$ de todos los puntos posibles. Usted puede recordar esta parcela de la superficie que se parece a un parque al aire libre con algunas colinas con el proceso y las aves como un relajante Hobo Hill. Esta función tiene más de un mínimo local. Recuerde, dependiendo de dónde inicialice los parámetros $w$ y $b$, puede terminar en diferentes mínimos locales. Puedes terminar aquí, o puedes terminar aquí. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_75.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Pero resulta que cuando usted está usando una función de coste de error cuadrado con la regresión lineal, la función de coste no tiene y nunca tendrá múltiples mínimos locales. Tiene un único mínimo global debido a esta forma de tazón. El término técnico para esto es que esta función de coste es una función convexa. Informalmente, una función convexa es una función con forma de cuenco y no puede tener ningún mínimo local aparte del único mínimo global. Cuando se implementa el descenso de gradiente en una función convexa, una buena propiedad es que, siempre que la tasa de aprendizaje se elija adecuadamente, siempre convergerá al mínimo global.  \n",
    "\n",
    "Enhorabuena, ahora sabes cómo implementar el descenso de gradiente para la regresión lineal. Tenemos un último vídeo para esta semana. En ese video, veremos este algoritmo en acción. Vamos a ese último video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"green\"><b> Link a video </b></font></summary>\n",
    "    \n",
    "https://drive.google.com/file/d/1j9_hT4PdCB-6o8P0MMzhGkIODfmpkWCx/view?usp=sharing\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué ocurre cuando se ejecuta el descenso de gradiente para la regresión lineal. Vamos a ver el algoritmo en acción. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_85.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Aquí hay un gráfico del modelo y los datos en la parte superior izquierda y un gráfico de contorno de la función de coste en la parte superior derecha y en la parte inferior está el gráfico de superficie de la misma función de coste. A menudo $w$ y $b$ se inicializan a 0, pero para esta demostración, vamos a inicializar $w$ = -0,1 y $b$ = 900. Así que esto corresponde a $f(x) = -0,1x + 900$.  \n",
    "\n",
    "Ahora, si damos un paso usando el descenso de gradiente, terminamos yendo desde este punto de la función de coste de aquí (cruz azul) hasta este punto justo abajo (cruz naranja) y a la derecha y fíjate que el ajuste de la línea recta también cambia un poco.  \n",
    "\n",
    "Demos otro paso. La función de coste se ha desplazado ahora a este tercio (cruz verde) y de nuevo la función $f(x)$ también ha cambiado un poco.  \n",
    "\n",
    "A medida que se dan más de estos pasos, el coste va disminuyendo en cada actualización. Así que los parámetros $w$ y $b$ siguen esta trayectoria. Y si miras a la izquierda, obtienes este ajuste de línea recta correspondiente que se ajusta a los datos cada vez mejor hasta que hemos alcanzado el mínimo global. El mínimo global corresponde a este ajuste de línea recta, que es un ajuste relativamente bueno a los datos. Quiero decir, no es genial. Y así es el descenso de gradiente y vamos a utilizar esto para ajustar un modelo a todos los datos. Y ahora puedes usar este modelo $f(x)$ para predecir el precio de la casa de tus clientes o de cualquier otra casa. Por ejemplo, si el tamaño de la casa de tu amigo es de 1250 pies cuadrados, ahora puedes leer el valor y predecir que tal vez podrían obtener, no sé, 250.000 dólares por la casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W1_Página_86.jpg\"   style=\"width:500px;height:280px;\" >\n",
    "</figure>\n",
    "\n",
    "Para ser más precisos, este proceso de descenso de gradiente se llama descenso de gradiente por lotes (Batch gradient descent). El término descenso de gradiente por lotes se refiere al hecho de que en cada paso del descenso de gradiente, estamos mirando todos los ejemplos de entrenamiento, en lugar de sólo un subconjunto de los datos de entrenamiento.  \n",
    "\n",
    "Así que al calcular el descenso de gradiente, al calcular las derivadas, al calcular la suma de $i$ 1 a $m$. Y el descenso de gradiente de bash está mirando todo el lote de ejemplos de entrenamiento en cada actualización. Sé que el descenso de gradiente por lotes puede no ser el nombre más intuitivo, pero esto es lo que la gente en la comunidad de aprendizaje de la máquina lo llaman. Si has oído hablar del boletín The Batch, es publicado por DeepLearning.AI. El boletín The batch también recibió el nombre de este concepto en el aprendizaje automático. Y luego resulta que hay otras versiones del descenso de gradiente que no miran todo el conjunto de entrenamiento, sino que miran subconjuntos más pequeños de los datos de entrenamiento en cada paso de actualización. Pero usaremos el descenso de gradiente por lotes para la regresión lineal.Así que eso es todo para la regresión lineal.  \n",
    "\n",
    "Enhorabuena por haber superado tu primer modelo de aprendizaje automático. Espero que vayas a celebrarlo o, no sé, que te eches una siesta en tu hamaca. En el laboratorio opcional que sigue a este video. Verás una revisión del algoritmo de descenso de gradiente y cómo implementarlo en el código. También verás un gráfico que muestra cómo el costo disminuye a medida que continúas entrenando más iteraciones. Y también verás un gráfico de contorno, viendo cómo el coste se acerca al mínimo global a medida que el descenso de gradiente encuentra valores cada vez mejores para los parámetros $w$ y $b$. Así que recuerda que para hacer el laboratorio opcional. Sólo tienes que leer y ejecutar este código. Necesitarás escribir cualquier código por ti mismo y espero que te tomes unos momentos para hacerlo. Y también familiarízate con el código del descenso de gradiente porque esto te ayudará a implementar tú mismo este y otros algoritmos similares en el futuro.  \n",
    "\n",
    "Gracias por seguir conmigo hasta el final de este último vídeo de la primera semana y enhorabuena por haber llegado hasta aquí. Estás en camino de convertirte en una persona de aprendizaje automático. Además de los laboratorios opcionales, si aún no lo has hecho. Espero que también revises los cuestionarios de práctica, que son una buena manera de comprobar tu propia comprensión de los conceptos. Tampoco pasa nada si no lo haces todo bien a la primera. Y también puedes hacer los cuestionarios varias veces hasta que obtengas la puntuación que deseas. Ahora sabes cómo implementar la regresión lineal con una variable y eso nos lleva al cierre de esta semana. La próxima semana, aprenderemos a hacer la regresión lineal mucho más poderosa, en lugar de una característica como el tamaño de una casa, aprenderás cómo hacerla funcionar con muchas características. También aprenderás a hacer que se ajuste a curvas no lineales. Estas mejoras harán que el algoritmo sea mucho más útil y valioso. Por último, también repasaremos algunos consejos prácticos que realmente esperan conseguir que la regresión lineal funcione en aplicaciones prácticas. Estoy muy contento de tenerte aquí conmigo en esta clase y espero verte la próxima semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice quiz: Train the model with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 1**\n",
    "\n",
    "El descenso del gradiente es un algoritmo para encontrar los valores de los parámetros $w$ y $b$ que minimizan la función de coste $J$. \n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    " \n",
    "Cuando $\\frac{\\partial J(w,b)}{\\partial w}$ es un número negativo (menor que cero), ¿qué ocurre con $w$ después de un paso de actualización?\n",
    "- $w$ disminuye\n",
    "- No es posible saber si $w$ aumenta o disminuye. \n",
    "- $w$ aumenta\n",
    "- $w$ permanece igual \n",
    "\n",
    "**Pregunta 2**\n",
    "\n",
    "Para la regresión lineal, ¿cuál es el paso de actualización del parámetro $b$?\n",
    "\n",
    "- $b = b - \\alpha \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)}$\n",
    "- $b = b - \\alpha \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuestas:\n",
    "\n",
    "*Pregunta 1:*\n",
    "    \n",
    "$w$ aumenta\n",
    "\n",
    "*Pregunta 2:*\n",
    " \n",
    "$b = b - \\alpha \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})$\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
