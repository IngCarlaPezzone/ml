{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NATURAL LANGUAGE PROCESSING SPECIALIZATION\n",
    "# Curso 1: Natural Language Processing with Classification and Vector Spaces\n",
    "\n",
    "*Esta notebook plasma los apuntes traducidos al español del Curso dicatado por [DeepLearning.AI](https://www.deeplearning.ai/courses/), por lo que puede encontrar errores. Las figuras y ecuaciones se han obtenido/adaptado directamente de las diapositivas utilizadas en el curso. Todo el mérito es de los instructores. Simplemente espero que los apuntes sirvan como material de estudio complementario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEMANA 1: SENTIMENTAL ANALYSIS WITH LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the NLP Specialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiero que conozcas a mis amigos, Jonas y Lucas, los instructores de esta especialización. Hola a todos. Bienvenidos a la especialización. \n",
    "\n",
    "Conozco a Jonas desde hace muchos años. Es instructor en la Universidad de Stanford y también me ha ayudado a crear la especialización de aprendizaje profundo. A lo largo de los años, Jonas  ha enseñado a cientos de estudiantes aprendiendo IA y aprendizaje automático, NLP y otros temas por primera vez, y también es mentor de estudiantes en una gran variedad de proyectos relacionados con la IA. Así que me encantó tenerte con nosotros. Gracias por la introducción y siempre es genial trabajar con usted. \n",
    "\n",
    "Lucas es miembro del equipo de Google Brain donde investiga sobre el aprendizaje profundo y PNL. Así que todo, desde la traducción automática hasta el análisis, es el coautor del sistema TensorFlow de Google, así como de la red de transformadores. Por lo tanto, su trabajo ha tenido una gran influencia en todo el PNL y la IA. Estoy muy emocionado de tener también a Lucas como instructor de la especialización. Gracias por la introducción, Andrew. \n",
    "\n",
    "Jonas y Lucas te guiarán a través de los conceptos más importantes en el procesamiento del lenguaje natural. La PNL ha cambiado mucho en las últimas décadas. La vista ha comenzado utilizando principalmente sistemas basados en reglas donde alguien podría codificar una regla como usted ve la palabra buena, luego suponga que esta es una opinión positiva del cliente para luego usar sistemas probabilísticos que funcionen mucho mejor. Pero todavía requieren mucha ingeniería manual para saber dónde la PNL se basa mucho más en el aprendizaje automático y el aprendizaje profundo.\n",
    "\n",
    "Más recientemente, con el aumento de las potentes computadoras, ahora podemos entrenar sistemas integrales que hubieran sido imposibles de entrenar hace unos años. Ahora podemos capturar patrones más complicados y podemos usar estos modelos en cuestión respondiendo en chatbots, y luego en otras aplicaciones. Muchas de estas aplicaciones se construyen con modelos de atención, que vas a aprender en esta especialización. Hace unos años, estos modelos tardaban semanas o incluso meses en entrenarse. Pero con atención, puedes entrenar estos modelos en solo unas horas. \n",
    "\n",
    "En esta especialización, usted aprende a construir tecnologías PNL incluyendo las mismas tecnologías que las implementadas en muchos sistemas comerciales grandes. En el primer curso, aprenderá sobre la clasificación y los espacios vectoriales. Jonas, ¿puedes contarnos un poco sobre el primer curso? Seguro, en el primer curso, aprenderás a distinguir entre fragmentos de texto con sentimientos positivos y sentimientos negativos. Lo hará utilizando regresión logística y clasificadores de Bayes ingenuos. También aprenderá a representar palabras, consultas y documentos incluyendo otros fragmentos de texto como números en vectores. Construirá su primer sistema de traducción automática y aprenderá sobre hash sensible a la localidad, que es solo un método, que le ayudará con la búsqueda eficiente. Gracias Jonas. \n",
    "\n",
    "Después del primer curso, luego pasa al segundo curso en el que aprendes modelos probabilísticos en PNL. Así que estas son cosas como dar unas pocas palabras, ¿cuál es la probabilidad de que la siguiente palabra sea la palabra v versus algo más. Así que estos son algoritmos que todos estamos usando casi todos los días. Y en esta especialización, aprenderá cómo construir estos algoritmos usted mismo. Después de los dos primeros cursos con la base que te doy, entonces pasarás al tercer curso que te enseña modelos de secuencia. \n",
    "\n",
    "Y, por último, en el cuarto curso, usted aprende acerca de los modelos de atención y esto le llevará a decir a los modelos de arte PNL cosas útiles como chatbots preguntas respuesta y resumen de texto. Jonas, ¿quieres decir unas palabras sobre eso?. En el momento en que complete las puntuaciones para, usted será capaz de implementar la traducción automática neuronal de última generación, resumen, respuesta de preguntas y chatbots. Le mostraremos cómo puede combinar la atención y la computación paralela para construir estos sistemas desde cero. Estos modelos tienen un alto impacto en la industria. Se podrían utilizar, por ejemplo, para automatizar los centros de llamadas o las empresas pueden usarlos para dar sentido a grandes volúmenes de datos. \n",
    "\n",
    "Estoy muy emocionado de que todo el mundo comience a tomar estos cursos, aprender estas tecnologías e ir a construir algunos grandes sistemas de PNL. Empecemos. Impresionante, nos vemos en el aula. Vamos a saltar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Course 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido a este primer curso de PNL en el que aprenderás sobre la clasificación y los espacios vectoriales. También aprenderá sobre la aplicación de estas ideas a problemas como el análisis de sentimientos y la traducción de palabras. Por ejemplo, supongamos que tiene 1.000 reseñas de productos, por lo que fragmentos de textos escritos por los usuarios. ¿Puede crear un sistema para revisar automáticamente todas estas reseñas de productos para averiguar qué fracción de ellos son opiniones positivas frente a críticas negativas? Este curso te enseñará cómo hacerlo. \n",
    "\n",
    "Lucas, ¿puedes decir unas palabras sobre este primer curso? Seguro. En la primera semana, aprenderá a representar texto como vector y a crear un clasificador que clasifique si un texto de muestra es un sentimiento positivo o negativo. Usará regresión logística para eso. En la segunda semana, usarás el clasificador Naive Bayes en el mismo problema. En la tercera semana, aprenderá acerca de los modelos de espacio vectorial. Aprenderá a representar documentos de texto como tweets, artículos, consultas o cualquier objeto que contenga texto como vector. Esto es importante en la recuperación de información, en la indexación, en la clasificación de relevancia y también en el filtrado de información. Por ejemplo, cuando busca una consulta en línea, el algoritmo se basa en todos estos conceptos para devolverle los resultados. Finalmente, en la semana 4, construirá su primer sistema simple de traducción automática y hará uso del hash sensible a la localidad para mejorar el rendimiento de la búsqueda de vecinos más cercanos. Gracias, Eunice y Lucas. Con eso, empecemos y pasemos al siguiente video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenidos a la primera semana del Curso 1. Esta semana trata sobre la regresión logística, que es una herramienta muy importante utilizada en muchas aplicaciones en PNL. Los algoritmos de regresión logística son particularmente útiles porque son fáciles de entrenar y le proporcionan un buen resultado de referencia. Esta semana utilizarás la regresión logística para el análisis del sentimiento de los tweets. Primero procesarás los datos, luego entrenarás tu modelo y, finalmente, probarás la precisión de tu modelo. Hemos diseñado estos cursos de manera que cada semana yo te daré la visión general del material y Jonas te dará los detalles. Llévatelo, Jonas. Bien, genial. Sígueme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised ML & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido y esta semana vas a aprender sobre el aprendizaje automático supervisado y específicamente vas a aprender acerca de la regresión logística. Para que pueda implementar regresión logística, debe tomar algunos pasos. En este video aprenderás sobre los pasos necesarios para implementar este algoritmo, así que echemos un vistazo.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_04.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "En el aprendizaje automático supervisado tiene características de entrada $X$ y un conjunto de etiquetas $Y$. Ahora, para asegurarse de que está obteniendo las predicciones más precisas basadas en sus datos, su objetivo es minimizar sus tasas de error o costo tanto como sea posible. Y para hacer esto, va a ejecutar su función de predicción que toma datos de parámetros para asignar sus entidades a las etiquetas de salida $\\hat{y}$. Ahora la mejor asignación de entidades a etiquetas se logra cuando se minimiza la diferencia entre los valores esperados $Y$ y los valores predecidos $\\hat{y}$. Qué hace la función de coste comparando qué tan cerca está su $\\hat{y}$ de salida con su etiqueta $Y$. A continuación, puede actualizar sus parámetros y repetir todo el proceso hasta que su costo se minimice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_05.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que echemos un vistazo a la tarea supervisada de clasificación de aprendizaje automático del análisis de sentimientos. En este ejemplo tienes el tweet, digamos, estoy feliz porque estoy aprendiendo PNL. Y el objetivo de esta tarea es predecir si un tweeta tiene un sentimiento positivo o negativo. Y lo harás comenzando con un conjunto de entrenamiento donde los tweets con un sentimiento positivo tienen una etiqueta de 1, y los tweets con un sentimiento negativo tienen una etiqueta de 0. Para esta tarea, utilizará su clasificador de regresión logística que asigna sus observaciones a dos clases distintas. A continuación te mostraré cómo hacer esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_06.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que para empezar a construir un clasificador de regresión logística que sea capaz de predecir sentimientos de un tweet arbitrario. Primero procesará los tweets sin procesar en sus conjuntos de entrenamiento y extraerá características útiles. Luego entrenará su clasificador de regresión logística mientras minimiza el costo. Y finalmente podrás hacer tus predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "No te hemos dicho cómo convertir el texto en bruto en características numéricas para las tareas de PNL. Pero, ¿cuál sería tu conjetura sobre cómo lo haremos para los tweets? \n",
    "\n",
    "- Asigna un número real a cada palabra del diccionario inglés y sustituye cada una de las palabras de cada tuit por el número correspondiente. \n",
    "\n",
    "- Digitaliza la forma de cada palabra como si fuera una imagen en blanco y negro, extrae las características como lo harías en el reconocimiento de imágenes. \n",
    "\n",
    "- Haz una lista de posibles palabras y coteja cada una de ellas con las palabras de cada uno de tus tuits. Al final tendrás un vector de características poblado de ceros y unos con un tamaño igual al número de palabras posibles.\n",
    "\n",
    "- Cuente las veces que cada palabra de los tweets aparece en cada una de las categorías (positivas y negativas), y luego sume esos recuentos para cada uno de sus tweets en cada categoría. Terminará con un vector de características con n características, donde n es el número de categorías.\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: No hay respuestas incorrectas en este cuestionario.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que en este video aprendiste acerca de los pasos necesarios para clasificar un tweet. Dado el tweet, debe clasificarlo como positivo o negativo. Para que lo haga, primero tiene que extraer las características. Entonces tienes que entrenar a tu modelo. Y luego tienes que clasificar el tweet basado en tu modelo entrenado. En el siguiente vídeo, aprenderás a extraer estas características. Así que echemos un vistazo a cómo puedes hacer eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary & Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola. Bienvenida de nuevo. En este vídeo, aprenderás a representar un texto como vector. Para que lo hagas, primero tienes que crear un vocabulario que te permitirá codificar cualquier texto o cualquier tweet como una matriz de números. Así que vamos a sumergirnos y ver cómo se puede hacer esto. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_10.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Imagine una lista de tweets, visualmente se vería así. Entonces tu vocabulario, $V$, sería la lista de palabras únicas de tu lista de tweets. Para obtener esa lista, tendrás que revisar todas las palabras de todos tus tweets y guardar cada palabra nueva que aparezca en tu búsqueda. Así que en este ejemplo, tendrías la palabra *I*, luego la palabra *am* y *happy*, *because*, y así sucesivamente. Pero tenga en cuenta que la palabra *I* y la palabra *am* no se repetirían en el vocabulario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_11.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a tomar estos tweets y extraer características usando su vocabulario. Para hacerlo, tendrías que comprobar si cada palabra de tu vocabulario aparece en el tweet. Si lo hace como en el caso de la palabra *I*, asignaría un valor de 1 a esa característica, así. Si no aparece, asignarías un valor de 0. En este ejemplo, la representación de su tweet tendría seis 1 y muchos 0. Estos corresponden a cada palabra única de tu vocabulario que no está en el tweet. Ahora, este tipo de representación con un pequeño número relativo de valores distintos de cero se denomina **representación dispersa**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_12.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora echemos un vistazo más de cerca a esta representación de estos tuits. En las últimas diapositivas, te guié a través de extracciones de características para representar el tweet basado en un vocabulario y llegué a este vector. Esta representación tendría un número de características iguales al tamaño de todo su vocabulario. Esto tendría muchas características iguales a 0 para cada tweet. Con la representación dispersa, un modelo de regresión logística tendría que aprender $n+1$ parámetros, donde $n$ sería igual al tamaño de su vocabulario y se puede imaginar que para grandes tamaños de vocabulario, esto sería problemático. Tomaría una cantidad excesiva de tiempo para entrenar su modelo y mucho más tiempo del necesario para hacer predicciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Dada la siguiente lista de tweets, ¿cuántos parámetros tendría que aprender un clasificador de regresión logística con las entradas representadas como se ha comentado en esta clase? (Recuerde añadir también 1 debido al sesgo)\n",
    "\n",
    "*“I am happy because I am learning NLP”, “I hated that movie”, “I love working at DL”*\n",
    "\n",
    "- 4\n",
    "- 14\n",
    "- 42\n",
    "- 18\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: 14.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un texto, aprendió a representar este texto como un vector de dimensión $V$. Específicamente, lo hizo para un tweet y fue capaz de construir un vocabulario de la dimensión $V$. Ahora, a medida que $V$ se hace más grande y más grande, se enfrentará a ciertos problemas. En el siguiente video, aprenderá a identificar estos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative and Positive Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUEDE ACA!!\n",
    "\n",
    "Ahora aprenderemos a generar recuentos, que luego puede usar como características en su clasificador de regresión logística. Específicamente, dada una palabra, desea realizar un seguimiento del número de veces, ahí es donde aparece como la clase positiva. Dada otra palabra, desea realizar un seguimiento del número de veces que esa palabra apareció en la clase negativa. Utilizando ambos recuentos, puede extraer entidades y utilizarlas en su clasificador de regresión logística. Así que echemos un vistazo a cómo puedes hacer eso. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_16.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Es útil imaginar primero cómo se verían estas dos clases. Aquí, por ejemplo, podría tener un corpus que consta de cuatro tweets. Asociado con ese **corpus**, tendrías un conjunto de palabras únicas, tu **vocabulario**. En este ejemplo, el vocabulario tendría ocho palabras únicas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_17.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Para este ejemplo particular de análisis de sentimientos, usted tiene dos clases. Una clase asociada con el sentimiento positivo y la otra con el sentimiento negativo. Así que tomando su corpus, tendría un conjunto de dos tweets que pertenecen a la clase positiva, y los conjuntos de dos tweets que pertenecen a la clase negativa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_18.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Tomemos los conjuntos de tweets positivos. Ahora, eche un vistazo a su vocabulario. Para obtener la frecuencia positiva en cualquier palabra en su vocabulario, tendrá que contar los tiempos tal como aparece en los tweets positivos. Por ejemplo, la palabra feliz aparece una vez en el primer tweet positivo, y otra vez en el segundo tweet positivo. Así que la frecuencia positiva es dos. La tabla completa se ve así. Siéntase libre de hacer una pausa y comprobar cualquiera de sus entradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_19.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "La misma lógica se aplica para obtener la frecuencia negativa. Sin embargo, en aras de la claridad, mira algún ejemplo, la palabra am aparece dos veces en el primer tweet y otra vez en el segundo. Así que su frecuencia negativa es tres. Echa un vistazo a toda la tabla para ver las frecuencias negativas y siéntase libre de comprobar sus valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_19.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que esta es toda la tabla con las frecuencias positivas y negativas para su corpus. En la práctica, al codificar, esta tabla es un **mapa de diccionario de una clase** de palabra allí a su **frecuencia**. Por lo tanto, asigna la palabra y su clase correspondiente a la frecuencia o el número de veces que fue donde apareció en la clase. \n",
    "\n",
    "Ahora sabe cómo crear un diccionario de frecuencia, que asigna una palabra y la clase al número de veces que esa palabra apareció en la clase correspondiente. En el siguiente video, vas a usar tu diccionario de frecuencias para representar un tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction with Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bienvenido de nuevo. Antes aprendiste a codificar un tweet como vector de la dimensión V. Ahora aprenderás a codificar un tweet o específicamente representado como un vector de la dimensión 3. Al hacerlo, tendrás una velocidad mucho más rápida para tu clasificador de regresión logística, porque en lugar de aprender las características V, solo tienes que aprender tres características. Echemos un vistazo a cómo puedes hacer esto. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_24.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Acabas de ver que la frecuencia de una palabra en una clase es simplemente el número de veces que la palabra aparece en el conjunto de tweets que pertenecen a esa clase y que esta tabla es básicamente una asignación de diccionario desde pares de clases de palabras, a frecuencias, o simplemente nos dice cuántos veces cada palabra apareció en su clase correspondiente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_25.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora que ha construido su diccionario de frecuencias, puede usarlo para extraer características útiles para el análisis de sentimientos. ¿Cómo se ve una característica? Veamos el tweet arbitrario $m$. \n",
    "\n",
    "- La primera característica sería una unidad de sesgo igual a 1. \n",
    "- El segundo es la suma de las frecuencias positivas para cada palabra única en el tweet $m$. \n",
    "- El tercero es la suma de frecuencias negativas para cada palabra única en el tweet. \n",
    "\n",
    "Entonces, para extraer las entidades de esta representación, solo tendría que sumar frecuencias de palabras. Fácil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_26.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Por ejemplo, tome los siguientes tweets. Ahora veamos las frecuencias para la clase positiva de la última conferencia. Las únicas palabras del vocabulario que no aparecen en estos tweets son felices y porque. Ahora echemos un vistazo a la segunda entidad de la representación que vio en la última diapositiva. Para obtener este valor, debe sumar las frecuencias de las palabras del vocabulario que aparecen en el tweet. Al final, se obtiene un valor igual a ocho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA </b></font>\n",
    "\n",
    "Dados los siguientes tuits y frecuencias , ¿cuál es el valor de la suma de las frecuencias negativas?\n",
    "\n",
    "<figure>\n",
    " <img align=\"center\", src=\"./Imagenes/01.png\"   style=\"40%\" >\n",
    "</figure>\n",
    "\n",
    "- 11\n",
    "- 8\n",
    "- 7\n",
    "- 17\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta: 11.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_27.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora vamos a obtener el valor de la tercera característica. Es la suma de las frecuencias negativas de las palabras del vocabulario que aparecen en el tweet. Para este ejemplo, debe obtener 11 después de resumir las frecuencias subrayadas. Hasta ahora, este tweets, esta representación sería igual al vector 1, 8, 11. \n",
    "\n",
    "Ahora sabes cómo representar un tweet como vector de la dimensión 3. En el siguiente video aprenderás a preprocesar tus tweets y, como resultado, usarás esas palabras preprocesadas como palabras de tu vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola, ahora aprenderá acerca de dos conceptos principales de preprocesamiento. La primera cosa sobre la que aprenderás se llama el tallo o raiz (**stemming**) y la segunda cosa que aprenderás se llama palabras de detención (**stop words**), y específicamente aprenderás cómo usar palabras de tallo y palabras de detención para preprocesar tus textos. Echemos un vistazo a cómo puedes hacer esto. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_33.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Vamos a procesar este tweet. Primero, elimino todas las palabras que no agregan significado significativo a los tweets, también conocidos como palabras de parada y signos de puntuación. En la práctica, usted tendría que comparar su tweet con dos listas. Uno con palabras detenidas en inglés y otro con puntuación. Estas listas suelen ser mucho más grandes, pero para el propósito de este ejemplo, lo harán muy bien. Todas las palabras del tweet que también aparece en la lista de palabras detenidas deben ser eliminadas. Así que tendrías que eliminar la palabra *and*, la palabra *are*, la palabra *a*, y la palabra *at*. El tweet sin palabras de parada se ve así. Obsérvese que el significado general de la oración podría inferirse sin esfuerzo alguno. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_34.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, eliminemos todos los signos de puntuación. En este ejemplo, sólo hay signos de exclamación. El tweet sin palabras de parada y puntuación se ve así. Sin embargo, tenga en cuenta que en algunos contextos no tendrá que eliminar la puntuación. Por lo tanto, debe pensar cuidadosamente si la puntuación agrega información importante a su tarea PNL específica o no. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_35.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Los tweets y otros tipos de textos suelen tener identificadores y URL, pero estos no añaden ningún valor a la tarea de análisis de sentimientos. Vamos a eliminar estos dos manejadores y esta URL. Al final de este proceso, los tweets resultantes contienen toda la información importante relacionada con su sentimiento. *tuning GREAT AI model* es claramente un tweet positivo y un modelo suficientemente bueno debe ser capaz de clasificarlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_36.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora que el tweet del ejemplo tiene solo la información necesaria, realizaré la derivación para cada palabra. Stamming en PNL es simplemente transformar cualquier palabra en su raíz base, que se podría definir como el conjunto de caracteres que se utilizan para construir la palabra y sus derivados. \n",
    "\n",
    "Tomemos la primera palabra del ejemplo. Su tallo está *tun*, porque la adición de la letra *e*, forma la palabra *tune*. Añadiendo el sufijo *ed*, forma la palabra *tuned*, y añadiendo el sufijo *ing*, forma la palabra *tuning*. Después de realizar el tallo en su cuerpo, la palabra *tune*, *tuned* y *tuning* se reducirá al *tun* de tallo. Así que su vocabulario se reduciría significativamente cuando realice este proceso para cada palabra en el corpus. \n",
    "\n",
    "Para reducir aún más su vocabulario sin perder información valiosa, tendría que convertir a minúsculas cada una de sus palabras. Así que la palabra *GREAT*, *Great* y *great* sería tratada como la misma palabra exacta. \n",
    "\n",
    "Este es el tweet final de preproceso como una lista de palabras. \n",
    "\n",
    "Ahora que está familiarizado con las palabras de tallo y de detención, conoce los conceptos básicos del procesamiento de textos. En el siguiente vídeo, puede utilizar la función de conjunto de procesos para extraer una matriz x, que representa todos los tweets de su conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Preprocessing**\n",
    "> En el preprocesamiento hay que realizar lo siguiente:\n",
    ">\n",
    "> 1. Eliminar manejadores y URLs\n",
    "> 2. Convertir la cadena en palabras. \n",
    "> 3. Eliminar las palabras de parada como \"y, es, a, en, etc.\".\n",
    "> 4. Stemming- o convertir cada palabra en su raíz. Por ejemplo, *dancer*, *dancing*, *danced*, se convierte en *'danc'*. Puedes utilizar porter stemmer para encargarte de esto. \n",
    "> 5. Convierte todas tus palabras en minúsculas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Natural Language preprocessing**\n",
    ">\n",
    "> Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usará todo lo que aprendió para crear una matriz que corresponda a todas las características de su ejemplo de entrenamiento. Específicamente, te guiaré a través de un algoritmo que te permite generar esta matriz x. Echemos un vistazo a cómo se puede construir. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_40.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Anteriormente, vio cómo preprocesar un tweet como este para obtener una lista de palabras que contienen toda la información relevante para las tareas de análisis de sentimientos en PNL. Con esa lista de palabras, sería capaz de obtener una buena representación usando una asignación de diccionario de frecuencia. Y, por último, obtén un vector con una unidad de sesgo y dos características adicionales que almacenan la suma del número de veces que cada palabra en tus tweets de proceso aparece en tweets positivos y la suma del número de veces que aparecen en negativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/02.png\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "En la práctica, tendría que realizar este proceso en un conjunto de $m$ tweets. Así que dado un conjunto de múltiples tweets sin procesar, tendría que preprocesarlos uno por uno para obtener estos conjuntos de listas de palabras uno para cada uno de sus tweets. Y, finalmente, podría extraer entidades usando un mapeo de diccionario de frecuencias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_41.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Al final, tendría una matriz, $X$ con $m$ filas y 3 columnas donde cada fila contendría las características de cada uno de sus tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_42.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "La implementación general de este proceso es bastante fácil. \n",
    "\n",
    "- Primero, construyes el diccionario de frecuencias, \n",
    "- luego inicializa la matriz $X$ para que coincida con tu número de tweets. \n",
    "- Después de eso, querrás revisar tus conjuntos de tweets eliminando cuidadosamente las palabras de detención, stemming, la eliminación de direcciones URL y los manejadores y las minúsculas. \n",
    "- Y finalmente, extraiga las características resumiendo las frecuencias positivas y negativas de los tweets. \n",
    "\n",
    "Para la asignación de esta semana, se le han proporcionado algunas funciones de ayuda, *build_freqs* y *process_tweet*. Sin embargo, tendrá que implementar la función para extraer las características de un solo tweet. \n",
    "\n",
    "Eso era mucho código, pero al menos ahora tienes tu matriz $X$. Y en el siguiente video, te mostraremos cómo puedes alimentar esa matriz $X$ en tu clasificador de regresión logística. Echemos un vistazo a cómo puedes hacer eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Visualizing word frequencies**\n",
    ">\n",
    "> Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtendrá una visión general de la regresión logística. Anteriormente, aprendió a extraer características y ahora usará esas características extraídas para predecir si un tweet tiene un sentimiento positivo o un sentimiento negativo. La regresión logística hace uso de una función sigmoide que genera una probabilidad entre cero y uno. Echemos un vistazo a la descripción general de la regresión logística. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_46.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Sólo un resumen rápido. En el aprendizaje automático supervisado, tiene entidades de entrada y un conjunto de etiquetas. Para realizar predicciones basadas en los datos, utilice una función con algunos parámetros para asignar las entidades a las etiquetas de salida. Para obtener una asignación óptima de las entidades a las etiquetas, se minimiza la función de coste que funciona comparando qué tan cerca está $\\hat{Y}$ de salida con las verdaderas etiquetas $Y$ de los datos. Después de lo cual los parámetros se actualizan y repite el proceso hasta que se minimice el coste. Para la regresión logística, esta función $F$ es igual a la función sigmoide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_47.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "La función utilizada para clasificar en regresión logística $h$ es la función sigmoide y depende de los parámetros $\\theta$ y luego de las características del vector $X_(i)$, donde $i$ se utiliza para denotar los puntos de observación o datos. En el contexto de los tweets, ese es el iésimo tweets. \n",
    "\n",
    "Visualmente, la función sigmoide tiene esta forma y se aproxima a 0 a medida que el producto de punto de $\\theta^{T}X$, aquí (senala el eje de las absisas), se acerca menos el infinito y 1 a medida que se acerca al infinito. \n",
    "\n",
    "Para la clasificación, se necesita un umbral. Por lo general, se establece en 0.5 y este valor corresponde a un producto de punto entre $\\theta^{T}$ y $X=0$. Por lo tanto, \n",
    "\n",
    "- cada vez que el producto punto es mayor o igual que cero, la predicción es positiva, \n",
    "- y siempre que el producto punto es menor que cero, la predicción es negativa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_48.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Así que veamos un ejemplo en el contexto ya familiar de tweets y análisis de sentimientos. Mira el siguiente tweet. Después de un preprocesamiento, debe terminar con una lista como esta. Tenga en cuenta que los controladores se eliminan, todo está en minúsculas y la palabra *tuning* se reduce a su raiz, *tun*. Entonces podría extraer entidades dadas un diccionario de frecuencias y llegar a un vector similar al siguiente. Con unidades de sesgo por aquí y dos características que son la suma de frecuencias positivas y negativas de todas las palabras en sus tweets procesados. \n",
    "\n",
    "Ahora suponiendo que ya tiene un conjunto óptimo de parámetros $\\theta$, usted sería capaz de obtener el valor de la función sigmoide, en este caso, igual a 4.92, y finalmente, predecir un sentimiento positivo. Ahora que conoces la notación de regresión logística, puedes usarla para entrenar un factor de peso $\\theta$. \n",
    "\n",
    "En el siguiente video, aprenderá sobre la mecánica detrás del entrenamiento de un clasificador de regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el video anterior, aprendiste a clasificar si un tweet tiene un sentimiento positivo o negativo, usando un $\\theta$ que te he dado. En este video, aprenderás tu propia $\\theta$ desde cero, y específicamente, te guiaré a través de un algoritmo que te permite obtener tu variable $\\theta$. Veamos cómo puedes hacer esto. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_52.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Para entrenar su clasificador de regresión logística, itere hasta encontrar el conjunto de parámetros $\\theta$, que minimiza su función de costo. Supongamos que su pérdida solo depende de los parámetros $\\theta_1$ y $\\theta_2$, tendría una función de costo que se parece a esta gráfica de contorno a la izquierda. \n",
    "\n",
    "A la derecha, puede ver la evolución de la función de costo a medida que itera. \n",
    "\n",
    "- Primero, tendría que inicializar sus parámetros $\\theta$. \n",
    "- Luego actualizará su $\\theta$ en la dirección del gradiente de su función de costo. \n",
    "- Después de 100 iteraciones, estaría en este punto, después de 200 aquí, y así sucesivamente. \n",
    "- Después de muchas iteraciones, usted deriva a un punto cercano a sus costos óptimos y terminaría su entrenamiento aquí (punto naranja). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_53.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Veamos este proceso con más detalle. \n",
    "- Primero, tendría que inicializar sus parámetros vectoriales $\\theta$. \n",
    "- Luego usaría la función logística para obtener valores para cada una de sus observaciones. \n",
    "- Después de eso, podrá calcular los gradientes de su función de costo y actualizar sus parámetros. \n",
    "- Finalmente, podría calcular su costo $J$ y determinar si se necesitan más iteraciones de acuerdo con un parámetro stop o el número máximo de iteraciones. \n",
    "\n",
    "Como podría haber visto en los otros cursos, este algoritmo se conoce como descenso de gradiente. \n",
    "\n",
    "Ahora, que tiene su variable $\\theta$, desea evaluar su $\\theta$, lo que significa que desea evaluar su clasificador. Una vez que pones tu $\\theta$ en tu función sigmoide, ¿obtienes un buen clasificador o obtienes un clasificador malo? En el siguiente video, te mostraremos cómo puedes hacer esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Visualizing tweets and Logistic Regression models**\n",
    ">\n",
    "> Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tiene sus datos, utilizará estos datos para predecir nuestros nuevos puntos de datos. Por ejemplo, dado un nuevo tweet, usarás estos datos para indicar si este tweet es positivo o negativo. Al hacerlo, desea analizar si su modelo se generaliza bien o no. En este video, le mostraremos si su modelo se generaliza bien o no, y específicamente, le mostraremos cómo calcular la *precisión* de su modelo. Echemos un vistazo a cómo puedes hacer esto. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_57.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Para esto, necesitarás $X_{Val}$ y $Y_{Val}$, datos que fueron retirados durante los entrenamientos, también conocidos como los conjuntos de validación, y $\\theta$, los conjuntos de parámetros óptimos que obtuvo de la formación sobre sus datos. \n",
    "- Primero, calculará la función sigmoide para $X_{Val}$ con los parámetros $\\theta$, \n",
    "- luego evaluará si cada valor de $h(X_Val,\\theta)$ es mayor o igual a un valor de umbral, a menudo establecido en 0.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_58.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Por ejemplo, si su $h(X_{Val},\\theta)$ es igual al siguiente vector, 0.3, 0.8, 0.5, etc., hasta el número de ejemplos de su conjunto de validación, va a afirmar si cada uno de sus componentes es mayor o igual a 0.5. Entonces, \n",
    "\n",
    "- ¿es 0.3 mayor o igual a 0.5? No. Así que nuestra primera predicción es igual a 0. \n",
    "- ¿Es 0.8 mayor o igual a 0.5? Sí. Así que nuestra predicción para el segundo ejemplo es 1. \n",
    "- ¿Es 0.5 mayor o igual que 0.5? Sí. Así que nuestra tercera predicción es igual a 1, y así sucesivamente. \n",
    "\n",
    "Al final, tendrá un vector poblado con ceros y unos indicando ejemplos negativos y positivos previstos, respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_59.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Después de crear el vector de predicciones, puede calcular la precisión de su modelo sobre los conjuntos de validación. Para ello, comparará las predicciones que ha realizado con el valor verdadero para cada observación a partir de sus datos de validación. Si los valores son iguales y su predicción es correcta, obtendrá un valor de 1 y 0 de lo contrario. \n",
    "\n",
    "Por ejemplo, si su predicción fue correcta, como en este caso donde su predicción y su etiqueta son iguales a 0, su vector tendrá un valor igual a 1 en la primera posición. Por el contrario, si su segunda predicción no era correcta, debido a que su predicción y etiqueta no están de acuerdo, su vector tendrá un valor de 0 en la segunda posición, etc. \n",
    "\n",
    "Después de comparar los valores de cada predicción con las etiquetas verdaderas de su conjunto de validación, puede obtener el total de veces que sus predicciones fueron correctas resumiendo el **vector de las comparaciones**. Finalmente, dividirá ese número sobre el número total $m$ de observaciones de sus conjuntos de validación. \n",
    "\n",
    "Esta métrica proporciona una estimación de los tiempos en que su regresión logística funcionará correctamente en datos no vistos. Por lo tanto, si su precisión es igual a 0.5, significa que el 50% del tiempo, se espera que su modelo funcione bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_60.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Por ejemplo, si sus vectores $Y_{Val}$ y de predicción para cinco observaciones tienen este aspecto, \n",
    "\n",
    "- comparará cada uno de sus valores y determinará si coinciden o no. \n",
    "- Después de eso, tendrá el siguiente vector con un solo 0 en la tercera posición donde la predicción y la etiqueta no están de acuerdo. \n",
    "- A continuación, debe sumar el número de veces que sus predicciones fueron correctas y dividir ese número por el número total de observaciones en sus conjuntos de validación. Por ejemplo, se obtiene una precisión igual al 80%. \n",
    "\n",
    "Felicitaciones por terminar la primera semana de esta especialización. Aprendiste muchos conceptos esta semana. Lo primero que aprendiste es cómo preprocesar un texto. Aprendió a extraer entidades de ese texto. Aprendió a usar esas entidades extraídas y entrenar un modelo con ellas. Luego aprendiste a probar tu modelo. En el ejercicio de programación de esta semana, usted tendrá la oportunidad de implementar todos estos conceptos de los que hablamos. Siéntase libre de seguir adelante y hacer el ejercicio de programación. También hay un video opcional a finales de esta semana que cubre la intuición detrás de la función de coste para la regresión logística. Si no quieres ver ese video, siéntete libre de ir a la próxima semana, donde aprenderás sobre un nuevo algoritmo de clasificación conocido como Bayes ingenuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me alegro de volver a verte. En este vídeo opcional, usted aprenderá acerca de la intuición detrás de la función de costo de regresión logística. Específicamente, comprenderá por qué la función de costo está diseñada de esa manera. Verá lo que sucede cuando predice la etiqueta verdadera y verá lo que sucede cuando predice la etiqueta incorrecta. Vamos a sumergirnos y ver cómo se diseña esta función de costo de regresión logística. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_64.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Echemos un vistazo ahora a la ecuación de la función de costo, mientras que esto podría parecer una gran ecuación complicada, en realidad es bastante sencillo, una vez que se divide en sus componentes. \n",
    "\n",
    "- Primero, eche un vistazo a la parte izquierda de la ecuación donde encontrará una suma sobre la variable $m$, que es sólo el número de ejemplos de entrenamiento en su conjunto de entrenamiento. Esto indica que va a sumar el costo de cada ejemplo de formación. \n",
    "- Al frente, hay un $-1/m$, lo que indica que cuando se combina con la suma, esto será algún tipo de promedio. El signo menos asegura que sus costos totales siempre serán positivos, como verá claramente más adelante en este video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_65.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Dentro de los recuadros, la ecuación tiene dos términos que se suman juntos. Para considerar lo que cada uno de estos términos contribuye a la función de costo de cada ejemplo de formación, echemos un vistazo a cada uno de ellos por separado. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_66.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "El término de la izquierda es el producto de $y^{(i)}$, que es la etiqueta para cada ejemplo de entrenamiento, multiplicado por el registro de la predicción, que es la función de regresión logística aplicada a cada ejemplo de entrenamiento. Representada como $h(x^{(i)},\\theta)$.\n",
    "\n",
    "- Ahora, considere el caso cuando su etiqueta sea 0. En este caso, la función $h$ puede devolver cualquier valor, y todo el término será 0 porque 0 veces nada es solo 0. \n",
    "- ¿Qué pasa con el caso cuando tu etiqueta es 1? Si su predicción es cercana a 1, entonces el registro de su predicción estará cerca de 0, porque, como recordará, el registro de 1 es 0. Y el producto también estará cerca de 0. \n",
    "- Si su etiqueta es 1, y su predicción es cercana a 0, entonces este término explota y se acerca al infinito negativo. \n",
    "\n",
    "Intuitivamente, ahora, puede ver que este es el término relevante en su función de costo cuando su etiqueta es 1. Cuando su predicción está cerca del valor de la etiqueta, la pérdida es pequeña, y cuando la etiqueta y la predicción no están de acuerdo, el costo total aumenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_67.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora considere el término en el lado derecho de la ecuación de la función de costo, \n",
    "- en este caso, si su etiqueta es 1, entonces el término $(1-y)$ va a 0. Y por lo tanto, cualquier valor devuelto por la función de regresión logística resultará en un 0 para todo el término, porque de nuevo, 0 veces cualquier cosa es solo 0. \n",
    "- Si su etiqueta es 0, y la función de regresión logística devuelve un valor cercano a 0, entonces los productos en este término volverán a estar cerca de 0. \n",
    "- Si, por otro lado, su etiqueta es 0 y su predicción es cercana a 1, entonces el término log explotará y el término general se acercará al infinito negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_68.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "En este ejercicio se puede ver ahora que hay un término en la función de coste que es relevante cuando la etiqueta es 0, y otro que es relevante cuando la etiqueta es 1. En cada uno de estos términos, está tomando el registro de un valor entre 0 y 1, que siempre devolverá un número negativo, por lo que el signo menos se asegura de que el costo total siempre será un número positivo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./Imagenes/C1_W1_Página_69.jpg\"   style=\"width:400px;height:224px;\" >\n",
    "</figure>\n",
    "\n",
    "Ahora, echemos un vistazo a cómo se ve la función de coste para cada una de las etiquetas, 0 y 1, sobre todos los valores de predicción posibles. \n",
    "\n",
    "- Primero, vamos a ver la pérdida cuando la etiqueta sea 1. En esta gráfica (izquierda), tiene el valor de predicción en el eje horizontal y el coste asociado con un único ejemplo de entrenamiento en el eje vertical. En este caso $J(\\theta)$ simplifica a solo $-log h(x^{(i)},\\theta)$. \n",
    " * Cuando su predicción es cercana a 1, la pérdida es cercana a 0. Porque tu predicción coincide bien con la etiqueta. \n",
    " * Y cuando la predicción está cerca de 0, la pérdida se acerca al infinito, porque su predicción y la etiqueta están en desacuerdo fuertemente. \n",
    "\n",
    "- Lo contrario es cierto cuando la etiqueta es 0. En este caso $J(\\theta)$ se reduce a sólo $-log h(x^{(i)},\\theta)$. \n",
    " * Ahora, cuando su predicción está cerca de 0, la pérdida también está cerca de 0. \n",
    " * Y cuando su predicción es cercana a 1, la pérdida se acerca al infinito. \n",
    " \n",
    "Ahora entiende cómo funciona la función de coste de regresión logística. Viste lo que pasó cuando predijiste un 1 y la etiqueta verdadera era un 1. También vio lo que sucedió cuando predijo un 0, y la etiqueta verdadera era un 0. En la próxima semana, aprenderá sobre Naive Bayes, que es un tipo diferente de algoritmo de clasificación, que también le permite predecir si un tweet es positivo o negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gran trabajo al superar la primera semana del Curso 1. Ahora sabes cómo entrenar un clasificador de regresión logística. Y en la tarea de programación de esta semana, prepararás datos de texto y construirás, entrenarás y probarás tu propio modelo de regresión logística, es realmente emocionante. Hemos creado un cuestionario al final que contiene algunas de las preguntas que te pueden hacer en una entrevista sobre estos temas. La próxima semana, explorarás otro método de clasificación de PNL llamado Naive Bayes. Buena suerte con la tarea de programación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optional Logistic Regression: Gradient**\n",
    ">\n",
    ">Esta es una lectura opcional en la que explico el descenso del gradiente con más detalle. Recuerde que anteriormente le di el paso de actualización del gradiente, pero no le expliqué explícitamente lo que ocurre entre bastidores. \n",
    ">\n",
    ">La forma general de descenso de gradiente se define como:\n",
    ">\n",
    "><figure>\n",
    " <img align=\"center\", src=\"./Imagenes/03.png\"   style=\"50%\" ></figure>\n",
    ">\n",
    "> Para todos los $j$. Podemos trabajar la parte de la derivada utilizando el cálculo para obtener:\n",
    ">\n",
    "><figure>\n",
    " <img align=\"center\", src=\"./Imagenes/04.png\"   style=\"50%\" ></figure>\n",
    ">\n",
    "> Una implementación vectorizada es:\n",
    ">\n",
    "><figure>\n",
    " <img align=\"center\", src=\"./Imagenes/05.png\"   style=\"50%\" ></figure>\n",
    ">\n",
    "> *Derivada parcial de $J(θ)$*\n",
    ">\n",
    "> Primero calcule la derivada de la función sigmoidea (será útil mientras encuentra la derivada parcial de $J(θ)$):\n",
    ">\n",
    "><figure>\n",
    " <img align=\"center\", src=\"./Imagenes/06.png\"   style=\"50%\" ></figure>\n",
    ">\n",
    "> Observa que hemos calculado la derivada parcial de la función sigmoidea. Si obtuviéramos $h(x^{(i)},\\theta)$con respecto a $\\theta_j$ se obtendría $h(x^(i), \\theta)(1-h(x^{(i)}, \\theta))x^{(i)}_j$. Obsérvese que ahí utilizamos la regla de la cadena, porque multiplicamos por la derivada de $\\theta^Tx^{(i)}$ con respecto a $\\theta_j$. Ahora estamos preparados para hallar la derivada parcial resultante:\n",
    ">\n",
    "><figure>\n",
    " <img align=\"center\", src=\"./Imagenes/07.jpg\"   style=\"50%\" ></figure>\n",
    ">\n",
    "> Enhorabuena, ya conoces la derivación completa de la regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Quiz: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "Al realizar la regresión logística en el análisis de sentimientos, representaste cada tuit como un vector de unos y ceros. Sin embargo, su modelo no funcionó bien. El coste del entrenamiento era razonable, pero el coste de las pruebas no era aceptable. ¿Cuál podría ser la razón?\n",
    "\n",
    "- Las representaciones vectoriales son escasas y, por tanto, es mucho más difícil que tu modelo aprenda algo que pueda generalizar bien al conjunto de pruebas.\n",
    "- Probablemente necesites aumentar el tamaño de tu vocabulario porque parece que tienes muy pocas características.\n",
    "- La regresión logística no funciona para el análisis de sentimientos y, por tanto, deberías buscar otros modelos.\n",
    "- Las representaciones dispersas requieren una buena cantidad de tiempo de entrenamiento, por lo que deberías entrenar tu modelo durante más tiempo\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "¿Cuáles de los siguientes son ejemplos de preprocesamiento de texto?\n",
    "\n",
    "- El \"stemming\", es decir, el proceso de reducir una palabra a su raíz.\n",
    "- Las minúsculas, que es el proceso de eliminar el cambio de todas las mayúsculas a minúsculas.\n",
    "- Eliminar las palabras de parada, los signos de puntuación, los manejadores y las URL.\n",
    "- Añadir nuevas palabras para que todas las frases tengan sentido\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "La función sigmoidea se define como $h(x^{(i)},\\theta)=\\frac{1}{1+e^{-\\theta^Tx^{(i)}}}$\n",
    "¿Cuál de las siguientes opciones es verdadera?\n",
    "\n",
    "- Valores positivos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 1 y los valores negativos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a -1.\n",
    "- Los valores positivos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 1 y los valores negativos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 0.\n",
    "- Pequeños valores positivos de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 1 y los valores positivos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 0.\n",
    "- Pequeños valores positivos de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 0 y los valores negativos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a -1.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 4 </b></font>\n",
    "\n",
    "La función de coste para la regresión logística se define como $J(\\theta)=-\\frac{1}{m} \\sum_{i=1}^{m}\\left[y^{(i)} \\log h\\left(x^{(i)},\\theta\\right)\\right] +\\left[(1-y^{(i)}) \\log \\left(1-h\\left(x^{(i)},\\theta\\right)\\right)\\right]$\n",
    "\n",
    "¿Cuál de las siguientes afirmaciones es cierta sobre la función de costes anterior? Marque todas las correctas.\n",
    "\n",
    "- Cuando $y^{(i)}=1$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a $\\infty$.\n",
    "- Cuando $y^{(i)}=1$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a 0.\n",
    "- Cuando $y^{(i)}=0$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a 0.\n",
    "- Cuando $y^{(i)}=0$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a $\\infty$.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 5 </b></font>\n",
    "\n",
    "¿Para qué valor de $\\theta^Tx$ en la función sigmoidea, $h(x^{(i)},\\theta) = 0,5$?\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 6 </b></font>\n",
    "\n",
    "Seleccione todas las opciones que correspondan. Al realizar la regresión logística para el análisis de sentimientos utilizando el método enseñado en la clase de esta semana, tiene que:\n",
    "\n",
    "- Realizar el procesamiento de los datos.\n",
    "- Crear un diccionario que mapee la palabra y la clase en la que se encuentra esa palabra con el número de veces que se encuentra esa palabra en la clase.\n",
    "- Crear un diccionario que mapee la palabra y la clase en la que se encuentra esa palabra para ver si esa palabra aparece en la clase.\n",
    "- Para cada tweet, tienes que crear una **característica positiva** con la suma de los recuentos positivos de cada palabra en ese tweet. También tienes que crear una **característica negativa** con la suma de los recuentos negativos de cada palabra en ese tuit.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 7 </b></font>\n",
    "\n",
    "Al entrenar la regresión logística, tiene que realizar las siguientes operaciones en el orden deseado.\n",
    "\n",
    "- Inicializar los parámetros, obtener el gradiente, clasificar/predecir, actualizar, obtener la pérdida, repetir\n",
    "- Inicializar parámetros, clasificar/predecir, obtener gradiente, actualizar, obtener pérdida, repetir\n",
    "- Inicializar los parámetros, obtener el gradiente, actualizar, clasificar/predecir, obtener la pérdida, repetir\n",
    "- Inicializar parámetros, obtener gradiente, actualizar, obtener pérdida, clasificar/predecir, repetir\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 8 </b></font>\n",
    "\n",
    "Suponiendo que hayamos acertado en la clasificación, donde $y^{(i)} = 1$ para algún ejemplo concreto $i$. Esto significa que $h(x^{(i)}, \\theta) > 0,5h$. ¿Cuál de las siguientes afirmaciones debe cumplirse?\n",
    "\n",
    "- Nuestra predicción, $h(x^{(i)},\\theta)$ para este ejemplo de entrenamiento específico es exactamente igual a su etiqueta correspondiente $y^{(i)}$.\n",
    "- Nuestra predicción, $h(x^{(i)},\\theta)$ para este ejemplo de entrenamiento específico es menor que $(1-y^{(i)}$.\n",
    "- Nuestra predicción, $h(x^{(i)},\\theta)$ para este ejemplo de entrenamiento específico es menor que $(1-h(x^{(i)}, \\theta))$.\n",
    "- Nuestra predicción, $h(x^{(i)},\\theta)$ para este ejemplo de entrenamiento específico es mayor que $(1 - h(x^{(i)}, \\theta))$.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 9 </b></font>\n",
    "\n",
    "¿Cuál es el propósito del descenso de gradiente? Selecciona todas las que correspondan.\n",
    "\n",
    "- El descenso gradual nos permite aprender los parámetros $\\theta$ en la regresión logística para minimizar la función de pérdida $J$.\n",
    "- El descenso gradual nos permite aprender los parámetros $\\theta$ en la regresión logística para maximizar la función de pérdida $J$.\n",
    "- El descenso gradual, *grad_theta* nos permite actualizar los parámetros $\\theta$ calculando $\\theta = \\theta - \\alpha * grad\\_theta$\n",
    "- El descenso por gradiente, *grad_theta* nos permite actualizar los parámetros $\\theta$ computando $\\theta = \\theta + \\alpha * grad_theta$\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 10 </b></font>\n",
    "\n",
    "¿Cuál es una buena métrica que permite decidir cuándo dejar de entrenar/intentar obtener un buen modelo? Seleccione todas las que correspondan.\n",
    "\n",
    "- Cuando la precisión es lo suficientemente buena en el conjunto de pruebas.\n",
    "- Cuando la precisión es lo suficientemente buena en el conjunto de entrenamiento.\n",
    "- Cuando se representa el coste frente al número de iteraciones y se ve que la pérdida converge (es decir, ya no cambia tanto).\n",
    "- Cuando $\\alpha$, su tamaño de paso no es ni demasiado pequeño ni demasiado grande.\n",
    "\n",
    "\n",
    "***\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "**Respuesta 1**: Las representaciones vectoriales son escasas y, por tanto, es mucho más difícil que tu modelo aprenda algo que pueda generalizar bien al conjunto de pruebas.\n",
    "    \n",
    "**Respuesta 2**: \n",
    "\n",
    "- El \"stemming\", es decir, el proceso de reducir una palabra a su raíz.\n",
    "- Las minúsculas, que es el proceso de eliminar el cambio de todas las mayúsculas a minúsculas.\n",
    "- Eliminar las palabras de parada, los signos de puntuación, los manejadores y las URL.\n",
    "\n",
    "**Respuesta 3**: Los valores positivos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 1 y los valores negativos grandes de $\\theta^Tx^{(i)}$ harán que $h(x^{(i)},\\theta)$ se acerque a 0.\n",
    "    \n",
    "**Respuesta 4**: \n",
    "    \n",
    "- Cuando $y^{(i)}=1$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a $\\infty$.\n",
    "- Cuando $y^{(i)}=0$, como $h(x^{(i)},\\theta)$ se acerca a 0, la función de coste se aproxima a 0.\n",
    "    \n",
    "**Respuesta 5**: 0.\n",
    "    \n",
    "**Respuesta 6**: \n",
    "    \n",
    "- Realizar el procesamiento de los datos.\n",
    "- Crear un diccionario que mapee la palabra y la clase en la que se encuentra esa palabra con el número de veces que se encuentra esa palabra en la clase.\n",
    "- Para cada tweet, tienes que crear una **característica positiva** con la suma de los recuentos positivos de cada palabra en ese tweet. También tienes que crear una **característica negativa** con la suma de los recuentos negativos de cada palabra en ese tuit.\n",
    "    \n",
    "**Respuesta 7**: Inicializar parámetros, clasificar/predecir, obtener gradiente, actualizar, obtener pérdida, repetir.\n",
    "    \n",
    "**Respuesta 8**: Nuestra predicción, $h(x^{(i)},\\theta)$ para este ejemplo de entrenamiento específico es mayor que $(1 - h(x^{(i)}, \\theta))$.\n",
    "    \n",
    "**Respuesta 9**: \n",
    "  \n",
    "- El descenso gradual nos permite aprender los parámetros $\\theta$ en la regresión logística para minimizar la función de pérdida $J$.\n",
    "- El descenso gradual, *grad_theta* nos permite actualizar los parámetros $\\theta$ calculando $\\theta = \\theta - \\alpha * grad\\_theta$\n",
    "    \n",
    "**Respuesta 10**: \n",
    "    \n",
    "- Cuando la precisión es lo suficientemente buena en el conjunto de pruebas.\n",
    "- Cuando se representa el coste frente al número de iteraciones y se ve que la pérdida converge (es decir, ya no cambia tanto).\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Assignment: Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
