{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1: Regresión logística\n",
    "Bienvenidos a la primera semana de esta especialización. Aprenderá sobre regresión logística. Concretamente, implementará regresión logística para el análisis de sentimientos en los tweets. Dado un tweet, decidirás si tiene un sentimiento positivo o negativo. Específicamente usted:\n",
    "\n",
    "* Aprenda a extraer características para regresión logística dado algo de texto\n",
    "* Implementar regresión logística desde cero\n",
    "* Aplicar regresión logística en una tarea de procesamiento de lenguaje natural\n",
    "* Prueba usando tu regresión logística\n",
    "* Realizar análisis de errores\n",
    "\n",
    "Usaremos un conjunto de datos de tweets. Con suerte, obtendrá una precisión superior al 99%.\n",
    "Ejecute la celda a continuación para cargar los paquetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/emi/Escritorio/Coursera/coursera npl/1 - Natural Language Processing with Classification and Vector Spaces/Week 1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones importadas\n",
    "\n",
    "Descarga los datos necesarios para esta tarea. Consulte la [documentación para el conjunto de datos twitter_samples] (http://www.nltk.org/howto/twitter.html).\n",
    "\n",
    "* twitter_samples: si está ejecutando este cuaderno en su computadora local, deberá descargarlo usando:\n",
    "`` Python\n",
    "nltk.download ('twitter_samples')\n",
    "''\n",
    "\n",
    "* palabras vacías: si está ejecutando este cuaderno en su computadora local, deberá descargarlo usando:\n",
    "`` pitón\n",
    "nltk.download ('palabras vacías')\n",
    "''\n",
    "\n",
    "#### Importa algunas funciones auxiliares que proporcionamos en el archivo utils.py:\n",
    "* `process_tweet ()`: limpia el texto, lo tokeniza en palabras separadas, elimina las palabras vacías y convierte las palabras en raíces.\n",
    "* `build_freqs ()`: esto cuenta la frecuencia con la que una palabra en el 'corpus' (el conjunto completo de tweets) se asoció con una etiqueta positiva '1' o una etiqueta negativa '0', luego construye el diccionario `freqs`, donde cada clave es una tupla (palabra, etiqueta) y el valor es el recuento de su frecuencia dentro del corpus de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agregue la carpeta, tmp2, desde nuestro espacio de trabajo local que contiene archivos corpora descargados previamente a la ruta de datos de nltk\n",
    "# esto permite la importación de estos archivos sin descargarlos nuevamente cuando actualizamos nuestro espacio de trabajo\n",
    "\n",
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepara los datos\n",
    "* El `twitter_samples` contiene subconjuntos de 5,000 tweets positivos, 5,000 tweets negativos y el conjunto completo de 10,000 tweets.\n",
    "     * Si utiliza los tres conjuntos de datos, introduciríamos duplicados de los tweets positivos y negativos.\n",
    "     * Seleccionará solo los cinco mil tweets positivos y los cinco mil tweets negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccione el conjunto de tweets positivos y negativos\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train test split: 20% will be in the test set, and 80% in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir los datos en dos partes, una para entrenamiento y otra para pruebas (conjunto de validación)\n",
    "test_pos  = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg  = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x  = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the numpy array of positive labels and negative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinar etiquetas positivas y negativas\n",
    "train_y = np.append( np.ones( (len(train_pos), 1) ), np.zeros( (len(train_neg), 1) ) , axis = 0)\n",
    "test_y  = np.append( np.ones( (len(test_pos) , 1) ), np.zeros( (len(test_neg) , 1) ) , axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape  = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imprima el tren de formas y los conjuntos de prueba\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape  = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cree el diccionario de frecuencias usando la función `build_freqs ()` importada.\n",
    "     * Recomendamos encarecidamente que abra `utils.py` y lea la función` build_freqs () `para comprender lo que está haciendo.\n",
    "     * Para ver el directorio de archivos, vaya al menú y haga clic en Archivo-> Abrir.\n",
    "\n",
    "```Python\n",
    "    for y,tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "```\n",
    "* Observe cómo el bucle for externo pasa por cada tweet, y el bucle for interno recorre cada palabra en un tweet.\n",
    "* El diccionario `freqs` es el diccionario de frecuencias que se está construyendo.\n",
    "* La clave es la tupla (palabra, etiqueta), como (\"feliz\", 1) o (\"feliz\", 0). El valor almacenado para cada clave es el recuento de cuántas veces la palabra \"feliz\" se asoció con una etiqueta positiva, o cuántas veces \"feliz\" se asoció con una etiqueta negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs)  = 11340\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs)  = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "type(freqs) = <class 'dict'>\n",
    "len(freqs) = 11346\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuit de proceso\n",
    "La función dada \"process_tweet ()\" convierte el tweet en palabras individuales, elimina las palabras vacías y aplica la derivación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "# test the function below\n",
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "This is an example of a positive tweet: \n",
    " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
    " \n",
    "This is an example of the processes version: \n",
    " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Regresión logística\n",
    "\n",
    "\n",
    "### Parte 1.1: Sigmoide\n",
    "Aprenderá a utilizar la regresión logística para la clasificación de texto.\n",
    "* La función sigmoidea se define como:\n",
    "\n",
    "$$ h (z) = \\frac {1} {1+ \\exp ^ {- z}} \\tag {1} $$\n",
    "\n",
    "Asigna la entrada 'z' a un valor que varía entre 0 y 1, por lo que puede tratarse como una probabilidad.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='../tmp2/sigmoid_plot.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /> Figure 1 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instrucciones: Implementar la función sigmoidea\n",
    "* Querrá que esta función funcione si z es un escalar así como si es una matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html\" > numpy.exp </a> </li>\n",
    "\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def sigmoid(z): \n",
    "    '''\n",
    "    entrada: z: es la entrada (puede ser un escalar o una matriz) \n",
    "    Salida:  sigmoide de z\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística: regresión y sigmoide\n",
    "\n",
    "La regresión logística toma una regresión lineal regular y aplica un sigmoide a la salida de la regresión lineal.\n",
    "\n",
    "Regresión:\n",
    "$$ z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N $$\n",
    "Tenga en cuenta que los valores $ \\theta $ son \"pesos\". Si realizó la especialización en aprendizaje profundo, nos referimos a los pesos con el vector `w`. En este curso, usamos una variable diferente $ \\theta $ para referirnos a los pesos.\n",
    "\n",
    "Regresión logística\n",
    "$$ h (z) = \\frac {1} {1+ \\exp ^ {- z}} $$\n",
    "$$ z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N $$\n",
    "Nos referiremos a 'z' como los 'logits'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1.2 Función de costo y gradiente\n",
    "\n",
    "La función de costo utilizada para la regresión logística es el promedio de la pérdida de registro en todos los ejemplos de entrenamiento:\n",
    "\n",
    "$$ J (\\theta) = - \\frac {1} {m} \\sum_ {i = 1} ^ my ^ {(i)} \\log (h (z (\\theta) ^ {(i)})) + (1-y ^ {(i)}) \\log (1-h (z (\\theta) ^ {(i)})) \\tag {5} $$\n",
    "* $ m $ es la cantidad de ejemplos de entrenamiento\n",
    "* $ y ^ {(i)} $ es la etiqueta real del i-ésimo ejemplo de entrenamiento.\n",
    "* $ h (z (\\theta) ^ {(i)}) $ es la predicción del modelo para el i-ésimo ejemplo de entrenamiento.\n",
    "\n",
    "La función de pérdida para un solo ejemplo de entrenamiento es\n",
    "$$ Pérdida = -1 \\times \\left (y ^ {(i)} \\log (h (z (\\theta) ^ {(i)})) + (1-y ^ {(i)}) \\log (1-h (z (\\theta) ^ {(i)})) \\right) $$\n",
    "\n",
    "* Todos los valores de $ h $ están entre 0 y 1, por lo que los registros serán negativos. Ésa es la razón del factor -1 aplicado a la suma de los dos términos de pérdida.\n",
    "* Tenga en cuenta que cuando el modelo predice 1 ($ h (z (\\theta)) = 1 $) y la etiqueta $ y $ también es 1, la pérdida para ese ejemplo de entrenamiento es 0.\n",
    "* De manera similar, cuando el modelo predice 0 ($ h (z (\\theta)) = 0 $) y la etiqueta real también es 0, la pérdida para ese ejemplo de entrenamiento es 0.\n",
    "* Sin embargo, cuando la predicción del modelo está cerca de 1 ($ h (z (\\theta)) = 0.9999 $) y la etiqueta es 0, el segundo término de la pérdida logarítmica se convierte en un número negativo grande, que luego se multiplica por el factor general de -1 para convertirlo en un valor de pérdida positivo. $ -1 \\times (1 - 0) \\times log (1 - 0.9999) \\approx 9.2 $ Cuanto más se acerque la predicción del modelo a 1, mayor será la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifique que cuando el modelo predice cerca de 1, pero la etiqueta real es 0, la pérdida is a large positive value\n",
    "-1 * (1 - 0) * np.log(1 - 0.9999) # la perdida es aproximadamente a  9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Del mismo modo, si el modelo predice cerca de 0 ($ h (z) = 0.0001 $) pero la etiqueta real es 1, el primer término en la función de pérdida se convierte en un número grande: $ -1 \\times log (0.0001) \\approx 9,2 $. Cuanto más cerca de cero esté la predicción, mayor será la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifique que cuando el modelo predice cerca de 0 pero la etiqueta real es 1, la pérdida es un valor positivo grande\n",
    "-1 * np.log(0.0001) # la perdida es aproximadamente a  9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actualizar los pesos\n",
    "\n",
    "Para actualizar su vector de peso $ \\theta $, aplicará el descenso de gradiente para mejorar iterativamente las predicciones de su modelo.\n",
    "El gradiente de la función de costo $ J $ con respecto a uno de los pesos $ \\theta_j $ es:\n",
    "\n",
    "$$ \\nabla _ {\\theta_j} J (\\theta) = \\frac {1} {m} \\sum_ {i = 1} ^ m (h ^ {(i)} - y ^ {(i)}) x_j \\tag {5} $$\n",
    "* 'i' es el índice de todos los ejemplos de entrenamiento 'm'.\n",
    "* 'j' es el índice del peso $ \\theta_j $, entonces $ x_j $ es la característica asociada con el peso $  theta_j $\n",
    "\n",
    "* Para actualizar el peso $ \\theta_j $, lo ajustamos restando una fracción del gradiente determinado por $ \\alpha $:\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\times \\nabla _ {\\theta_j} J (\\theta) $$\n",
    "* La tasa de aprendizaje $ \\alpha $ es un valor que elegimos para controlar qué tan grande será una sola actualización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones: Implementar la función de descenso de gradiente\n",
    "* El número de iteraciones `num_iters` es el número de veces que usarás todo el conjunto de entrenamiento.\n",
    "* Para cada iteración, calculará la función de costo usando todos los ejemplos de entrenamiento (hay ejemplos de entrenamiento `m`), y para todas las funciones.\n",
    "* En lugar de actualizar un solo peso $\\theta_i $ a la vez, podemos actualizar todos los pesos en el vector de columna:\n",
    "* $ \\mathbf {\\theta} = \\begin {pmatrix} \n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\\n",
    "\\theta_2\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "\\theta_n\n",
    "\\end {pmatrix} $\n",
    "* $ \\mathbf {\\theta} $ tiene dimensiones (n + 1, 1), donde 'n' es el número de características, y hay un elemento más para el término de sesgo $ \\theta_0 $ (tenga en cuenta que el valor de característica correspondiente $ \\mathbf {x_0} $ es 1).\n",
    "* Los 'logits', 'z', se calculan multiplicando la matriz de características 'x' con el vector de peso 'theta'. $ z = \\mathbf {x} \\mathbf {\\theta} $\n",
    "    * $ \\mathbf {x} $ tiene dimensiones (m, n + 1)\n",
    "    * $ \\mathbf {\\theta} $: tiene dimensiones (n + 1, 1)\n",
    "    * $ \\mathbf {z} $: tiene dimensiones (m, 1)\n",
    "* La predicción 'h', se calcula aplicando el sigmoide a cada elemento en 'z': $ h (z) = sigmoide (z) $, y tiene dimensiones (m, 1).\n",
    "* La función de costo $ J $ se calcula tomando el producto escalar de los vectores 'y' y 'log (h)'. Dado que tanto 'y' como 'h' son vectores columna (m, 1), transponga el vector a la izquierda, de modo que la multiplicación matricial de un vector fila con un vector columna realice el producto escalar.\n",
    "$$ J = \\frac {-1} {m} \\times \\left (\\mathbf {y} ^ T \\cdot log (\\mathbf {h}) + \\mathbf {(1-y)} ^ T \\cdot log (\\mathbf {1-h}) \\right) $$\n",
    "* La actualización de theta también está vectorizada. Debido a que las dimensiones de $ \\mathbf {x} $ son (m, n + 1), y tanto $ \\mathbf {h} $ como $ \\mathbf {y} $ son (m, 1), necesitamos transponer $ \\mathbf {x} $ y colóquelo a la izquierda para realizar la multiplicación de matrices, que luego da la respuesta (n + 1, 1) que necesitamos:\n",
    "$$ \\mathbf {\\theta} = \\mathbf {\\theta} - \\frac {\\alpha} {m} \\times \\left (\\mathbf {x} ^ T \\cdot \\left (\\mathbf {hy} \\right) \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>use np.dot para la multiplicación de matrices. </li>\n",
    "     <li> Para asegurarse de que la fracción -1 / m sea un valor decimal, utilice el numerador o el denominador (o ambos), como `float (1)`, o escriba `1` para la versión flotante de 1.</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Ientrada:\n",
    "         x: matriz de características que es (m, n + 1)\n",
    "         y: etiquetas correspondientes de la matriz de entrada x, dimensiones (m, 1)\n",
    "         theta: vector de peso de dimensión (n + 1,1)\n",
    "         alfa: tasa de aprendizaje\n",
    "         num_iters: número de iteraciones para las que desea entrenar su modelo\n",
    "     Salida:\n",
    "         J: el costo final\n",
    "         theta: tu vector de peso final\n",
    "     Sugerencia: es posible que desee imprimir el costo para asegurarse de que esté bajando.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # obtener 'm', el número de filas en la matriz x\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # obtener z, el producto escalar de xy theta\n",
    "        z = np.dot( x , theta )\n",
    "        \n",
    "        # obtener el sigmoide de h\n",
    "        h = sigmoid( z )\n",
    "        \n",
    "        # calcular la función de costo\n",
    "        # tenga en cuenta que también podemos usar np.array.transpose () en lugar de np.array.T\n",
    "        # np.array.T solo hace que el código sea un poco más legible :)\n",
    "        J = - 1. / m * ( np.dot( y.T , np.log( h ) ) + np.dot( ( 1 - y ).T , np.log( 1 - h ) ))                                                    \n",
    "\n",
    "        # actualizar los pesos theta\n",
    "        theta = theta - (alpha / m) * np.dot( x.T , ( h - y ) )\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Verifica la función\n",
    "# Construya un caso de prueba sintético usando numerosas funciones PRNG\n",
    "np.random.seed(1)\n",
    "# La entrada X es 10 x 3 con unos para los términos de sesgo\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Las etiquetas Y son 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Aplicar descenso de gradiente\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "The cost after training is 0.67094970.\n",
    "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Extraer las características\n",
    "\n",
    "* Dada una lista de tweets, extrae las características y guárdalas en una matriz. Extraerás dos características.\n",
    "     * La primera característica es la cantidad de palabras positivas en un tweet.\n",
    "     * La segunda característica es la cantidad de palabras negativas en un tweet.\n",
    "* Luego entrene su clasificador de regresión logística en estas características.\n",
    "* Pruebe el clasificador en un conjunto de validación.\n",
    "\n",
    "### Instrucciones: Implementar la función extract_features.\n",
    "* Esta función admite un solo tweet.\n",
    "* Procese el tweet usando la función `process_tweet ()` importada y guarde la lista de palabras del tweet.\n",
    "* Recorra cada palabra en la lista de palabras procesadas\n",
    "     * Para cada palabra, consulte el diccionario `freqs` para el recuento cuando esa palabra tiene una etiqueta positiva '1'. (Busque la clave (palabra, 1.0)\n",
    "     * Haga lo mismo para el recuento para cuando la palabra esté asociada con la etiqueta negativa '0'. (Busque la clave (palabra, 0.0).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Asegúrese de manejar los casos en los que la clave (palabra, etiqueta) no se encuentra en el diccionario. </li>\n",
    "     <li> Busque en la web sugerencias sobre el uso del método `.get ()` de un diccionario de Python. Aquí hay un <a href=\"https://www.programiz.com/python-programming/methods/dictionary/get\" > example </a> </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Entrada:\n",
    "         tweet: una lista de palabras para un tweet\n",
    "         freqs: un diccionario correspondiente a las frecuencias de cada tupla (palabra, etiqueta)\n",
    "     Salida:\n",
    "         x: un vector de características de dimensión (1,3)\n",
    "    '''\n",
    "    # process_tweet tokeniza, deriva y elimina palabras vacías\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elementos en forma de vector de 1 x 3\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    # el término de sesgo se establece en 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # recorrer cada palabra en la lista de palabras\n",
    "    for word in word_l:\n",
    "        \n",
    "        # incrementar el recuento de palabras para la etiqueta positiva 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # incrementar el recuento de palabras para la etiqueta negativa 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 3.02e+03 6.10e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Check your function\n",
    "\n",
    "# test 1\n",
    "# test on training data\n",
    "tmp1 = extract_features(train_x[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "[[1.00e+00 3.02e+03 6.10e+01]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "# check for when the words are not in the freqs dictionary\n",
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "[[1. 0. 0.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Entrenamiento de su modelo\n",
    "\n",
    "Para entrenar el modelo:\n",
    "* Apile las características de todos los ejemplos de entrenamiento en una matriz `X`.\n",
    "* Llame a `gradientDescent`, que ha implementado anteriormente.\n",
    "\n",
    "Esta sección se le proporciona. Léalo para comprenderlo y ejecutar la celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.24216477.\n",
      "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "The cost after training is 0.24216529.\n",
    "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4: Pruebe su regresión logística\n",
    "\n",
    "Es hora de que pruebe su función de regresión logística en alguna entrada nueva que su modelo no haya visto antes.\n",
    "\n",
    "#### Instrucciones: Escribe `predict_tweet`\n",
    "Predice si un tweet es positivo o negativo.\n",
    "\n",
    "* Dado un tweet, procéselo y luego extraiga las funciones.\n",
    "* Aplique los pesos aprendidos del modelo en las características para obtener los logits.\n",
    "* Aplicar el sigmoide a los logits para obtener la predicción (un valor entre 0 y 1).\n",
    "\n",
    "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "   Entrada:\n",
    "         tuit: una cuerda\n",
    "         freqs: un diccionario correspondiente a las frecuencias de cada tupla (palabra, etiqueta)\n",
    "         theta: (3,1) vector de pesos\n",
    "     Salida:\n",
    "         y_pred: la probabilidad de que un tweet sea positivo o negativo\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.518580\n",
      "I am bad -> 0.494339\n",
      "this movie should have been great. -> 0.515331\n",
      "great -> 0.515464\n",
      "great great -> 0.530898\n",
      "great great great -> 0.546273\n",
      "great great great great -> 0.561561\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n",
    "    #print( '{:<100} -> {}'.format(tweet,predict_tweet(tweet, freqs, theta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "```\n",
    "I am happy -> 0.518580\n",
    "I am bad -> 0.494339\n",
    "this movie should have been great. -> 0.515331\n",
    "great -> 0.515464\n",
    "great great -> 0.530898\n",
    "great great great -> 0.546273\n",
    "great great great great -> 0.561561\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81636482]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to check the sentiment of your own tweet below\n",
    "my_tweet = 'I am learning :)'\n",
    "predict_tweet(my_tweet, freqs, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifique el rendimiento usando el equipo de prueba\n",
    "Después de entrenar su modelo con el conjunto de entrenamiento anterior, verifique cómo podría funcionar su modelo con datos reales no vistos probándolo con el conjunto de prueba.\n",
    "\n",
    "#### Instrucciones: Implementar `test_logistic_regression`\n",
    "* Dados los datos de prueba y los pesos de su modelo entrenado, calcule la precisión de su modelo de regresión logística.\n",
    "* Utilice su función `predict_tweet ()` para hacer predicciones en cada tweet en el conjunto de prueba.\n",
    "* Si la predicción es> 0,5, establezca la clasificación del modelo `y_hat` en 1; de lo contrario, establezca la clasificación del modelo` y_hat` en 0.\n",
    "* Una predicción es precisa cuando `y_hat` es igual a` test_y`. Resuma todas las instancias en las que sean iguales y divida por \"m\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use np.asarray() to convert a list to a numpy array</li>\n",
    "    <li>Use np.squeeze() to make an (m,1) dimensional array into an (m,) array </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    \"\"\"\n",
    "    Entrada:\n",
    "         test_x: una lista de tweets\n",
    "         test_y: (m, 1) vector con las etiquetas correspondientes para la lista de tweets\n",
    "         freqs: un diccionario con la frecuencia de cada par (o tupla)\n",
    "         theta: vector de peso de dimensión (3, 1)\n",
    "     Salida:\n",
    "         precisión: (# de tweets clasificados correctamente) / (# total de tweets)\n",
    "    \"\"\"\n",
    "    \n",
    "    # la lista para almacenar predicciones\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # obtener la predicción de la etiqueta para el tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # agregar 1.0 a la lista\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # añadir 0 a la lista\n",
    "            y_hat.append(0)\n",
    "\n",
    "    # Con la implementación anterior, y_hat es una lista, pero test_y es (m, 1) matriz\n",
    "    # convierta ambos en arreglos unidimensionales para compararlos usando el operador '=='\n",
    "    \n",
    "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9950\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output: \n",
    "```0.9950```  \n",
    "Pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5: Análisis de errores\n",
    "\n",
    "En esta parte, verá algunos tweets que su modelo clasificó incorrectamente. ¿Por qué crees que ocurrieron las clasificaciones erróneas? Específicamente, ¿qué tipo de tweets clasifica erróneamente su modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "EL TWEET ES: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
      "EL TWEET PROSESADO ES: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n",
      "\n",
      "1\t0.49996897\tb'truli later move know queen bee upward bound movingonup'\n",
      "\n",
      "EL TWEET ES: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "EL TWEET PROSESADO ES: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "\n",
      "1\t0.48650628\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "\n",
      "EL TWEET ES: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "EL TWEET PROSESADO ES: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "\n",
      "1\t0.48370676\tb\"i'm play brain dot braindot\"\n",
      "\n",
      "EL TWEET ES: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "EL TWEET PROSESADO ES: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "\n",
      "1\t0.48370676\tb\"i'm play brain dot braindot\"\n",
      "\n",
      "EL TWEET ES: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "EL TWEET PROSESADO ES: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "\n",
      "1\t0.48370676\tb\"i'm play brain dot braindot\"\n",
      "\n",
      "EL TWEET ES: off to the park to get some sunlight : )\n",
      "EL TWEET PROSESADO ES: ['park', 'get', 'sunlight']\n",
      "\n",
      "1\t0.49578773\tb'park get sunlight'\n",
      "\n",
      "EL TWEET ES: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "EL TWEET PROSESADO ES: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "\n",
      "1\t0.48199817\tb'uff itna miss karhi thi ap :p'\n",
      "\n",
      "EL TWEET ES: @phenomyoutube u probs had more fun with david than me : (\n",
      "EL TWEET PROSESADO ES: ['u', 'prob', 'fun', 'david']\n",
      "\n",
      "0\t0.50020361\tb'u prob fun david'\n",
      "\n",
      "EL TWEET ES: pats jay : (\n",
      "EL TWEET PROSESADO ES: ['pat', 'jay']\n",
      "\n",
      "0\t0.50039294\tb'pat jay'\n",
      "\n",
      "EL TWEET ES: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "EL TWEET PROSESADO ES: ['belov', 'grandmoth']\n",
      "\n",
      "0\t0.50000002\tb'belov grandmoth'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict_tweet(tweet, freqs, theta) \n",
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('EL TWEET ES:', x)\n",
    "        print('EL TWEET PROSESADO ES:', process_tweet(x))\n",
    "        print()\n",
    "        print('%d\\t%0.8f\\t%s\\n' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this specialization, we will see how we can use deep learning to improve the prediction performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Predict with your own tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
      "[[0.48139087]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "806ffbd34e7df5bf411885353da832d7b539620a21d62174860bf511972b526a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
