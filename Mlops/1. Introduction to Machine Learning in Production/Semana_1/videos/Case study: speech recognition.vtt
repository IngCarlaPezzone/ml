WEBVTT

1
00:00:00.340 --> 00:00:04.320
Uno de los éxitos del aprendizaje profundo
ha sido el reconocimiento del habla.

2
00:00:04.320 --> 00:00:08.566
El aprendizaje profundo ha hecho que el reconocimiento del habla
mucho más preciso que tal vez

3
00:00:08.566 --> 00:00:09.420
hace una década.

4
00:00:09.420 --> 00:00:13.963
Y esto está permitiendo a muchos de nosotros
utilizar el reconocimiento de voz en nuestros

5
00:00:13.963 --> 00:00:18.370
altavoces de nuestros smartphones para
búsqueda por voz y en otro contexto.

6
00:00:18.370 --> 00:00:21.855
Es posible que hayas oído de vez en cuando
sobre la investigación

7
00:00:21.855 --> 00:00:25.440
trabajo que se realiza para construir
mejores modelos de habla.

8
00:00:25.440 --> 00:00:30.216
Pero ¿qué más se necesita para realmente
construir un valioso despliegue de producción

9
00:00:30.216 --> 00:00:32.130
sistema de reconocimiento de voz.

10
00:00:32.130 --> 00:00:36.417
Utilicemos el ciclo de vida del proyecto de aprendizaje automático
para establecer un sistema de reconocimiento de voz

11
00:00:36.417 --> 00:00:41.327
ejemplo de reconocimiento de voz para que puedas entender
todos los pasos necesarios para construir y

12
00:00:41.327 --> 00:00:43.240
desplegar un sistema de este tipo.

13
00:00:43.240 --> 00:00:48.332
He trabajado en sistemas de reconocimiento de voz
en un contexto comercial antes y

14
00:00:48.332 --> 00:00:52.957
por lo que el primer paso de eso fue el alcance
para definir primero el proyecto y

15
00:00:52.957 --> 00:00:56.349
tomar la decisión de
trabajar en el reconocimiento del habla,

16
00:00:56.349 --> 00:00:59.761
digamos para la búsqueda por voz como parte
de la definición del proyecto.

17
00:00:59.761 --> 00:01:02.887
Eso también te anima a
para tratar de estimar o

18
00:01:02.887 --> 00:01:06.140
al menos estimar las métricas clave.

19
00:01:06.140 --> 00:01:08.460
Esto dependerá mucho del problema.

20
00:01:08.460 --> 00:01:12.760
Casi todas las aplicaciones tendrán su
propio conjunto de objetivos y métricas.

21
00:01:12.760 --> 00:01:17.261
Pero en el caso del reconocimiento de voz,
algunas cosas que me importaban como

22
00:01:17.261 --> 00:01:20.280
la precisión del sistema de
la latencia del sistema?

23
00:01:20.280 --> 00:01:23.340
¿Cuánto tiempo tarda el sistema
en transcribir el habla y

24
00:01:23.340 --> 00:01:24.780
¿cuál es el rendimiento?

25
00:01:24.780 --> 00:01:27.740
Cuántas consultas por segundo manejamos.

26
00:01:27.740 --> 00:01:33.110
Y luego, si es posible, también podría
tratar de estimar los recursos necesarios.

27
00:01:33.110 --> 00:01:37.451
Así que cuánto tiempo, cuánto cálculo
cuánto presupuesto, así como la línea de tiempo.

28
00:01:37.451 --> 00:01:40.440
¿Cuánto tiempo se necesita para
llevar a cabo este proyecto?

29
00:01:40.440 --> 00:01:45.660
Tendré mucho más que decir sobre
el alcance en la tercera semana de este curso.

30
00:01:45.660 --> 00:01:51.340
Así que volveremos a este tema y
y lo describiremos con más detalle.

31
00:01:51.340 --> 00:01:55.214
El siguiente paso es la etapa de datos donde
hay que definir los datos y

32
00:01:55.214 --> 00:01:59.140
establecer una línea de base y
también etiquetar y organizar los datos.

33
00:01:59.140 --> 00:02:00.650
¿Qué hay de difícil en esto?

34
00:02:00.650 --> 00:02:05.328
Uno de los retos de los sistemas prácticos de
sistemas de reconocimiento del habla es

35
00:02:05.328 --> 00:02:10.251
la etiqueta de los datos de forma consistente,
Aquí hay un clip de audio de un típico

36
00:02:10.251 --> 00:02:15.011
grabación que puedes obtener si estás
trabajando en el reconocimiento de voz para

37
00:02:15.011 --> 00:02:20.040
búsqueda por voz, déjame reproducir este clip de audio,

38
00:02:20.040 --> 00:02:24.031
Y la pregunta es dado este
clip de audio que acaba de escuchar

39
00:02:24.031 --> 00:02:28.340
"Um hoy es si", ¿quieres
transcribirlo así?

40
00:02:28.340 --> 00:02:30.781
Lo que si tienes
transcriptor etiquetar los datos,

41
00:02:30.781 --> 00:02:33.350
esta sería una transcripción
transcripción razonable.

42
00:02:33.350 --> 00:02:36.590
¿O querrías
transcribirlo así?

43
00:02:36.590 --> 00:02:39.938
Que también es una transcripción
razonable transcripción o

44
00:02:39.938 --> 00:02:44.777
si el transcriptor dijera, bueno
a menudo hay mucho ruido y audio,

45
00:02:44.777 --> 00:02:49.119
ya sabes, tal vez hay un sonido de
un cónclave, algo se cayó y

46
00:02:49.119 --> 00:02:51.421
no quieres transcribir el ruido.

47
00:02:51.421 --> 00:02:56.030
Así que tal vez es sólo el ruido y
deberías transcribirlo así.

48
00:02:56.030 --> 00:03:01.600
Resulta que cualquiera de estas tres formas
de transcribir el audio está bien.

49
00:03:01.600 --> 00:03:04.525
Probablemente preferiría la primera o la segunda
la primera o la segunda, no la tercera.

50
00:03:04.525 --> 00:03:08.526
Pero lo que perjudica el rendimiento del
algoritmo de aprendizaje es si un tercio de

51
00:03:08.526 --> 00:03:12.070
la transcripción se utiliza la primera,
un tercio, el segundo y

52
00:03:12.070 --> 00:03:14.183
un tercio de la forma de conducción trans.

53
00:03:14.183 --> 00:03:18.644
Porque entonces tus datos son inconsistentes y
confusos para el aprendizaje

54
00:03:18.644 --> 00:03:23.710
algoritmo, porque ¿cómo se supone que el algoritmo
algoritmo de aprendizaje se supone que adivinar que uno de estos

55
00:03:23.710 --> 00:03:29.040
convenciones específicas de transcripción ha
ha utilizado para un clip de audio.

56
00:03:29.040 --> 00:03:32.640
Así que la detección de la corrección de
consistencias como esa.

57
00:03:32.640 --> 00:03:37.489
Tal vez sólo pedir a todo el mundo para estandarizar
en esta primera convención que

58
00:03:37.489 --> 00:03:42.120
puede tener un impacto significativo en
el rendimiento de su algoritmo de aprendizaje.

59
00:03:42.120 --> 00:03:46.800
Así que volveremos más adelante en este curso
para profundizar en algunas de las mejores prácticas para

60
00:03:46.800 --> 00:03:50.940
cómo detectar incoherencias y
cómo abordarlas.

61
00:03:50.940 --> 00:03:54.861
Otros ejemplos de datos
preguntas de definición de datos para

62
00:03:54.861 --> 00:04:00.978
un clip de audio como el de hoy si,
cuánto silencio quieres antes y

63
00:04:00.978 --> 00:04:05.391
después de cada clip después de que un orador
haya dejado de hablar.

64
00:04:05.391 --> 00:04:09.370
¿Quieres incluir otros 100
milisegundos de silencio después de eso?

65
00:04:09.370 --> 00:04:15.540
O 300 milisegundos o
500 milisegundos, medio segundo?

66
00:04:15.540 --> 00:04:19.740
¿O cómo se realiza la
la normalización del volumen?

67
00:04:19.740 --> 00:04:24.550
Algunos oradores hablan alto, otros son menos
alto y entonces hay un truco

68
00:04:24.550 --> 00:04:28.534
caso de si tienes un solo clip de audio
de audio con un volumen muy alto y

69
00:04:28.534 --> 00:04:31.930
un volumen muy bajo,
todo dentro del mismo clip de audio.

70
00:04:31.930 --> 00:04:36.647
Entonces, ¿cómo se realiza la normalización
normalización del volumen.

71
00:04:36.647 --> 00:04:41.440
preguntas como todas estas son preguntas de
de datos.

72
00:04:41.440 --> 00:04:43.760
Mucho progreso en el aprendizaje automático.

73
00:04:43.760 --> 00:04:45.271
Esto es un montón de aprendizaje automático

74
00:04:45.271 --> 00:04:50.109
investigación fue impulsada por los investigadores
que trabajan para mejorar el rendimiento en

75
00:04:50.109 --> 00:04:51.600
conjunto de datos de referencia.

76
00:04:51.600 --> 00:04:56.122
En ese modelo, los investigadores
podrían descargar el conjunto de datos y

77
00:04:56.122 --> 00:04:58.740
sólo trabajar en ese conjunto de datos fijos.

78
00:04:58.740 --> 00:05:03.325
Y esta mentalidad ha llevado a un tremendo
progreso en el aprendizaje automático, así que

79
00:05:03.325 --> 00:05:07.598
no hay quejas en absoluto sobre esta mentalidad,
pero si estás trabajando en

80
00:05:07.598 --> 00:05:11.900
un sistema de producción, entonces no
tienes que mantener el conjunto de datos fijos.

81
00:05:11.900 --> 00:05:16.850
A menudo edito el conjunto de entrenamiento o incluso en
el conjunto de prueba si eso es lo que se necesita en

82
00:05:16.850 --> 00:05:22.140
para mejorar la calidad de los datos para
conseguir que un sistema de producción funcione mejor.

83
00:05:22.140 --> 00:05:27.013
Entonces, ¿cuáles son las formas prácticas de hacer esto
efectivamente, no una forma ad hoc, sino

84
00:05:27.013 --> 00:05:31.740
marcos sistemáticos para
asegurarse de tener datos de alta calidad.

85
00:05:31.740 --> 00:05:34.213
Aprenderás más sobre esto
más adelante en este curso y

86
00:05:34.213 --> 00:05:36.151
más adelante en la especialización también.

87
00:05:37.240 --> 00:05:42.266
Después de que hayas recogido tu conjunto de datos,
el siguiente paso es el modelado,

88
00:05:42.266 --> 00:05:47.840
en el que tienes que seleccionar y entrenar
el modelo y realizar un análisis de errores.

89
00:05:47.840 --> 00:05:54.140
Los tres insumos clave que entran en el entrenamiento
un modelo de aprendizaje automático son el código que

90
00:05:54.140 --> 00:06:00.740
es el algoritmo o la arquitectura del modelo
arquitectura del modelo que se puede elegir.

91
00:06:00.740 --> 00:06:05.226
También hay que elegir los hiperparámetros y
luego están los datos y

92
00:06:05.226 --> 00:06:09.100
ejecutar el código con sus
hiperparámetros en tus datos

93
00:06:09.100 --> 00:06:14.873
te da el modelo de aprendizaje automático el
celebrar, un modelo de aprendizaje automático para

94
00:06:14.873 --> 00:06:18.910
aprender de, digamos,
clips de audio a transcripciones de texto.

95
00:06:18.910 --> 00:06:22.356
Encontré que en muchos trabajos de investigación o

96
00:06:22.356 --> 00:06:28.174
trabajo académico se tiende a mantener
los datos fijos y variar el código y

97
00:06:28.174 --> 00:06:34.661
puede variar los hiperparámetros para
para tratar de obtener un buen rendimiento.

98
00:06:35.740 --> 00:06:40.837
Por el contrario, he encontrado que para
muchos equipos de productos, si su principal

99
00:06:40.837 --> 00:06:46.862
objetivo es simplemente construir y desplegar un sistema de
valioso sistema de aprendizaje automático,

100
00:06:46.862 --> 00:06:51.961
He descubierto que puede ser incluso más
efectivo mantener el código fijo y

101
00:06:51.961 --> 00:06:57.810
para centrarse en la optimización de los datos
y quizás los hiperparámetros,

102
00:06:57.810 --> 00:07:01.891
con el fin de obtener un modelo de alto rendimiento,

103
00:07:01.891 --> 00:07:06.933
Un sistema de aprendizaje automático
incluye tanto códigos como

104
00:07:06.933 --> 00:07:11.734
datos y también hiperparámetros que tal vez

105
00:07:11.734 --> 00:07:16.440
un poco más fácil de optimizar que el código o
datos.

106
00:07:16.440 --> 00:07:21.400
Y encontré que en lugar de tomar
una visión centrada en el modelo de tratar de

107
00:07:21.400 --> 00:07:25.829
optimizar el código a su fijo
conjunto de datos para muchos problemas,

108
00:07:25.829 --> 00:07:31.856
puedes usar una implementación de código abierto
de algo que descargues de Git-hub y

109
00:07:31.856 --> 00:07:35.160
en lugar de eso, sólo céntrate en optimizar los datos.

110
00:07:35.160 --> 00:07:40.160
Así que durante el modelado, ¿tienes que seleccionar
y entrenar alguna arquitectura del modelo.

111
00:07:40.160 --> 00:07:45.073
Tal vez alguna arquitectura de red neuronal
el análisis de errores puede entonces decir

112
00:07:45.073 --> 00:07:48.540
dónde se queda corto tu modelo.

113
00:07:48.540 --> 00:07:53.440
Y si puedes usar ese análisis de errores
para decirte como sistemáticamente

114
00:07:53.440 --> 00:07:57.700
mejorar tus datos,
tal vez mejorar el código también. Eso está bien.

115
00:07:57.700 --> 00:08:03.560
Pero a menudo, si el análisis de errores puede decirte
cómo mejorar sistemáticamente los datos,

116
00:08:03.560 --> 00:08:08.740
que puede ser una manera muy eficiente para
llegar a un modelo de alta precisión.

117
00:08:08.740 --> 00:08:13.497
Y parte del truco es que no quieres
sentir que tienes que recoger

118
00:08:13.497 --> 00:08:17.290
más datos todo el tiempo porque
siempre podemos usar más datos.

119
00:08:17.290 --> 00:08:20.293
Pero en lugar de simplemente
tratar de recoger más y

120
00:08:20.293 --> 00:08:25.145
más y más datos, lo cual es útil pero
puede ser costoso si su análisis

121
00:08:25.145 --> 00:08:29.842
puede ayudar a ser más específico en exactamente
qué datos recoger, eso puede ayudar

122
00:08:29.842 --> 00:08:33.880
a ser mucho más eficiente
en la construcción de un modelo preciso.

123
00:08:33.880 --> 00:08:36.911
Finalmente, cuando hayas
entrenado el modelo y

124
00:08:36.911 --> 00:08:40.899
cuando el análisis de errores parece
sugerir que está funcionando lo suficientemente bien,

125
00:08:40.899 --> 00:08:45.710
entonces estás listo para ir al despliegue,
Comprueba el reconocimiento de voz.

126
00:08:45.710 --> 00:08:50.340
Así es como se puede
desplegar un sistema de voz.

127
00:08:50.340 --> 00:08:52.130
Tienes un teléfono móvil.

128
00:08:52.130 --> 00:08:57.720
Este sería un dispositivo de borde con software
que se ejecuta localmente en tu teléfono.

129
00:08:57.720 --> 00:09:02.310
Ese software interviene en el micrófono
para grabar lo que alguien está diciendo.

130
00:09:02.310 --> 00:09:06.811
Quizás para la búsqueda por voz y
en una implementación típica de

131
00:09:06.811 --> 00:09:11.440
reconocimiento de voz,
utilizarías un módulo VAD.

132
00:09:11.440 --> 00:09:14.461
VAD significa detección de actividad vocal.

133
00:09:15.540 --> 00:09:16.640
Sí.

134
00:09:16.640 --> 00:09:20.460
Y normalmente es un algoritmo
simple.

135
00:09:20.460 --> 00:09:25.991
Tal vez un algoritmo de aprendizaje y
el trabajo del VAD permite al teléfono inteligente

136
00:09:25.991 --> 00:09:31.713
You also have to choose the hyperparameters and
then there are the data and

92
00:06:05.226 --> 00:06:09.100
run the code with your
hyperparameters in your data

93
00:06:09.100 --> 00:06:14.873
gives you the machine learning model the
celebrate, a machine learning model for

94
00:06:14.873 --> 00:06:18.910
learn from, let's say,
audio clips to text transcripts.

95
00:06:18.910 --> 00:06:22.356
I found that in many research papers or

96
00:06:22.356 --> 00:06:28.174
academic work tends to keep the data fixed
the data fixed and vary the code and

97
00:06:28.174 --> 00:06:34.661
you can vary the hyperparameters to
to try to get good performance.

98
00:06:35.740 --> 00:06:40.837
Conversely, I have found that for
many product teams, if their main

99
00:06:40.837 --> 00:06:46.862
goal is to simply build and deploy a valuable machine learning
valuable machine learning system,

100
00:06:46.862 --> 00:06:51.961
I have found that it can be even more
effective to keep the code fixed and

101
00:06:51.961 --> 00:06:57.810
to focus on optimizing the data
and perhaps hyperparameters,

102
00:06:57.810 --> 00:07:01.891
in order to obtain a high performance model,

103
00:07:01.891 --> 00:07:06.933
A machine learning system
includes both codes and

104
00:07:06.933 --> 00:07:11.734
data and also hyperparameters that may

105
00:07:11.734 --> 00:07:16.440
a little easier to optimize than code or data.
data.

106
00:07:16.440 --> 00:07:21.400
And I found that instead of taking
a model-centric view of trying to

107
00:07:21.400 --> 00:07:25.829
optimize the code to its fixed
data set for many problems,

108
00:07:25.829 --> 00:07:31.856
you can use an open source implementation
implementation of something that you download from Git-hub and

109
00:07:31.856 --> 00:07:35.160
instead, just focus on optimizing the data.

110
00:07:35.160 --> 00:07:40.160
So during the modeling, do you have to select
and train some model architecture.

111
00:07:40.160 --> 00:07:45.073
Maybe some neural network architecture
error analysis can then say

112
00:07:45.073 --> 00:07:48.540
where your model falls short.

113
00:07:48.540 --> 00:07:53.440
And if you can use that error analysis
to tell you how systematically

114
00:07:53.440 --> 00:07:57.700
improve your data,
maybe improve the code as well. That's fine.

115
00:07:57.700 --> 00:08:03.560
But often, if error analysis can tell you how to systematically
how to systematically improve the data,

116
00:08:03.560 --> 00:08:08.740
that can be a very efficient way to arrive at a
come up with a highly accurate model.

117
00:08:08.740 --> 00:08:13.497
And part of the trick is that you don't want to
feel like you have to pick up

118
00:08:13.497 --> 00:08:17.290
more data all the time because
we can always use more data.

119
00:08:17.290 --> 00:08:20.293
But instead of just
trying to collect more and

120
00:08:20.293 --> 00:08:25.145
more and more data, which is useful but can be costly if
can be costly if your analysis

121
00:08:25.145 --> 00:08:29.842
can help to be more specific on exactly what data to collect
what data to collect, that can help

122
00:08:29.842 --> 00:08:33.880
to be much more efficient
in building an accurate model.

123
00:08:33.880 --> 00:08:36.911
Finally, when you have
trained the model and

124
00:08:36.911 --> 00:08:40.899
when the error analysis seems to suggest
suggest that it is working well enough,

125
00:08:40.899 --> 00:08:45.710
then you are ready to go to deployment,
Check the speech recognition.

126
00:08:45.710 --> 00:08:50.340
This is how you can
deploy a voice system.

127
00:08:50.340 --> 00:08:52.130
You have a cell phone.

128
00:08:52.130 --> 00:08:57.720
This would be an edge device with software
running locally on your phone.

129
00:08:57.720 --> 00:09:02.310
That software taps into the microphone
to record what someone is saying.

130
00:09:02.310 --> 00:09:06.811
Perhaps for voice search and
in a typical implementation of

131
00:09:06.811 --> 00:09:11.440
voice recognition,
you would use a VAD module.

132
00:09:11.440 --> 00:09:14.461
VAD stands for voice activity detection.

133
00:09:15.540 --> 00:09:16.640
Yes.

134
00:09:16.640 --> 00:09:20.460
And it's usually a simple
algorithm.

135
00:09:20.460 --> 00:09:25.991
Maybe a learning algorithm and
the work of the VAD allows the smart phone to
