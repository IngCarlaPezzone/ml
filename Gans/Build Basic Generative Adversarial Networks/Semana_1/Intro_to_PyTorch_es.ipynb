{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1k6Y9afpxL6"
   },
   "source": [
    "# Intro\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a very powerful machine learning framework. Central to PyTorch are [tensors](https://pytorch.org/docs/stable/tensors.html), a generalization of matrices to higher ranks. One intuitive example of a tensor is an image with three color channels: A 3-channel (red, green, blue) image which is 64 pixels wide and 64 pixels tall is a $3\\times64\\times64$ tensor. You can access the PyTorch framework by writing `import torch` near the top of your code, along with all of your other import statements.\n",
    "\n",
    "This guide will help introduce you to the functionality of PyTorch, but don't worry too much about memorizing it: the assignments will link to relevant documentation where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es un marco de aprendizaje automático muy potente. En PyTorch son fundamentales los [tensores](https://pytorch.org/docs/stable/tensors.html), una generalización de las matrices a rangos superiores. Un ejemplo intuitivo de un tensor es una imagen con tres canales de color: Una imagen de 3 canales (rojo, verde, azul) que tiene 64 píxeles de ancho y 64 píxeles de alto es un tensor de $3\\times64\\times64$. Puedes acceder al framework PyTorch escribiendo `import torch` cerca de la parte superior de tu código, junto con todas tus otras declaraciones de importación.\n",
    "\n",
    "Esta guía te ayudará a introducirte en la funcionalidad de PyTorch, pero no te preocupes demasiado por memorizarla: las asignaciones enlazarán con la documentación relevante cuando sea necesario.\n",
    "\n",
    "Traducción realizada con la versión gratuita del traductor www.DeepL.com/Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwp6T5ZMteDC"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvXp0rlPBqdQ"
   },
   "source": [
    "# Why PyTorch?\n",
    "\n",
    "One important question worth asking is, why is PyTorch being used for this course? There is a great breakdown by [the Gradient](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) looking at the state of machine learning frameworks today. In part, as highlighted by the article, PyTorch is generally more pythonic than alternative frameworks, easier to debug, and is the most-used language in machine learning research by a large and growing margin. While PyTorch's primary alternative, Tensorflow, has attempted to integrate many of PyTorch's features, Tensorflow's implementations come with some inherent limitations highlighted in the article.\n",
    "\n",
    "Notably, while PyTorch's industry usage has grown, Tensorflow is still (for now) a slight favorite in industry. In practice, the features that make PyTorch attractive for research also make it attractive for education, and the general trend of machine learning research and practice to PyTorch makes it the more proactive choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué PyTorch?\n",
    "\n",
    "Una pregunta importante que vale la pena hacer es, ¿por qué se utiliza PyTorch para este curso? Hay un gran desglose por [el Gradiente](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) mirando el estado de los marcos de aprendizaje de la máquina hoy en día. En parte, como se destaca en el artículo, PyTorch es generalmente más pitónico que los marcos alternativos, más fácil de depurar, y es el lenguaje más utilizado en la investigación de aprendizaje automático por un margen grande y creciente. Mientras que la principal alternativa de PyTorch, Tensorflow, ha intentado integrar muchas de las características de PyTorch, las implementaciones de Tensorflow vienen con algunas limitaciones inherentes destacadas en el artículo.\n",
    "\n",
    "En particular, mientras que el uso de PyTorch en la industria ha crecido, Tensorflow sigue siendo (por ahora) un ligero favorito en la industria. En la práctica, las características que hacen que PyTorch sea atractivo para la investigación también lo hacen para la educación, y la tendencia general de la investigación y la práctica del aprendizaje automático hacia PyTorch hace que sea la opción más proactiva. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCgwdP20r1yX"
   },
   "source": [
    " # Propiedades de los tensores\n",
    "Una forma de crear tensores a partir de una lista o un array es utilizar `torch.Tensor`. Se utilizará para crear ejemplos en este cuaderno, pero nunca necesitarás usarlo en el curso - de hecho, si te encuentras necesitándolo, probablemente no sea la respuesta correcta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0hgYekGsxlB"
   },
   "outputs": [],
   "source": [
    "example_tensor = torch.Tensor(\n",
    "    [\n",
    "     [[1, 2], [3, 4]], \n",
    "     [[5, 6], [7, 8]], \n",
    "     [[9, 0], [1, 2]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dO4C2oft7zq"
   },
   "source": [
    "Puedes ver el tensor en el cuaderno simplemente imprimiéndolo (aunque algunos tensores más grandes se cortarán)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "U2FKEzeYuEOX",
    "outputId": "dfa12ff7-afd1-4737-a669-54f36b4209dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUwlmUngw-VR"
   },
   "source": [
    "## Propiedades del tensor: Dispositivo\n",
    "\n",
    "Una propiedad importante es el dispositivo del tensor - a lo largo de este cuaderno te ceñirás a los tensores que están en la CPU. Sin embargo, a lo largo del curso también utilizarás tensores en la GPU (es decir, una tarjeta gráfica que se te proporcionará para que la utilices en el curso). Para ver el dispositivo del tensor, todo lo que necesitas escribir es `example_tensor.device`. Para mover un tensor a un nuevo dispositivo, puedes escribir `nuevo_tensor = example_tensor.to(device)` donde dispositivo será `cpu` o `cuda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R7SF44_Vw9h0",
    "outputId": "57f90e38-f9e1-4115-8f27-ebe651d5b2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkfySyFduHQi"
   },
   "source": [
    "## Tensor Properties: Shape\n",
    "\n",
    "Y puedes obtener el número de elementos en cada dimensión imprimiendo la forma del tensor, usando `ejemplo_tensor.shape`, algo con lo que probablemente estés familiarizado si has usado numpy. Por ejemplo, este tensor es un tensor $3\\times2\\times2$, ya que tiene 3 elementos, cada uno de los cuales es $2\\times2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKmfzpOBun0t",
    "outputId": "883009b6-7300-4329-f9ec-df99cc36d846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL954xmAuq4b"
   },
   "source": [
    "También se puede obtener el tamaño de una dimensión particular $n$ utilizando `ejemplo_tensor.forma[n]` o, de forma equivalente, `ejemplo_tensor.tamaño(n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7IKy3BB8uqBo",
    "outputId": "7fac1275-132f-4d2b-bf63-73065a2aea6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape[0] = 3\n",
      "size(1) = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"shape[0] =\", example_tensor.shape[0])\n",
    "print(\"size(1) =\",  example_tensor.size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pzzG8bav5rl"
   },
   "source": [
    "Por último, a veces es útil obtener el número de dimensiones (rango) o el número de elementos, lo que puede hacerse de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l_j9qTwyv41-",
    "outputId": "5921cbd1-19a2-4543-9488-3f72c0cb4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank = 3\n",
      "Number of elements = 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank =\", len(example_tensor.shape))\n",
    "print(\"Number of elements =\", example_tensor.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gibyKQJQzLkm"
   },
   "source": [
    "# Indexing Tensors\n",
    "\n",
    "Como con numpy, puedes acceder a elementos específicos o subconjuntos de elementos de un tensor. Para acceder al elemento $n$-ésimo, puedes simplemente escribir `example_tensor[n]` - como con Python en general, estas dimensiones están indexadas a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F87bFA5SzNz7",
    "outputId": "1b0a8381-6fd8-40b4-a5c8-88cc80029f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CegGw5wzpGa"
   },
   "source": [
    "Además, si se quiere acceder a la dimensión $j$-ésima del ejemplo $i$-ésimo, se puede escribir `ejemplo_tensor[i, j]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bl1JSZcRz0xn",
    "outputId": "7f98e47b-66cb-4927-b784-7e4bcb9eb687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyQRCRIa4NaY"
   },
   "source": [
    "Ten en cuenta que si quieres obtener un valor escalar en Python a partir de un tensor, puedes utilizar `ejemplo_escalar.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e56KSJOq4YOE",
    "outputId": "29e1fd13-32df-40c5-e558-3193fa5da629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_scalar = example_tensor[1, 1, 0]\n",
    "example_scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZdMEQfu0A7h"
   },
   "source": [
    "Además, puedes indexar en el elemento ith de una columna utilizando `x[:, i]`. Por ejemplo, si quieres el elemento superior izquierdo de cada elemento en `ejemplo_tensor`, que es el elemento `0, 0` de cada matriz, puedes escribir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x2cFxJx50eGH",
    "outputId": "e66eade9-4b4b-4c7a-ea99-a83195d10541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 9.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-rTBP-1whd2"
   },
   "source": [
    "# Initializing Tensors\n",
    "\n",
    "Hay muchas formas de crear nuevos tensores en PyTorch, pero en este curso, las más importantes son: \n",
    "\n",
    "[`torch.ones_like`](https://pytorch.org/docs/master/generated/torch.ones_like.html): crea un tensor de todos los ones con la misma forma y dispositivo que `example_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "g7gbs4AnwlIo",
    "outputId": "b0c67ed9-e33f-47d6-d95c-e53bc4f90dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aIbSlaJy9Z0"
   },
   "source": [
    "[`torch.zeros_like`](https://pytorch.org/docs/master/generated/torch.zeros_like.html): crea un tensor de todos los ceros con la misma forma y dispositivo que `example_tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "X4cWQduzzCd8",
    "outputId": "dbc8a5fa-8db1-4f6d-e38e-d1deb982ff36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsOmgS1izDS_"
   },
   "source": [
    "[`torch.randn_like`](https://pytorch.org/docs/stable/generated/torch.randn_like.html): crea un tensor con cada elemento muestreado a partir de una [distribución normal (o gaussiana)](https://en.wikipedia.org/wiki/Normal_distribution) con la misma forma y dispositivo que `example_tensor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2hto51IazDow",
    "outputId": "cb62a68a-6171-4d1e-eb9b-f31784464aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3675,  0.2242],\n",
       "         [-0.3378, -1.0944]],\n",
       "\n",
       "        [[ 1.5371,  0.7701],\n",
       "         [-0.1490, -0.0928]],\n",
       "\n",
       "        [[ 0.3270,  0.4642],\n",
       "         [ 0.1494,  0.1283]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(example_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXp0i5Cf6AGj"
   },
   "source": [
    "A veces (aunque menos a menudo de lo que esperas), puedes necesitar inicializar un tensor conociendo sólo la forma y el dispositivo, sin un tensor de referencia para `ones_like` o `randn_like`. En este caso, puede crear un tensor de $2x2$ de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RZRqt3-S6cUZ",
    "outputId": "7bef97cc-a303-4200-c0f8-ef9bf3cb4996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2235, -1.8912],\n",
       "        [-1.2873,  0.7405]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2, device='cpu') # Alternatively, for a GPU tensor, you'd use device='cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTkmDwVsrM6R"
   },
   "source": [
    "# Basic Functions\n",
    "\n",
    "Hay una serie de funciones básicas que debes conocer para usar PyTorch - si estás familiarizado con numpy, todas las funciones de uso común existen en PyTorch, normalmente con el mismo nombre. Puedes realizar una multiplicación / división por un escalar $c$ escribiendo simplemente `c * ejemplo_tensor`, y una suma / resta por un escalar escribiendo `ejemplo_tensor + c`.\n",
    "\n",
    "Ten en cuenta que la mayoría de las operaciones no son in-place en PyTorch, lo que significa que no cambian los datos de la variable original (Sin embargo, puedes reasignar el mismo nombre de la variable a los datos cambiados si lo deseas, como `ejemplo_tensor = ejemplo_tensor + 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "FpfwOUdopsF_",
    "outputId": "32347400-2e6a-40c6-e6f1-21e6aacde795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -8.,  -6.],\n",
       "         [ -4.,  -2.]],\n",
       "\n",
       "        [[  0.,   2.],\n",
       "         [  4.,   6.]],\n",
       "\n",
       "        [[  8., -10.],\n",
       "         [ -8.,  -6.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(example_tensor - 5) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uciZnx4b3UjX"
   },
   "source": [
    "Puede calcular la media o la desviación estándar de un tensor utilizando [`ejemplo_tensor.mean()`](https://pytorch.org/docs/stable/generated/torch.mean.html) o [`ejemplo_tensor.std()`](https://pytorch.org/docs/stable/generated/torch.std.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0ELXUKG7329z",
    "outputId": "720dd190-7dd4-43f1-e53c-cba4263eb2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor(4.)\n",
      "Stdev: tensor(2.9848)\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\", example_tensor.mean())\n",
    "print(\"Stdev:\", example_tensor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QsyTRym32SX"
   },
   "source": [
    "También puede querer encontrar la media o la desviación estándar a lo largo de una dimensión concreta. Para ello, basta con pasar a la función el número correspondiente a esa dimensión. Por ejemplo, si quieres obtener la media de la matriz de $2\\times2$ del `tensor_de_ejemplo` de $3\\times2\\times2$ puedes escribir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eCJl3Im25B9k",
    "outputId": "4bd9decd-579e-462c-bde1-ee8d9d1b2061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 2.6667],\n",
       "        [3.6667, 4.6667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor.mean(0)\n",
    "\n",
    "# Equivalently, you could also write:\n",
    "# example_tensor.mean(dim=0)\n",
    "# example_tensor.mean(axis=0)\n",
    "# torch.mean(example_tensor, 0)\n",
    "# torch.mean(example_tensor, dim=0)\n",
    "# torch.mean(example_tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb-_5ubc8t97"
   },
   "source": [
    "PyTorch tiene muchas otras funciones poderosas, pero estas deberían ser todas las funciones de PyTorch que necesitas para este curso fuera de su módulo de redes neuronales (`torch.nn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[5., 6.],\n",
       "         [7., 8.]],\n",
       "\n",
       "        [[9., 0.],\n",
       "         [1., 2.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [6., 7.],\n",
       "        [5., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(example_tensor)\n",
    "example_tensor.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtWjExD69JEs"
   },
   "source": [
    "# PyTorch Neural Network Module (`torch.nn`)\n",
    "\n",
    "PyTorch tiene un montón de clases poderosas en su módulo `torch.nn` (Normalmente, importado como simplemente `nn`). Estas clases permiten crear una nueva función que transforma un tensor de manera específica, a menudo conservando la información cuando se llama varias veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYrgloYo_slC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyCPVmTD_kkl"
   },
   "source": [
    "## `nn.Linear`\n",
    "\n",
    "Para crear una capa lineal, hay que pasarle el número de dimensiones de entrada y el número de dimensiones de salida. El objeto lineal inicializado como `nn.Linear(10, 2)` tomará una matriz de $n\\times10$ y devolverá una matriz de $n\\times2$, donde todos los elementos de $n$ han tenido la misma transformación lineal realizada. Por ejemplo, se puede inicializar una capa lineal que realice la operación $Ax + b$, donde $A$ y $b$ se inicializan aleatoriamente al generar el objeto [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pNPaHPo89VrN",
    "outputId": "c14dc316-ae68-49d3-a8eb-8ad6e1464f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2900, -0.5352],\n",
       "        [ 0.4298,  0.4173],\n",
       "        [ 0.4861, -0.3332]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 2)\n",
    "example_input = torch.randn(3, 10)\n",
    "example_output = linear(example_input)\n",
    "example_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGNULkJR_mzn"
   },
   "source": [
    "## `nn.ReLU`\n",
    "\n",
    "[`nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) creará un objeto que, al recibir un tensor, realizará una función de activación ReLU. Esto se revisará más adelante en la conferencia, pero en esencia, una no linealidad ReLU establece todos los números negativos en un tensor a cero. En general, las redes neuronales más simples se componen de series de transformaciones lineales, cada una de ellas seguida de funciones de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nGxVFS3nBASc",
    "outputId": "d5f57584-1bad-4803-ba8c-b69881db4a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2900, 0.0000],\n",
       "        [0.4298, 0.4173],\n",
       "        [0.4861, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu_output = relu(example_output)\n",
    "relu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzfOEZ03AJzA"
   },
   "source": [
    "## `nn.BatchNorm1d`\n",
    "\n",
    "[`nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) es una técnica de normalización que reescalará un lote de $n$ entradas para tener una media y desviación estándar consistente entre lotes.  \n",
    "\n",
    "Como indica el `1d` en su nombre, esto es para situaciones en las que se espera un conjunto de entradas, donde cada una de ellas es una lista plana de números. En otras palabras, cada entrada es un vector, no una matriz o un tensor de mayor dimensión. Para un conjunto de imágenes, cada una de las cuales es un tensor de mayor dimensión, se utilizaría [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), que se discute más adelante en esta página.\n",
    "\n",
    "`nn.BatchNorm1d` toma como argumento el número de dimensiones de entrada de cada objeto del lote (el tamaño de cada vector de ejemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O4tYsi9-G9vM",
    "outputId": "ba61d37c-a8af-4663-fcc2-1691c6d241de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3570, -0.7070],\n",
       "        [ 0.3368,  1.4140],\n",
       "        [ 1.0202, -0.7070]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchnorm = nn.BatchNorm1d(2)\n",
    "batchnorm_output = batchnorm(relu_output)\n",
    "batchnorm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMZewDz9Idr1"
   },
   "source": [
    "## `nn.Sequential`\n",
    "\n",
    "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) crea una única operación que realiza una secuencia de operaciones. Por ejemplo, puede escribir una capa de red neuronal con una normalización por lotes como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "R3GhASjyJt3N",
    "outputId": "3ef779ca-a17b-42fd-f2e5-fbb5fdc60b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "tensor([[ 1.7690,  0.2864,  0.7925,  2.2849,  1.5226],\n",
      "        [ 0.1877,  0.1367, -0.2833,  2.0905,  0.0454],\n",
      "        [ 0.7825,  2.2969,  1.2144,  0.2526,  2.5709],\n",
      "        [-0.4878,  1.9587,  1.6849,  0.5284,  1.9027],\n",
      "        [ 0.5384,  1.1787,  0.4961, -1.6326,  1.4192]])\n",
      "output: \n",
      "tensor([[0.0000, 1.1865],\n",
      "        [1.5208, 0.0000],\n",
      "        [0.0000, 1.1601],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7246, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp_layer = nn.Sequential(\n",
    "    nn.Linear(5, 2),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "test_example = torch.randn(5,5) + 1\n",
    "print(\"input: \")\n",
    "print(test_example)\n",
    "print(\"output: \")\n",
    "print(mlp_layer(test_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SToQiSv5K5Yb"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "Uno de los aspectos más importantes de cualquier marco de aprendizaje automático es su biblioteca de diferenciación automática. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4GZFCZ0QqI1"
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "Para crear un optimizador en PyTorch, necesitarás usar el módulo `torch.optim`, a menudo importado como `optim`. [`optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) corresponde al optimizador Adam. Para crear un objeto optimizador, tendrás que pasarle los parámetros a optimizar y la tasa de aprendizaje, `lr`, así como cualquier otro parámetro específico del optimizador.\n",
    "\n",
    "Para todos los objetos `nn`, puede acceder a sus parámetros como una lista utilizando su método `parameters()`, como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIcCbs35K4wY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "adam_opt = optim.Adam(mlp_layer.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BsPFZu2M0Xx"
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Un paso de entrenamiento (básico) en PyTorch consta de cuatro partes básicas:\n",
    "\n",
    "\n",
    "1.   Poner todos los gradientes a cero usando `opt.zero_grad()`.\n",
    "2.   Calcular la pérdida, `loss`.\n",
    "3.   Calcular los gradientes con respecto a la pérdida usando `loss.backward()`.\n",
    "4.   Actualizar los parámetros que se están optimizando utilizando `opt.step()`.\n",
    "\n",
    "Esto podría parecerse al siguiente código (y te darás cuenta de que si lo ejecutas varias veces, la pérdida baja):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zm6lPx4sOJht",
    "outputId": "c21672bd-a306-42ab-face-9a299511a059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7719, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_example = torch.randn(100,5) + 1\n",
    "adam_opt.zero_grad()\n",
    "\n",
    "# We'll use a simple loss function of mean distance from 1\n",
    "# torch.abs takes the absolute value of a tensor\n",
    "cur_loss = torch.abs(1 - mlp_layer(train_example)).mean()\n",
    "\n",
    "cur_loss.backward()\n",
    "adam_opt.step()\n",
    "print(cur_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDjhZBCeTc6o"
   },
   "source": [
    "## `requires_grad_()`\n",
    "\n",
    "También puedes decirle a PyTorch que necesita calcular el gradiente con respecto a un tensor que hayas creado diciendo `ejemplo_tensor.requires_grad_()`, que lo cambiará en el lugar. Esto significa que incluso si PyTorch no almacenaría normalmente un grad para ese tensor en particular, lo hará para ese tensor especificado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mB22ovHyUEvH"
   },
   "source": [
    "## `with torch.no_grad():`\n",
    "\n",
    "PyTorch suele calcular los gradientes a medida que avanza en un conjunto de operaciones sobre tensores. Esto a menudo puede ocupar cálculos y memoria innecesarios, especialmente si está realizando una evaluación. Sin embargo, puede envolver un trozo de código con `with torch.no_grad()` para evitar que se calculen los gradientes en un trozo de código. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kowb1M425CE_"
   },
   "source": [
    "\n",
    "## `detach():`\n",
    "\n",
    "A veces, se quiere calcular y utilizar el valor de un tensor sin calcular sus gradientes. Por ejemplo, si tienes dos modelos, A y B, y quieres optimizar directamente los parámetros de A con respecto a la salida de B, sin calcular los gradientes a través de B, entonces podrías alimentar la salida separada de B a A. Hay muchas razones por las que podrías querer hacer esto, incluyendo la eficiencia o las dependencias cíclicas (es decir, A depende de B depende de A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9HY2wgKLOr-"
   },
   "source": [
    "# New `nn` Classes\n",
    "\n",
    "También puede crear nuevas clases que extiendan el módulo `nn`. Para estas clases, todos los atributos de la clase, como en `self.layer` o `self.param` serán tratados automáticamente como parámetros si son ellos mismos objetos `nn` o si son tensores envueltos en `nn.Parameter` que se inicializan con la clase. \n",
    "\n",
    "La función `__init__` define lo que ocurrirá cuando se cree el objeto. La primera línea de la función init de una clase, por ejemplo, `WellNamedClass`, tiene que ser `super(WellNamedClass, self).__init__()`. \n",
    "\n",
    "La función `forward` define lo que se ejecuta si se crea ese objeto `model` y se le pasa un tensor `x`, como en `model(x)`. Si eliges la firma de la función, `(self, x)`, entonces cada llamada de la función forward, obtiene dos piezas de información: `self`, que es una referencia al objeto con la que puedes acceder a todos sus parámetros, y `x`, que es el tensor actual para el que te gustaría devolver `y`.\n",
    "\n",
    "Una clase podría tener el siguiente aspecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOip473tQs-d"
   },
   "outputs": [],
   "source": [
    "class ExampleModule(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(ExampleModule, self).__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims)\n",
    "        self.exponent = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        # This is the notation for element-wise exponentiation, \n",
    "        # which matches python in general\n",
    "        x = x ** self.exponent \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4CUFH_GS5UY"
   },
   "source": [
    "Y puede ver sus parámetros de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YuelIiE4S3KR",
    "outputId": "27a52620-ca40-4dc8-dff5-4f3a56ba0e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor(1., requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2789,  0.2618, -0.0678,  0.2766,  0.1436,  0.0917, -0.1669, -0.1887,\n",
       "           0.0913, -0.1998],\n",
       "         [-0.1757,  0.0361,  0.1140,  0.2152, -0.1200,  0.1712,  0.0944, -0.0447,\n",
       "           0.1548,  0.2383]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1881, -0.0834], requires_grad=True)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_model = ExampleModule(10, 2)\n",
    "list(example_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F7E1wKN5tez"
   },
   "source": [
    "Y también puedes imprimir sus nombres, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "dYTuTDsQ5pnY",
    "outputId": "6635a493-7318-4688-bd18-bfba41d43e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exponent',\n",
       "  Parameter containing:\n",
       "  tensor(1., requires_grad=True)),\n",
       " ('linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.2789,  0.2618, -0.0678,  0.2766,  0.1436,  0.0917, -0.1669, -0.1887,\n",
       "            0.0913, -0.1998],\n",
       "          [-0.1757,  0.0361,  0.1140,  0.2152, -0.1200,  0.1712,  0.0944, -0.0447,\n",
       "            0.1548,  0.2383]], requires_grad=True)),\n",
       " ('linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.1881, -0.0834], requires_grad=True))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example_model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWPoIqX2UsaH"
   },
   "source": [
    "Y aquí hay un ejemplo de la clase en acción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7NXwbg5tUroC",
    "outputId": "0836e447-7c37-464e-b196-048ae0a0cc73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0567,  0.4562],\n",
       "        [ 0.3780,  0.3452]], grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 10)\n",
    "example_model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ocol8DABScy"
   },
   "source": [
    "# 2D Operations\n",
    "\n",
    "No los necesitarás para la primera lección, y la teoría detrás de cada uno de ellos se revisará más en conferencias posteriores, pero aquí hay una referencia rápida: \n",
    "\n",
    "\n",
    "* Convoluciones 2D: [`nn.Conv2d`](https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html) requiere el número de canales de entrada y salida, así como el tamaño del núcleo.\n",
    "* Convoluciones 2D transpuestas (también conocidas como deconvoluciones): [`nn.ConvTranspose2d`](https://pytorch.org/docs/master/generated/torch.nn.ConvTranspose2d.html) también requiere el número de canales de entrada y salida, así como el tamaño del kernel\n",
    "* Normalización 2D por lotes: [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) requiere el número de dimensiones de entrada\n",
    "* Redimensionamiento de imágenes: [`nn.Upsample`](https://pytorch.org/docs/master/generated/torch.nn.Upsample.html) requiere el tamaño final o un factor de escala. Alternativamente, [`nn.functional.interpolate`](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.interpolate) toma los mismos argumentos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro to PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
