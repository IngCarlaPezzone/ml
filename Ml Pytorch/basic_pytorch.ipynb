{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción  a Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "\n",
    "- [1 - Instalación e importación de Pytorch](#1)\n",
    "- [2 - ¿Qué es Pytorch?](#2)\n",
    "- [3 - Escalares, Vectores, Matrices y Tensores. De Numpy a Pytorch](#3)\n",
    "    - [3.1 - Escalares](#3.1)\n",
    "    - [3.2 - Vector](#3.2)\n",
    "    - [3.3 - Matriz](#3.3)\n",
    "    - [3.4 - Tensor](#3.4)\n",
    "    - [3.5 - Inicialización de los tensores](#3.5)\n",
    "        - [3.5.1 - torch.empty](#3.5.1)\n",
    "        - [3.5.2 - torch.rand](#3.5.2)\n",
    "        - [3.5.3 - torch.zeros](#3.5.3)\n",
    "        - [3.5.4 - torch.ones](#3.5.4)\n",
    "    - [3.6 - Creación de rangos y tensores like](#3.6)\n",
    "    - [3.7 - Tensor a partir de lista](#3.7)\n",
    "    - [3.8 - Tensor de PyTorch y NumPy](#3.8)\n",
    "    - [3.9 - Operaciones con tensores](#3.9)\n",
    "        - [3.9.1 - Suma](#3.9.1)\n",
    "        - [3.9.2 - Substracción](#3.9.2)\n",
    "        - [3.9.3 - Multiplicación por elementos](#3.9.3)\n",
    "        - [3.9.4 - División](#3.9.4)\n",
    "        - [3.9.5 - Multiplicación matricial o Producto punto](#3.9.5)\n",
    "    - [3.10 - Exploración de tensores](#3.10)\n",
    "    - [3.11 - Información de los tensores](#3.11)\n",
    "- [4 - Autograd](#4)\n",
    "- [5 - GPU](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Instalación e importación de Pytorch\n",
    "\n",
    "*Para instalar y ver la documentación oficial consultar:* https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La instalación de Pytorch depende de cada equipo.\n",
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - ¿Qué es Pytorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es un framework de aprendizaje automático (Machine Learning) y aprendizaje profundo (Deep Learning) de código abierto.\n",
    "\n",
    "Contiene un conjunto de librerías y herramientas que nos hacen la vida más fácil a la hora de diseñar, entrenar y poner en producción nuestros modelos de `Deep Learning`. Una forma sencilla de entender qué es `Pytorch` es la siguiente:\n",
    "\n",
    "$$ Pytorch = Numpy + Autograd + GPU $$\n",
    "\n",
    "Vamos a ver qué significa cada uno de estos términos:\n",
    "\n",
    "* Numpy: Pytorch sigue una interfaz muy similar a la de `NumPy`. Así como en `NumPy` donde el objeto principal es el `ndarray`, en `Pytorch` el objeto principal es el `tensor`. Podemos definir un tensor de manera similar a como definimos un array, incluso podemos inicializar tensores a partir de arrays.\n",
    "\n",
    "* Autograd: La funcionalidad más importante que `Pytorch` añade es la conocidad como `autograd`, la cual nos proporciona la posibilidad de calcular derivadas de manera automática con respecto a cualquier `tensor`. Esto le da a `Pytorch` un gran potencial para diseñar `redes neuronales` complejas y entrenarlas utilizando algoritmos de gradientes sin tener que calcular todas estas derivadas manualmente.\n",
    "\n",
    "* GPU: Es un hardware especializado en acelerar las operaciones matriciales, especialmente las complejas. Se llama Unidades de Procesado Gráfico, o GPUs.\n",
    "\n",
    "A continuación, se explican en mas detalle cada una de estos términos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "### 3 - Escalares, Vectores, Matrices y Tensores. De Numpy a Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "#### 3.1 - Escalares\n",
    "Un escalar es un solo número y en lenguaje tensorial es un tensor de dimensión cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variable 'scalar' es:  tensor(7)\n",
      "Dimensión:  0\n",
      "Valor python dentro del tensor:  7\n"
     ]
    }
   ],
   "source": [
    "# Definición de un escalar\n",
    "scalar = torch.tensor(7)\n",
    "print(\"La variable 'scalar' es: \", scalar)\n",
    "# Dimensión del escalar\n",
    "dim_scalar = scalar.ndim\n",
    "print(\"Dimensión: \", dim_scalar)\n",
    "# Obtener el número de Python dentro de un tensor (sólo funciona con tensores de un elemento)\n",
    "valor_scalar = scalar.item()\n",
    "print(\"Valor python dentro del tensor: \", valor_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "#### 3.2 - Vector\n",
    "Un vector es un tensor de una dimensión pero puede contener muchos números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variable 'vector' es:  tensor([7, 7])\n",
      "Dimensión:  1\n",
      "Forma:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Definición de un vector\n",
    "vector = torch.tensor([7, 7])\n",
    "print(\"La variable 'vector' es: \", vector)\n",
    "# Dimensión del vector\n",
    "dim_vector = vector.ndim\n",
    "print(\"Dimensión: \", dim_vector)\n",
    "# Forma (shape) del vector\n",
    "forma_vector = vector.shape\n",
    "print(\"Forma: \", forma_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "#### 3.3 - Matriz\n",
    "Es como el vector, pero de dos dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variable 'MATRIX' es: \n",
      " tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "Dimensión:  2\n",
      "Forma:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Definición de una matriz\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX\n",
    "print(\"La variable 'MATRIX' es: \\n\", MATRIX)\n",
    "# Dimensión de la matriz\n",
    "dim_MATRIX = MATRIX.ndim\n",
    "print(\"Dimensión: \", dim_MATRIX)\n",
    "# Forma (shape) de la matriz\n",
    "forma_MATRIX = MATRIX.shape\n",
    "print(\"Forma: \", forma_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.4'></a>\n",
    "#### 3.4 - Tensor\n",
    "Es una matriz de *n* dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variable 'TENSOR' es: \n",
      " tensor([[[1, 2, 3],\n",
      "         [3, 6, 9],\n",
      "         [2, 4, 5]]])\n",
      "Dimensión:  3\n",
      "Forma:  torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Definición de un tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR\n",
    "print(\"La variable 'TENSOR' es: \\n\", TENSOR)\n",
    "# Dimensión del tensor\n",
    "dim_TENSOR = TENSOR.ndim\n",
    "print(\"Dimensión: \", dim_TENSOR)\n",
    "# Forma (shape) del tensor\n",
    "forma_TENSOR = TENSOR.shape\n",
    "print(\"Forma: \", forma_TENSOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.5'></a>\n",
    "#### 3.5 - Inicialización de los tensores\n",
    "Los valores que componen los tensores representan alguna forma de dato para que los modelos de aprendizaje los manipule y saquen patrones de los mismos. Cuando se construyen modelos de aprendizaje automático con PyTorch, es raro que se creen tensores a mano.\n",
    "\n",
    "A continuación, se ven distintas formas de inicializar tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.5.1'></a>\n",
    "##### 3.5.1 - torch.empty\n",
    "Devuelve un tensor lleno de datos no inicializados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalar no inicializado: \n",
      " tensor([7.1429e+31])\n",
      " \n",
      " Vector no inicializado: \n",
      " tensor([-6.0585e-30,  4.5916e-41,  0.0000e+00])\n",
      " \n",
      " Matriz no inicializado: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      " \n",
      " Tensor 3D no inicializado: \n",
      " tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      " \n",
      " Tensor 4D no inicializado: \n",
      " tensor([[[[0.0000e+00, 0.0000e+00, 7.7052e+31],\n",
      "          [7.2148e+22, 2.5226e-18, 1.0372e-08]],\n",
      "\n",
      "         [[1.0413e-11, 1.2353e-08, 4.1497e-08],\n",
      "          [4.0064e-11, 1.0681e-05, 2.9575e-18]]],\n",
      "\n",
      "\n",
      "        [[[6.7333e+22, 1.7591e+22, 1.7184e+25],\n",
      "          [4.3222e+27, 6.1972e-04, 7.2443e+22]],\n",
      "\n",
      "         [[1.7728e+28, 7.0367e+22, 1.9152e+23],\n",
      "          [6.6008e-07, 1.2859e-11, 3.3382e-09]]]])\n"
     ]
    }
   ],
   "source": [
    "# Escalar\n",
    "scalar_empty = torch.empty(1)\n",
    "print('Escalar no inicializado: \\n', scalar_empty)\n",
    "#Vector\n",
    "vector_empty = torch.empty(3)\n",
    "print(' \\n Vector no inicializado: \\n', vector_empty)\n",
    "#Matriz\n",
    "matrix_empty = torch.empty(2,3)\n",
    "print(' \\n Matriz no inicializado: \\n', matrix_empty)\n",
    "#Tensor 3D\n",
    "tensor3D_empty = torch.empty(2,2,3)\n",
    "print(' \\n Tensor 3D no inicializado: \\n', tensor3D_empty)\n",
    "# Tensor 4D\n",
    "tensor4D_empty = torch.empty(2,2,2,3)\n",
    "print(' \\n Tensor 4D no inicializado: \\n', tensor4D_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.5.2'></a>\n",
    "##### 3.5.2 - torch.rand\n",
    "Devuelve un tensor con valores aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor con valores aleatorios: \n",
      " tensor([[[0.8059, 0.3871],\n",
      "         [0.0210, 0.3182],\n",
      "         [0.2343, 0.2145]],\n",
      "\n",
      "        [[0.0513, 0.3674],\n",
      "         [0.5054, 0.1218],\n",
      "         [0.4624, 0.1615]],\n",
      "\n",
      "        [[0.0745, 0.7668],\n",
      "         [0.1390, 0.8063],\n",
      "         [0.3388, 0.3494]],\n",
      "\n",
      "        [[0.5184, 0.4179],\n",
      "         [0.5852, 0.1870],\n",
      "         [0.9464, 0.5185]],\n",
      "\n",
      "        [[0.0731, 0.9018],\n",
      "         [0.6828, 0.2115],\n",
      "         [0.3833, 0.3427]]])\n",
      "\n",
      " Forma del Tensor: \n",
      " torch.Size([5, 3, 2])\n",
      "\n",
      " Dimensión del Tensor: \n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "# Tensor con valores aleatorios de tamaño (5, 3, 2)\n",
    "random_tensor = torch.rand(size=(5, 3, 2))\n",
    "print(\"Tensor con valores aleatorios: \\n\", random_tensor)\n",
    "print(\"\\n Forma del Tensor: \\n\", random_tensor.shape)\n",
    "print(\"\\n Dimensión del Tensor: \\n\", random_tensor.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.5.3'></a>\n",
    "##### 3.5.3 - torch.zeros\n",
    "Tensor lleno de ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor con valores ceros: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      " Forma del Tensor: \n",
      " torch.Size([5, 3])\n",
      "\n",
      " Dimensión del Tensor: \n",
      " 2\n",
      "\n",
      " Tipo de dato: \n",
      " torch.float32\n"
     ]
    }
   ],
   "source": [
    "# matriz de ceros, 5 filas y 3 columnas\n",
    "zeros_tensor = torch.zeros(5, 3)\n",
    "print(\"Tensor con valores ceros: \\n\", zeros_tensor)\n",
    "print(\"\\n Forma del Tensor: \\n\", zeros_tensor.shape) #da lo mismo que zeros_tensor.size()\n",
    "print(\"\\n Dimensión del Tensor: \\n\", zeros_tensor.ndim)\n",
    "print(\"\\n Tipo de dato: \\n\", zeros_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.5.4'></a>\n",
    "##### 3.5.4 - torch.ones\n",
    "Tensor lleno de unos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor con valores ceros: \n",
      " tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n",
      "\n",
      " Forma del Tensor: \n",
      " torch.Size([4, 3, 2])\n",
      "\n",
      " Dimensión del Tensor: \n",
      " 3\n",
      "\n",
      " Tipo de dato: \n",
      " torch.float32\n"
     ]
    }
   ],
   "source": [
    "# tensor de unos, de 4 matrices de 3 filas y 2 columnas\n",
    "ones_tensor = torch.ones(4, 3, 2)\n",
    "print(\"Tensor con valores ceros: \\n\", ones_tensor)\n",
    "print(\"\\n Forma del Tensor: \\n\", ones_tensor.shape) #da lo mismo que ones_tensor.size()\n",
    "print(\"\\n Dimensión del Tensor: \\n\", ones_tensor.ndim)\n",
    "print(\"\\n Tipo de dato: \\n\", ones_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.6'></a>\n",
    "#### 3.6 - Creación de rangos y tensores like\n",
    "\n",
    "**torch.arange**: Cuando se requiere un rango determinado.\n",
    "Es igual que `range()` de Python, pero este método en Pytorch (`torch.range()`) quedará obsoleto.\n",
    "\n",
    "**_like**: Cuando se quiere un tensor de una forma determinada según un tensor previamente creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear una matriz de todos ceros como el tensor zero_to_ten anterior\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.7'></a>\n",
    "#### 3.7 - Tensor a partir de lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista: \n",
      " [[1, 2, 3], [4, 5, 6]]\n",
      "Esto es:  <class 'list'>\n",
      "\n",
      "Tensor a partir de lista: \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Esto es:  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# tensor a partir de lista \n",
    "lista = [[1, 2, 3],[4, 5, 6]]\n",
    "tensor_from_list = torch.tensor(lista)\n",
    "print(\"Lista: \\n\", lista)\n",
    "print(\"Esto es: \", type(lista))\n",
    "print(\"\\nTensor a partir de lista: \\n\", tensor_from_list)\n",
    "print(\"Esto es: \", type(tensor_from_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.8'></a>\n",
    "#### 3.8 - Tensor de PyTorch y NumPy\n",
    "\n",
    "Los dos métodos principales para pasar de NumPy a PyTorch (y viceversa) son: \n",
    "* `torch.from_numpy(ndarray)`: lo que hace es pasar de NumPy array -> PyTorch tensor. \n",
    "* `torch.Tensor.numpy()`: lo que hace es pasar de Tensor PyTorch -> matriz NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Esto es:  <class 'numpy.ndarray'>\n",
      "Tipo de dato:  float64\n",
      "\n",
      "Tensor a partir de array: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n",
      "Esto es:  <class 'torch.Tensor'>\n",
      "Tipo de dato:  torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Crear un array de Numpy\n",
    "array = np.array([[1., 2., 3.],[4., 5., 6.]])\n",
    "print(\"Array: \\n\", a)\n",
    "print(\"Esto es: \", type(array))\n",
    "print(\"Tipo de dato: \", array.dtype) #Tipo de dato del array de Numpy es float64\n",
    "tensor_from_array = torch.from_numpy(array)\n",
    "print(\"\\nTensor a partir de array: \\n\", tensor_from_array)\n",
    "print(\"Esto es: \", type(tensor_from_array))\n",
    "print(\"Tipo de dato: \", tensor_from_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a partir de array: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Esto es:  <class 'torch.Tensor'>\n",
      "\n",
      "Tipo de dato:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Convertir un array Numpy float64 a tensor Pytorch float32\n",
    "tensor_from_array_dtype = torch.from_numpy(array).type(torch.float32)\n",
    "print(\"Tensor a partir de array: \\n\", tensor_from_array_dtype)\n",
    "print(\"\\nEsto es: \", type(tensor_from_array_dtype))\n",
    "print(\"\\nTipo de dato: \", tensor_from_array_dtype.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: \n",
      " [[11. 12. 13.]\n",
      " [14. 15. 16.]]\n",
      "\n",
      "Tensor: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Si se modifica el array no se modifica el tensor\n",
    "array = array + 10\n",
    "print(\"Array: \\n\", array)\n",
    "print(\"\\nTensor: \\n\", tensor_from_array_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array a partir de tensor: \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "Esto es:  <class 'numpy.ndarray'>\n",
      "\n",
      "Tipo de dato:  float32\n"
     ]
    }
   ],
   "source": [
    "# Pasar de tensor a array\n",
    "array_from_tensor = tensor_from_array_dtype.numpy() #Por defecto el tipo de dato es float32\n",
    "print(\"Array a partir de tensor: \\n\", array_from_tensor)\n",
    "print(\"\\nEsto es: \", type(array_from_tensor))\n",
    "print(\"\\nTipo de dato: \", array_from_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9'></a>\n",
    "#### 3.9 - Operaciones con tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9.1'></a>\n",
    "##### 3.9.1 - Suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: \n",
      " tensor([1, 2, 3])\n",
      "Tensor B: \n",
      " tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Se crean dos tensores\n",
    "tensorA = torch.tensor([1,2,3])\n",
    "tensorB = torch.tensor([4,5,6])\n",
    "print(\"Tensor A: \\n\", tensorA)\n",
    "print(\"Tensor B: \\n\", tensorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumar de un escalar a un tensor\n",
    "tensorA + 10 #los valores del tensor original no cambian si no son reasignados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma de dos tensores\n",
    "tensorA + tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de suma de Pytorch\n",
    "torch.add(tensorA,tensorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9.2'></a>\n",
    "#### 3.9.2 - Substracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resta de un escalar a un tensor\n",
    "tensorA - 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3, -3, -3])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resta de dos tensores\n",
    "tensorA - tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3, -3, -3])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de resta de Pytorch\n",
    "torch.sub(tensorA, tensorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9.3'></a>\n",
    "#### 3.9.3 - Multiplicación por elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación por elementos\n",
    "tensorA * 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación de tensores\n",
    "tensorA * tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de multiplicación de Pytorch con un escalar\n",
    "torch.multiply(tensorA, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de multiplicación de Pytorch con dos tensores\n",
    "torch.multiply(tensorA, tensorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mul es igual a multiply\n",
    "torch.mul(tensorA, tensorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9.4'></a>\n",
    "#### 3.9.4 - División"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División con un escalar\n",
    "tensorA / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0000, 2.5000, 2.0000])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# División de dos tensores\n",
    "tensorB / tensorA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de Pytorch para la division \n",
    "# con un escalar\n",
    "torch.div(tensorA,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0000,  5.0000,  3.3333])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de Pytorch para la division\n",
    "# un escalar con un tensor\n",
    "torch.div(10,tensorA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.4000, 0.5000])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función de Pytorch para la division\n",
    "# dos tensores\n",
    "torch.div(tensorA,tensorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.9.5'></a>\n",
    "#### 3.9.5 - Multiplicación matricial o Producto punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las operaciones mas comunes en los machine learning es la [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "Las dos reglas principales para la multiplicación de matrices que hay que recordar son:\n",
    "1. Las **dimensiones interiores** deben coincidir:\n",
    "  * `(3, 2) @ (3, 2)` no funcionará\n",
    "  * `(2, 3) @ (3, 2)` funcionará\n",
    "  * `(3, 2) @ (2, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de las **dimensiones exteriores**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    " \n",
    "(`@` en Python es el símbolo para la multiplicación de matrices. No se recomienda su uso.\n",
    "\n",
    "PyTorch implementa la funcionalidad de multiplicación de matrices en el método **torch.matmul()**.\n",
    "\n",
    "La diferencia entre la multiplicación por elementos y la multiplicación matricial es la suma de valores.\n",
    "\n",
    "Para el `tensorA` con valores `[1, 2, 3]`:\n",
    "\n",
    "| Operación | cálculo | código|\n",
    "| ----- | ----- | ----- |\n",
    "| Multiplicación por elementos: | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "**Multiplicación de matrices** | `[1*1 + 2*2 + 3*3]` = `[14]` |  `tensor.matmul(tensor)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14), torch.Size([3]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación matricial\n",
    "torch.matmul(tensorA, tensorA), tensorA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tensor t1 es: \n",
      " tensor([[0.8897, 0.7856],\n",
      "        [0.6159, 0.6680],\n",
      "        [0.4056, 0.5176]])\n",
      "Forma del tensor t1:  torch.Size([3, 2])\n",
      "\n",
      " El tensor t2 es: \n",
      " tensor([[0.8066, 0.9346, 0.6636],\n",
      "        [0.9523, 0.4502, 0.8108]])\n",
      "Forma del tensor t2:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Definición de dos tensores con valores aleatorios\n",
    "t1 = torch.rand(3,2)\n",
    "t2 = torch.rand(2,3)\n",
    "print(\"El tensor t1 es: \\n\", t1)\n",
    "print(\"Forma del tensor t1: \", t1.shape)\n",
    "print(\"\\n El tensor t2 es: \\n\", t2)\n",
    "print(\"Forma del tensor t2: \", t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de t1@t2 es: \n",
      " tensor([[1.4657, 1.1852, 1.2273],\n",
      "        [1.1329, 0.8764, 0.9503],\n",
      "        [0.8200, 0.6121, 0.6888]])\n",
      "Forma del tensor mm1:  torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Dimensiones interiores iguales no funciona\n",
    "mm1 = torch.matmul(t1, t2)\n",
    "print(\"El resultado de t1@t2 es: \\n\", mm1)\n",
    "print(\"Forma del tensor mm1: \", mm1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de t2@t1 es: \n",
      " tensor([[1.5623, 1.6014],\n",
      "        [1.4533, 1.4685]])\n",
      "Forma del tensor mm2:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Dimensiones interiores iguales no funciona\n",
    "mm2 = torch.matmul(t2, t1)\n",
    "print(\"El resultado de t2@t1 es: \\n\", mm2)\n",
    "print(\"Forma del tensor mm2: \", mm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado de t2@t1 es: \n",
      " tensor([[1.5623, 1.6014],\n",
      "        [1.4533, 1.4685]])\n",
      "Forma del tensor mm2:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# .mm es lo mismo que .matmul\n",
    "mm2 = torch.mm(t2, t1)\n",
    "print(\"El resultado de t2@t1 es: \\n\", mm2)\n",
    "print(\"Forma del tensor mm2: \", mm2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los errores mas comunes en deep learning es la operación de tensores sin respetar las reglas de forma.\n",
    "Como muestra el ejemplo siguiente, la multiplicación matricial de dos tensores con distintas dimensiones internas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-f8d4223f0f34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ([3, 2]) @ ([3, 2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# ([3, 2]) @ ([3, 2])\n",
    "torch.matmul(t1, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que esta operación funciones se hace la **transposición**, esto es, cambiar las dimensiones de uno de los tensores dados.\n",
    "\n",
    "Se puede realizar en PyTorch usando:\n",
    "* `torch.transpose(input, dim0, dim1)`: donde `input` es el tensor deseado a transponer y `dim0` y `dim1` son las dimensiones a intercambiar.\n",
    "* `tensor.T`: donde \"tensor\" es el tensor que se desea transponer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicación de t1 @ t1T\n",
    "\n",
    "t1T = t1.T #Transpuesta de t1\n",
    "print(\"Forma original de t1: \\n\", t1.shape)\n",
    "print(\"\\nTranspuesta de t1: \\n\", t1T)\n",
    "print(\"Forma de la transpuesta: \\n\", t1T.shape)\n",
    "\n",
    "multiplicacion = torch.matmul(t1, t1T)\n",
    "print(\"\\nEl resultado de t1 @ t1T es: \\n\", multiplicacion) \n",
    "print(\"Forma del resultado: \\n\", multiplicacion.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.10'></a>\n",
    "### 3.10 - Exploración de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor en el rango del 0 al 100 \n",
    "# tomando cada 10 valores\n",
    "tensorC = torch.arange(0, 100, 10)\n",
    "tensorC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el valor mínimo\n",
    "tensorC.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el valor máximo\n",
    "tensorC.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el valor medio\n",
    "tensorC.type(torch.float32).mean()\n",
    "# tensorC.mean() da error porque .mean() requiere que\n",
    "# el tensor sea torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la suma de todos los valores\n",
    "tensorC.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el índice del tensor donde se produce el máximo\n",
    "tensorC.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el índice del tensor donde se produce el mínimo\n",
    "tensorC.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing\n",
    "tensorD = torch.rand(5,3)\n",
    "print(tensorD)\n",
    "print(\"\\nTensor con todas las filas de la columna 0: \\n\", tensorD[:, 0]) \n",
    "print(\"\\nTensor con todas las columnas de la fila 1: \\n\", tensorD[1, :])\n",
    "print(\"\\nTensor con el elemento de la fila 1 columna 1: \\n\", tensorD[1,1])\n",
    "print(\"\\nElemento de la fila 1 columna 1: \\n\", tensorD[1,1].item())\n",
    "print(\"\\nTensor con las primeras 3 filas y todas las columnas: \\n\", tensorD[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexación\n",
    "#Crear un tensor\n",
    "tensorE = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(\"El tensorE es: \\n\", tensorE)\n",
    "print(\"\\nLa forma del tensorE es: \", tensorE.shape)\n",
    "#Indexar distintos valores\n",
    "print(\"\\nPrimer corchete:\\n\", tensorE[0]) \n",
    "print(\"\\nSegundo corchete: \", tensorE[0][0]) \n",
    "print(\"\\nTercer corchete: \", tensorE[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede usar : para especificar \"todos los valores\"\n",
    "# y , para añadir otra dimensión\n",
    "# Obtener todos los valores de la dimensión 0 y el índice 0 de la primera dimensión\n",
    "tensorE[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de las dimensiones 0 y 1, pero sólo el índice 1 de la dimensión 2\n",
    "tensorE[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los valores de la dimensión 0 pero sólo el valor del índice 1 de la 1ª y 2ª dimensión\n",
    "tensorE[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el índice 0 de la 0ª y 1ª dimensión y todos los valores de la 2ª dimensión \n",
    "tensorE[0, 0, :] # same as tensorE[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.11'></a>\n",
    "### 3.11 - Información de los tensores\n",
    "\n",
    "Los atributos mas comunes que se necesitan saber de un tensor son:\n",
    "\n",
    "* `forma`: ¿qué forma tiene el tensor? (algunas operaciones requieren reglas de forma específicas)\n",
    "* Tipo de datos: ¿en qué tipo de datos se almacenan los elementos del tensor?\n",
    "* Dispositivo: ¿en qué dispositivo se almacena el tensor? (normalmente GPU o CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorC: \\n\", tensorC)\n",
    "print(\"\\nForma del tensor: \", tensorC.shape)\n",
    "print(\"\\nTipo de dato del tensor: \", tensorC.dtype)\n",
    "print(\"\\nDispositivo donde se almacena el tensor: \", tensorC.device) #Por defecto será CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cambiar el tipo de dato del tensor se puede usar `torch.Tensor.type(dtype=None)` donde el parámetro `dtype` es el tipo de datos que quieres usar (int8, float16, float32, float64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor y chequear el tipo de dato\n",
    "tensorE = torch.arange(10., 100., 10.)\n",
    "tensorE.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir un tensor con datos de tipo int8\n",
    "tensor_int8 = tensorE.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas info: [documentación de `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.12'></a>\n",
    "### 3.12 - Reestructuración, apilamiento, compresión y descompresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordar tensorC y chequear su forma\n",
    "tensorC, tensorC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una dimensión extra\n",
    "tensorC_reshaped = tensorC.reshape(1, 10)\n",
    "tensorC_reshaped, tensorC_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apilar tensorC 3 veces (dim=0)\n",
    "tensorC_stacked = torch.stack([tensorC, tensorC, tensorC], dim=0)\n",
    "tensorC_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apilar tensorC 5 veces  (dim=1)\n",
    "tensorC_stacked = torch.stack([tensorC, tensorC, tensorC], dim=1)\n",
    "tensorC_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Exprimir\" todas las dimensiones en una sola\n",
    "\n",
    "tensorC_squeezed = tensorC_reshaped.squeeze()\n",
    "\n",
    "print(\"El tensorC con la nueva forma era: \\n\", tensorC_reshaped)\n",
    "print(\"\\nLa forma era: \", tensorC_reshaped.shape)\n",
    "print(\"\\nEl tensor 'exprimido' es: \\n\", tensorC_squeezed)\n",
    "print(\"\\nLa nueva forma es: \", tensorC_squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una dimensión de 1 en un índice específico\n",
    "# dim=0\n",
    "TensorC_unsqueezed = tensorC_squeezed.unsqueeze(dim=0)\n",
    "print(\"\\nEl tensor es: \\n\", TensorC_unsqueezed)\n",
    "print(\"\\nLa forma es: \", TensorC_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una dimensión de 1 en un índice específico\n",
    "# dim=1\n",
    "TensorC_unsqueezed = tensorC_squeezed.unsqueeze(dim=1)\n",
    "print(\"\\nEl tensor es: \\n\", TensorC_unsqueezed)\n",
    "print(\"\\nLa forma es: \", TensorC_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar el orden de los valores de los ejes\n",
    "# Crear un tensor con una forma específica\n",
    "# Puede simular una imagen de 224 x 224 a color (3 canales)\n",
    "foto = torch.rand(size=(224, 224, 3))\n",
    "print(\"La forma del tensor foto es: \\n\", foto.shape)\n",
    "# Permutar el tensor original para que los canales queden en el primer eje\n",
    "foto_permuted = foto.permute(2, 0, 1) \n",
    "# esto cambia los ejes 0->1, 1->2, 2->0\n",
    "print(\"La forma del tensor foto permutado es: \\n\", foto_permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a name='3.13'></a>\n",
    "### 3.13 - Reestructuración, apilamiento, compresión y descompresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Autograd\n",
    "\n",
    "La funcionalidad más importante que Pytorch añade es la conocidad como `autograd`, la cual permite la posibilidad de calcular derivadas de manera automática con respecto a cualquier tensor. Esto le da a Pytorch un gran potencial para diseñar redes neuronales complejas y entrenarlas utilizando algoritmos de gradientes sin tener que calcular todas estas derivadas manualmente. \n",
    "\n",
    "Para poder llevar a cabo estas operaciones, Pytorch va construyendo de manera dinámica un grafo computacional. Cada vez que aplicamos una operación sobre uno o varios tensores, éstos se añaden al grafo computacional junto a la operación en concreto. De esta manera, si se quiere calcular la derivada de cualquier valor con respecto a cualquier tensor, simplemente se tiene que aplicar el algoritmo de backpropagation (que no es más que la regla de la cadena de la derivada) en el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crean tres tensores x, y y z\n",
    "# Se definen dos operaciones p y g\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = torch.tensor(2., requires_grad=True)\n",
    "p = x + y\n",
    "z = torch.tensor(3., requires_grad=True)\n",
    "g = p * z\n",
    "print(\"x: \", x)\n",
    "print(\"y: \", y)\n",
    "print(\"z: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder calcular derivadas con respecto a estos tensores necesitamos ponder su propiedad `requiers_grad` a `True`. \n",
    "\n",
    "Ahora, calculamos el tensor intermedio $p$ como $p = x+ y$ y luego usamos este valor para calcular el resultado final $g$ como $g = p*z$. Cada vez que aplicamos una operación sobre un tensor que tiene su propiedad `requires_grad` a `True`, `Pytorch` irá construyendo el `grafo computacional`. Para este ejemplo, el grafo tendría la siguiente forma\n",
    "\n",
    "![](https://www.tutorialspoint.com/python_deep_learning/images/computational_graph_equation2.jpg)\n",
    "\n",
    "Si ahora se calculanlas derivadas de $g$ con respecto a $x$, $y$ y $z$, es tan fácil como llamar a la función `backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, `Pytorch` ha aplicado el algoritmo de `backpropagation` encima del grafo computacional, calculando todas las derivadas.\n",
    "\n",
    "$$ \\frac{dg}{dz} = p $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{dg}{dx} = \\frac{dg}{dp} \\frac{dp}{dx} = z $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `grafo computacional` es una herramienta extraordinaria para diseñar `redes neuronales` de complejidad arbitraria. Con una simple función, gracias al algoritmo de `backpropagation`, podemos calcular todas las derivadas de manera sencilla (cada nodo que representa una operación solo necesita calcular su propia derivada de manera local) y optimizar el modelo con nuestro algoritmo de gradiente preferido.\n",
    "\n",
    "Más sobre `autograd` [aquí](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - GPU\n",
    "\n",
    "Los algoritmos de aprendizaje profundo requieren muchas operaciones numéricas. Y, por defecto, estas operaciones suelen realizarse en una CPU (unidad de procesamiento informático).\n",
    "\n",
    "Sin embargo, existe otra pieza de hardware común llamada GPU (unidad de procesamiento gráfico), que a menudo es mucho más rápida para realizar los tipos específicos de operaciones que necesitan las redes neuronales (multiplicaciones de matrices) que las CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comprobar si esta disponible un dispositivo GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que el código se ejecute independientemente si se tiene o no GPU\n",
    "# Se setea una variable \"device\" para almacenar el dispositivo que este disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de contar con varias GPUs, se puede consultar la cantidad\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para mover un tensor a la GPU (si esta disponible)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)\n",
    "tensor_on_gpu = tensor.to(device) # Esto hace una copia de tensor en la GPU en este caso\n",
    "# Para devolver una copia de ese tensor y que este en los dos dispositivos (CPU y GPU)\n",
    "# hay que sobre escribir\n",
    "# algún_tensor = algún_tensor.to(dispositivo)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hay GPU disponible, el código anterior mostrará algo como:\n",
    "\n",
    " ```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    " ```\n",
    "\n",
    "`device='cuda:0'` quiere decir que esta disponible la GPU 0 y pueden haber disponibles varias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se puede transformar un tensor que esta en GPU a Numpy\n",
    "tensor_on_gpu.numpy()\n",
    "# Si tensor_on_gpu esta en GPU da un error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para devolver un tensor a la CPU y que se pueda transformar a Numpy\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu\n",
    "# Esto devuelve una copia del tensor de la GPU en la memoria de la CPU\n",
    "# El tensor original sigue en la GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ME QUEDE ACA!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn .__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "r, c = 3, 5\n",
    "fig = plt.figure(figsize=(2*c, 2*r))\n",
    "for _r in range(r):\n",
    "    for _c in range(c):\n",
    "        plt.subplot(r, c, _r*c + _c + 1)\n",
    "        ix  = random.randint(0, len(X)-1)\n",
    "        # img = X[ix]  # para versiones de dataset de sklearn inferiores a 1.0\n",
    "        img = X.iloc[ix].values\n",
    "        plt.imshow(img.reshape(28,28), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(Y[ix])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(\"int\"), Y[60000:].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función de pérdida y derivada\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    logits = output[torch.arange(len(output)), target]\n",
    "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in  = 784 # neuronas de entrada\n",
    "H     = 100 # neuronas de capa oculta\n",
    "D_out = 10  # neuronas de salidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.tensor (np.random.normal(\n",
    "            loc   = 0.0, \n",
    "            scale = 0.1,\n",
    "            #scale = np.sqrt( 2 / (D_in + H )),\n",
    "            size  = ( D_in , H)),\n",
    "    requires_grad = True,\n",
    "    device        = \"cpu\",\n",
    "    dtype         = torch.float)\n",
    "\n",
    "b1 = torch.zeros(H, \n",
    "                 requires_grad = True, \n",
    "                 device = \"cpu\", \n",
    "                 dtype = torch.float)\n",
    "\n",
    "w2 = torch.tensor(np.random.normal(\n",
    "          loc   = 0.0, \n",
    "          scale = 0.1,\n",
    "          #scale = np.sqrt( 2 / ( D_out + H) ), \n",
    "          size  = ( H , D_out )), \n",
    "                  requires_grad = True, \n",
    "                  device        = \"cpu\", \n",
    "                  dtype         = torch.float)\n",
    "\n",
    "b2 = torch.zeros(D_out, \n",
    "                 requires_grad = True, \n",
    "                 device        = \"cpu\", \n",
    "                 dtype         = torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos datos a tensores y copiamos en gpu\n",
    "X_t = torch.from_numpy(X_train.values).float()   #.cuda()\n",
    "Y_t = torch.from_numpy(y_train.values).long()   # .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs    = 100\n",
    "lr        = 0.8\n",
    "log_each  = 10\n",
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, epochs+1): \n",
    "    \n",
    "    # forward\n",
    "    h = X_t.mm(w1) + b1\n",
    "    h_relu = h.clamp(min=0) # relu  \n",
    "    y_pred = h_relu.mm(w2) + b2\n",
    "\n",
    "    # loss\n",
    "    loss = cross_entropy(y_pred, Y_t)\n",
    "    l.append(loss.item())\n",
    "\n",
    "    # Backprop (calculamos todos los gradientes automáticamente)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # update pesos\n",
    "        w1 -= lr * w1.grad\n",
    "        b1 -= lr * b1.grad\n",
    "        w2 -= lr * w2.grad  \n",
    "        b2 -= lr * b2.grad\n",
    "        \n",
    "        # ponemos a cero los gradientes para la siguiente iteración\n",
    "        # (sino acumularíamos gradientes)\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "    \n",
    "    if not e % log_each:\n",
    "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(\n",
    "          loc   = 0.0, \n",
    "          #scale = np.sqrt( 2 / ( D_out + H) ),\n",
    "          scale = 0.01,\n",
    "          size  = ( 10,5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x):\n",
    "    h = x.mm(w1) + b1\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2) + b2\n",
    "    y_probas = softmax(y_pred)\n",
    "    return torch.argmax(y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = evaluate(torch.from_numpy(X_test.values).float())#.cuda())\n",
    "accuracy_score(y_test, y_pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 3, 5\n",
    "fig = plt.figure(figsize=(2*c, 2*r))\n",
    "test_imgs, test_labs = [], []\n",
    "for _r in range(r):\n",
    "    for _c in range(c):\n",
    "        plt.subplot(r, c, _r*c + _c + 1)\n",
    "        ix = random.randint(0, len(X_test)-1)\n",
    "        img = X_test.iloc[ix].values\n",
    "        y_pred = evaluate(torch.tensor([img]).float())[0] #.cuda())[0]\n",
    "        plt.imshow(img.reshape(28,28), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "        #print(y_pred)\n",
    "        #print(y_test.iloc[ix])\n",
    "        plt.title(f\"{y_test.iloc[ix]}/{y_pred}\", color=\"green\" if y_test.iloc[ix] == y_pred.item() else \"red\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_test.iloc[5910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.tensor([[1,2],[4,5],[3,3]])\n",
    "print(mat1)\n",
    "\n",
    "print(mat1.sum(axis=0))\n",
    "print(mat1.sum(axis=1))\n",
    "print(mat1.sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.tensor([[[1,2],[4,5],[3,6]]])\n",
    "print(mat1)\n",
    "\n",
    "print(mat1.sum(axis=0))\n",
    "print(mat1.sum(axis=1))\n",
    "print(mat1.sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_x=torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
